# --- START OF FILE MCDOCRcvocr_gui.py ---


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CVOCR(Context Vision OCR)æ–‡æœ¬è¯†åˆ«æ’ä»¶ - å¢å¼ºç¨³å®šç‰ˆ v3.0 (2025)
ä½œè€…ï¼šè·³èˆçš„ç«å…¬å­
å®Œå…¨é‡æ„ï¼Œæ”¯æŒCVOCRæœ€æ–°ç‰ˆæœ¬ï¼Œå¤§å¹…å¢å¼ºæ–‡æœ¬æ£€æµ‹ç²¾åº¦å’Œè¯†åˆ«å‡†ç¡®åº¦
æ–°å¢æ™ºèƒ½æ–‡æœ¬æ£€æµ‹ã€é«˜çº§å›¾åƒé¢„å¤„ç†ã€è‡ªé€‚åº”å‚æ•°ä¼˜åŒ–ç­‰åŠŸèƒ½
æŠ€æœ¯æ¶æ„ï¼šPP-OCRv3 + LayoutLMv2 + Tesseract + GPT-Neo + Transformer OCR
"""

import os
import sys
import cv2
import numpy as np
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
from PIL import Image, ImageTk, ImageDraw, ImageFont, ImageEnhance, ImageFilter
import threading
import json
import time
import traceback
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Union, Tuple, Any, Callable
import logging
import inspect
from pathlib import Path
import queue
from enum import Enum
import math
import re
import yaml
from collections import defaultdict, deque
import asyncio 
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
import tempfile
import shutil
import platform
import subprocess
import psutil 
import functools 

try:
    import requests # ### å¢å¼ºåŠŸèƒ½ 1: å¯¼å…¥requestsåº“ç”¨äºè‡ªåŠ¨ä¸‹è½½æ¨¡å‹
except ImportError:
    requests = None


# ç‰ˆæœ¬ä¿¡æ¯
__version__ = "3.0.0"
__author__ = "è·³èˆçš„ç«å…¬å­"
__date__ = "2025-08-23"
__description__ = "Enhanced CVOCR GUI with Multi-Model Integration"

# ä»è®¾è®¡ç³»ç»Ÿå¯¼å…¥è®¾è®¡ä»¤ç‰Œå’Œå…¨å±€è®¾è®¡ç³»ç»Ÿå®ä¾‹
try:
    from design_system import design
except ImportError:
    # å¦‚æœæ²¡æœ‰design_systemæ¨¡å—ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æ›¿ä»£å“
    class SimpleDesign:
        @staticmethod
        def get_color(category, shade):
            colors = {
                'neutral': {
                    '0': '#ffffff', '50': '#f9fafb', '100': '#f3f4f6', 
                    '200': '#e5e7eb', '300': '#d1d5db', '400': '#9ca3af',
                    '500': '#6b7280', '600': '#4b5563', '700': '#374151', 
                    '800': '#1f2937', '900': '#111827'
                },
                'primary': {
                    '50': '#eff6ff', '100': '#dbeafe', '200': '#bfdbfe',
                    '300': '#93c5fd', '400': '#60a5fa', '500': '#3b82f6',
                    '600': '#2563eb', '700': '#1d4ed8', '800': '#1e40af',
                    '900': '#1e3a8a'
                },
                'success': {
                    '50': '#f0fdf4', '100': '#dcfce7', '500': '#22c55e',
                    '600': '#16a34a', '700': '#15803d'
                },
                'warning': {
                    '50': '#fffbeb', '100': '#fef3c7', '500': '#f59e0b',
                    '600': '#d97706', '700': '#b45309'
                },
                'error': {
                    '50': '#fef2f2', '100': '#fee2e2', '500': '#ef4444',
                    '600': '#dc2626', '700': '#b91c1c'
                }
            }
            return colors.get(category, {}).get(str(shade), '#ffffff')
        
        @staticmethod
        def get_spacing(size):
            spacing_map = {'1': 4, '2': 8, '3': 12, '4': 16, '6': 24, '8': 32, '12': 48}
            return spacing_map.get(str(size), 8)
        
        @staticmethod
        def get_font(size, family='primary'):
            fonts = {
                'xs': ('Arial', 9), 'sm': ('Arial', 10), 'base': ('Arial', 12), 
                'lg': ('Arial', 14), 'xl': ('Arial', 16), 'body': ('Arial', 11),
                'h1': ('Arial', 24, 'bold'), 'h2': ('Arial', 20, 'bold'),
                'h3': ('Arial', 16, 'bold'), 'h4': ('Arial', 14, 'bold')
            }
            return fonts.get(size, ('Arial', 12))
        
        @staticmethod
        def configure_ttk_styles(style_manager):
            style_manager.configure('Success.TLabel', foreground='#16a34a')
            style_manager.configure('Warning.TLabel', foreground='#d97706')
            style_manager.configure('Error.TLabel', foreground='#dc2626')
        
        @staticmethod
        def apply_button_style(button, style_type):
            colors = {
                'primary': {'bg': '#2563eb', 'fg': 'white', 'active_bg': '#1d4ed8'},
                'secondary': {'bg': '#6b7280', 'fg': 'white', 'active_bg': '#4b5563'},
                'success': {'bg': '#16a34a', 'fg': 'white', 'active_bg': '#15803d'},
                'warning': {'bg': '#d97706', 'fg': 'white', 'active_bg': '#b45309'},
                'error': {'bg': '#dc2626', 'fg': 'white', 'active_bg': '#b91c1c'}
            }
            color_config = colors.get(style_type, colors['secondary'])
            button.config(
                bg=color_config['bg'], 
                fg=color_config['fg'],
                activebackground=color_config['active_bg'],
                activeforeground='white',
                relief='flat',
                bd=0,
                font=('Arial', 10),
                cursor='hand2'
            )
        
        @staticmethod
        def apply_text_style(label, style_type):
            styles = {
                'h1': {'font': ('Arial', 24, 'bold')},
                'h2': {'font': ('Arial', 20, 'bold')},
                'h3': {'font': ('Arial', 16, 'bold')},
                'h4': {'font': ('Arial', 14, 'bold')},
                'body': {'font': ('Arial', 12)},
                'body_small': {'font': ('Arial', 10)},
                'caption': {'font': ('Arial', 9), 'fg': '#6b7280'}
            }
            style_config = styles.get(style_type, {})
            label.config(**style_config)
    
    design = SimpleDesign()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG, # <--- ä¿®æ”¹ä¸º DEBUG
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('cvocr_gui.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
class CVOCRConstants:
    """CVOCRå¸¸é‡å®šä¹‰"""
    VERSION = "3.0.0"
    SUPPORTED_IMAGE_FORMATS = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.gif']
    MAX_IMAGE_SIZE = 20000  # æœ€å¤§å›¾åƒå°ºå¯¸
    MIN_IMAGE_SIZE = 32     # æœ€å°å›¾åƒå°ºå¯¸
    MAX_FILE_SIZE = 500 * 1024 * 1024  # æœ€å¤§æ–‡ä»¶å¤§å° 500MB
    DEFAULT_CONFIDENCE_THRESHOLD = 60
    DEFAULT_DPI = 300
    CACHE_EXPIRE_HOURS = 24




class ModelDownloader:
    """
    ä¸€ä¸ªé€šç”¨çš„æ¨¡å‹ä¸‹è½½å’ŒéªŒè¯è¾…åŠ©ç±»ã€‚
    - è‡ªåŠ¨æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚
    - é€šè¿‡SHA256å“ˆå¸Œå€¼éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ã€‚
    - å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸåï¼Œåˆ™è‡ªåŠ¨ä¸‹è½½ã€‚
    - æä¾›ä¸‹è½½è¿›åº¦åé¦ˆã€‚
    """
    def __init__(self, models_info: Dict, logger_func: Callable):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨ã€‚
        Args:
            models_info (Dict): åŒ…å«æ¨¡å‹ä¿¡æ¯çš„å­—å…¸ã€‚
            logger_func (Callable): ç”¨äºå‘GUIå‘é€æ—¥å¿—æ¶ˆæ¯çš„å‡½æ•°ã€‚
        """
        self.models = models_info
        self.log = logger_func

    def _calculate_sha256(self, filepath: str) -> str:
        """è®¡ç®—æ–‡ä»¶çš„SHA256å“ˆå¸Œå€¼"""
        sha256_hash = hashlib.sha256()
        try:
            with open(filepath, "rb") as f:
                # é€å—è¯»å–ä»¥å¤„ç†å¤§æ–‡ä»¶
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            return sha256_hash.hexdigest()
        except Exception as e:
            self.log(f"âŒ è®¡ç®—å“ˆå¸Œå€¼å¤±è´¥: {filepath}, é”™è¯¯: {e}", "ERROR")
            return ""

    def _verify_file(self, filepath: str, expected_hash: str) -> bool:
        """éªŒè¯æ–‡ä»¶çš„SHA256å“ˆå¸Œå€¼æ˜¯å¦åŒ¹é…"""
        self.log(f"ğŸ” æ­£åœ¨éªŒè¯æ–‡ä»¶: {os.path.basename(filepath)}...", "INFO")
        actual_hash = self._calculate_sha256(filepath)
        if actual_hash.lower() == expected_hash.lower():
            self.log(f"âœ… æ–‡ä»¶ '{os.path.basename(filepath)}' éªŒè¯æˆåŠŸã€‚", "SUCCESS")
            return True
        else:
            self.log(f"âš ï¸ æ–‡ä»¶ '{os.path.basename(filepath)}' éªŒè¯å¤±è´¥ï¼å“ˆå¸Œå€¼ä¸åŒ¹é…ã€‚", "WARNING")
            self.log(f"   - æœŸæœ›å“ˆå¸Œ: {expected_hash.lower()}", "DEBUG")
            self.log(f"   - å®é™…å“ˆå¸Œ: {actual_hash.lower()}", "DEBUG")
            return False

    def _download_file(self, url: str, filepath: str) -> bool:
        """ä»URLä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦"""
        filename = os.path.basename(filepath)
        self.log(f"ğŸŒ å¼€å§‹ä¸‹è½½: {filename}...", "INFO")
        try:
            with requests.get(url, stream=True, timeout=300) as r:
                r.raise_for_status()
                total_size = int(r.headers.get('content-length', 0))
                bytes_downloaded = 0
                last_logged_percent = -1
                
                with open(filepath, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)
                        bytes_downloaded += len(chunk)
                        if total_size > 0:
                            percent = int((bytes_downloaded / total_size) * 100)
                            if percent > last_logged_percent and percent % 10 == 0:
                                self.log(f"   ä¸‹è½½è¿›åº¦: {filename} - {percent}%", "INFO")
                                last_logged_percent = percent
            
            self.log(f"âœ… {filename} ä¸‹è½½å®Œæˆã€‚", "SUCCESS")
            return True
        except requests.exceptions.RequestException as e:
            self.log(f"âŒ ä¸‹è½½å¤±è´¥: {filename}, é”™è¯¯: {e}", "ERROR")
            if os.path.exists(filepath):
                os.remove(filepath) # åˆ é™¤ä¸å®Œæ•´çš„æ–‡ä»¶
            return False
        except Exception as e:
            self.log(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {filename}, é”™è¯¯: {e}", "ERROR")
            return False

    def check_and_download_all(self) -> bool:
        """æ£€æŸ¥æ‰€æœ‰æ¨¡å‹ï¼Œå¦‚æœéœ€è¦åˆ™ä¸‹è½½å¹¶éªŒè¯ã€‚"""
        for model_name, info in self.models.items():
            filepath = info['filename']
            
            if os.path.exists(filepath):
                if self._verify_file(filepath, info['sha256_hash']):
                    continue  # æ–‡ä»¶å­˜åœ¨ä¸”å®Œå¥½ï¼Œè·³åˆ°ä¸‹ä¸€ä¸ª
                else:
                    self.log(f"æ£€æµ‹åˆ°æŸåæ–‡ä»¶ '{filepath}'ã€‚å°†åˆ é™¤å¹¶é‡æ–°ä¸‹è½½ã€‚", "WARNING")
                    os.remove(filepath)
            
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²æŸåè¢«åˆ é™¤ï¼Œåˆ™ä¸‹è½½
            if not self._download_file(info['url'], filepath):
                messagebox.showerror("æ¨¡å‹ä¸‹è½½å¤±è´¥", 
                                     f"æ— æ³•ä¸‹è½½å…³é”®æ¨¡å‹æ–‡ä»¶ '{filepath}'ã€‚\n\n"
                                     "å›¾å½¢å’Œè¡¨æ ¼æ£€æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚\n"
                                     "è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥å’Œæ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚")
                return False  # ä¸€æ—¦æœ‰æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œåˆ™ç»ˆæ­¢
            
            # ä¸‹è½½åå†æ¬¡éªŒè¯
            if not self._verify_file(filepath, info['sha256_hash']):
                messagebox.showerror("æ¨¡å‹éªŒè¯å¤±è´¥", 
                                     f"ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶ '{filepath}' å·²æŸåã€‚\n\n"
                                     "å›¾å½¢å’Œè¡¨æ ¼æ£€æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚\n"
                                     "è¯·å°è¯•é‡å¯ç¨‹åºæˆ–æ‰‹åŠ¨ä¸‹è½½ã€‚")
                return False # éªŒè¯å¤±è´¥ï¼Œç»ˆæ­¢

        self.log("âœ… æ‰€æœ‰YOLOæ¨¡å‹æ–‡ä»¶å‡å·²å‡†å¤‡å°±ç»ªã€‚", "SUCCESS")
        return True

class AdvancedTextSegmentator:
    """é«˜çº§æ–‡æœ¬åˆ†å‰²å™¨ - å®ç°ç²¾ç¡®çš„æ–‡æœ¬è¡Œæ£€æµ‹ã€å­—ç¬¦åˆ†å‰²å’ŒåŒºåŸŸä¼˜åŒ–"""
    
    def __init__(self):
        self.config = {
            # æ–‡æœ¬è¡Œæ£€æµ‹å‚æ•°
            'min_text_size': 6,
            'max_text_size': 300,
            'text_threshold': 0.6,
            'link_threshold': 0.3,
            'low_text': 0.3,
            'mag_ratio': 1.8,
            'slope_ths': 0.05,
            'ycenter_ths': 0.8,
            'height_ths': 0.8,
            'width_ths': 0.8,
            'add_margin': 0.15,
            
            # å­—ç¬¦åˆ†å‰²å‚æ•°
            'char_min_width': 4,
            'char_max_width': 100,
            'char_min_height': 8,
            'char_max_height': 150,
            'char_aspect_ratio_min': 0.1,
            'char_aspect_ratio_max': 5.0,
            
            # åˆ†å‰²è´¨é‡å‚æ•°
            'min_fill_ratio': 0.1,
            'max_overlap_ratio': 0.3,
            'merge_threshold': 0.5,
            'split_threshold': 0.7,
            
            # é«˜çº§åˆ†å‰²å‚æ•°
            'multi_scale_levels': 3,
            'adaptive_threshold_sizes': [7, 11, 15, 21],
            'morphology_iterations': 2,
            'connected_component_min_area': 25,
            
            # æ–‡æœ¬æ–¹å‘æ£€æµ‹
            'angle_detection_precision': 0.1,
            'text_line_merge_distance': 5,
            'text_line_height_variance': 0.3,
        }
        
        # åˆ†å‰²ç®—æ³•ç¼“å­˜
        self._segmentation_cache = {}
        self._cache_max_size = 15
        
        logger.info("é«˜çº§æ–‡æœ¬åˆ†å‰²å™¨å·²åˆå§‹åŒ–")
class EnhancedTextDetector(AdvancedTextSegmentator):
    """
    å¢å¼ºç‰ˆæ–‡æœ¬æ£€æµ‹å™¨ (V4.2 - ç­–ç•¥ç»„åˆç‰ˆ)
    - å…è®¸ç”¨æˆ·é€šè¿‡ç®—æ³•åˆ—è¡¨åŠ¨æ€ç»„åˆæ£€æµ‹ç­–ç•¥ã€‚
    - åºŸé™¤å›ºå®šçš„ç²¾åº¦ç­‰çº§ï¼Œæ”¹ä¸ºçµæ´»çš„æ–¹æ³•è°ƒåº¦ã€‚
    """
    def _is_likely_punctuation(self, region_info: Dict, reference_height: float) -> bool:
        """
        é€šè¿‡å‡ ä½•ç‰¹å¾å¯å‘å¼åœ°åˆ¤æ–­ä¸€ä¸ªåŒºåŸŸæ˜¯å¦å¯èƒ½æ˜¯æ ‡ç‚¹ç¬¦å·ã€‚
        Args:
            region_info (Dict): åŒ…å«åŒºåŸŸ 'rect' ä¿¡æ¯çš„å­—å…¸ã€‚
            reference_height (float): ç”¨äºæ¯”è¾ƒçš„å‚è€ƒé«˜åº¦ï¼ˆé€šå¸¸æ˜¯ç›¸é‚»æ–‡æœ¬å—çš„é«˜åº¦ï¼‰ã€‚
        Returns:
            bool: å¦‚æœåŒºåŸŸå¯èƒ½æ˜¯æ ‡ç‚¹ç¬¦å·ï¼Œåˆ™ä¸º Trueã€‚
        """
        if not region_info or reference_height <= 0:
            return False
        
        try:
            _, (w, h), _ = region_info['rect']
            # æ ‡å‡†åŒ–å®½é«˜
            if w < h: w, h = h, w

            # æ ‡ç‚¹ç¬¦å·çš„ç‰¹å¾ï¼š
            # 1. é«˜åº¦æ˜æ˜¾å°äºæ­£å¸¸å­—ç¬¦ã€‚
            # 2. å®½é«˜æ¯”åœ¨ä¸€å®šèŒƒå›´å†…ï¼ˆè¦†ç›–äº†æ–¹å½¢çš„ç‚¹ã€é€—å·ï¼Œä»¥åŠæ‰å¹³çš„ç ´æŠ˜å·ï¼‰ã€‚
            is_small_enough = h < reference_height * 0.6
            aspect_ratio = w / (h + 1e-6)
            is_aspect_ratio_ok = 0.2 < aspect_ratio < 2.5
            
            return is_small_enough and is_aspect_ratio_ok
        except Exception:
            return False


    def _aggregate_line_fragments(self, regions: List[np.ndarray]) -> List[np.ndarray]:
        """
        (V5æ ¸å¿ƒ) ä½¿ç”¨å‡¸åŒ…èšåˆç­–ç•¥ï¼Œå°†ä¸€è¡Œå†…çš„æ‰€æœ‰ç¢ç‰‡å¼ºåˆ¶åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„ã€å®Œæ•´çš„åŒºåŸŸã€‚
        è¿™æ˜¯ä¸€ä¸ªæ•´ä½“æ€§ã€éè´ªå©ªçš„åˆå¹¶æ–¹æ³•ã€‚
        
        Args:
            regions (List[np.ndarray]): å·²è¢«èšç±»åˆ°åŒä¸€è¡Œçš„æ‰€æœ‰æ–‡æœ¬åŒºåŸŸç¢ç‰‡ã€‚

        Returns:
            List[np.ndarray]: ä¸€ä¸ªåªåŒ…å«å•ä¸ªã€å·²åˆå¹¶çš„æ–‡æœ¬è¡ŒåŒºåŸŸçš„åˆ—è¡¨ã€‚
        """
        if not regions:
            return []
        
        # å¦‚æœä¸€è¡Œåªæœ‰ä¸€ä¸ªç¢ç‰‡ï¼Œç›´æ¥è¿”å›ï¼Œæ— éœ€å¤„ç†
        if len(regions) == 1:
            return regions
            
        try:
            # å°†è¯¥è¡Œæ‰€æœ‰ç¢ç‰‡çš„æ‰€æœ‰é¡¶ç‚¹åæ ‡æ”¶é›†åˆ°ä¸€ä¸ªå¤§çš„åˆ—è¡¨ä¸­
            all_points = np.vstack(regions)
            
            # è®¡ç®—èƒ½åŒ…å›´æ‰€æœ‰è¿™äº›ç‚¹çš„æœ€å°é¢ç§¯çš„æ—‹è½¬çŸ©å½¢
            merged_rect = cv2.minAreaRect(all_points)
            
            # è·å–è¿™ä¸ªæœ€ç»ˆçŸ©å½¢çš„å››ä¸ªè§’ç‚¹
            merged_box = cv2.boxPoints(merged_rect)
            
            # è¿”å›åªåŒ…å«è¿™ä¸€ä¸ªå®Œæ•´è¡Œæ¡†çš„åˆ—è¡¨
            return [merged_box.astype(np.float32)]

        except Exception as e:
            logger.error(f"è¡Œç¢ç‰‡èšåˆå¤±è´¥: {e}", exc_info=True)
            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œå®‰å…¨åœ°è¿”å›åŸå§‹æœªåˆå¹¶çš„ç¢ç‰‡
            return regions       
    def _merge_text_regions_in_line(self, regions: List[np.ndarray]) -> List[np.ndarray]:
        """
        æ™ºèƒ½åˆå¹¶åœ¨åŒä¸€è¡Œå†…çš„æ–‡æœ¬åŒºåŸŸ (V3 - å‡ ä½•ä¼˜åŒ–æœ€ç»ˆç‰ˆ)
        æ­¤ç‰ˆæœ¬ä¸“æ³¨äºé€šè¿‡æ›´ç²¾ç¡®å’Œæ›´å®½æ¾çš„å‡ ä½•åˆ¤æ–­æ¥æå‡åˆå¹¶æ•ˆæœã€‚
        - å›å½’åˆ°çº¯å‡ ä½•åˆ¤æ–­ï¼Œç§»é™¤äº†å¯èƒ½åœ¨æ–°å·¥ä½œæµä¸‹å¤±æ•ˆçš„åƒç´ ç‰¹å¾åˆ†æã€‚
        - é‡‡ç”¨æ›´é²æ£’çš„æ°´å¹³é—´éš™è®¡ç®—æ–¹æ³•ï¼Œç›´æ¥æ¯”è¾ƒæ—‹è½¬çŸ©å½¢çš„è¾¹ç•Œã€‚
        - é€‚åº¦æ”¾å®½äº†å‚ç›´å¯¹é½å’Œæ°´å¹³é—´éš™çš„é˜ˆå€¼ï¼Œä»¥åˆå¹¶æ›´å¤šåˆç†çš„æ–‡æœ¬å—ã€‚
        """
        if len(regions) <= 1:
            return regions

        try:
            # æ­¥éª¤1: è·å–æ¯ä¸ªåŒºåŸŸçš„è¯¦ç»†å‡ ä½•ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ—‹è½¬çŸ©å½¢å’Œå…¶å››ä¸ªè§’ç‚¹
            regions_info = []
            for r in regions:
                # ä½¿ç”¨ try-except ä»¥å¤„ç†æ— æ•ˆåŒºåŸŸï¼Œé˜²æ­¢ç¨‹åºå´©æºƒ
                try:
                    rect = cv2.minAreaRect(r.astype(np.int32))
                    # cv2.boxPoints è¿”å›æ—‹è½¬çŸ©å½¢çš„4ä¸ªè§’ç‚¹ï¼Œè¿™å¯¹äºç²¾ç¡®è®¡ç®—é—´éš™è‡³å…³é‡è¦
                    points = cv2.boxPoints(rect)
                    regions_info.append({'region': r, 'rect': rect, 'points': points})
                except cv2.error:
                    logger.warning(f"è·³è¿‡æ— æ•ˆåŒºåŸŸï¼Œæ— æ³•è®¡ç®— minAreaRectã€‚")
                    continue # è·³è¿‡è¿™ä¸ªæ— æ•ˆåŒºåŸŸ

            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„åŒºåŸŸå¯ä¾›å¤„ç†ï¼Œç›´æ¥è¿”å›
            if not regions_info:
                return regions

            # æ­¥éª¤2: æŒ‰ä¸­å¿ƒç‚¹çš„Xåæ ‡å¯¹åŒºåŸŸè¿›è¡Œæ’åºï¼Œç¡®ä¿ä»å·¦åˆ°å³å¤„ç†
            regions_info.sort(key=lambda item: item['rect'][0][0])

            # æ­¥éª¤3: è¿­ä»£åœ°è¿›è¡Œåˆ†ç»„å’Œåˆå¹¶
            merged_regions = []
            if not regions_info:
                return [] # å†æ¬¡æ£€æŸ¥ï¼Œä»¥é˜²ä¸‡ä¸€
            
            # åˆå§‹åŒ–ç¬¬ä¸€ä¸ªåˆå¹¶ç»„
            current_merge_group = [regions_info[0]]

            for i in range(1, len(regions_info)):
                prev_info = current_merge_group[-1]
                current_info = regions_info[i]

                (cx_prev, cy_prev), (w_prev, h_prev), _ = prev_info['rect']
                (cx_curr, cy_curr), (w_curr, h_curr), _ = current_info['rect']
                
                # æ ‡å‡†åŒ–å®½é«˜ï¼Œç¡®ä¿ h æ˜¯è¾ƒçŸ­çš„è¾¹ï¼ˆè¿‘ä¼¼äºæ–‡æœ¬è¡Œçš„é«˜åº¦ï¼‰
                if w_prev < h_prev: w_prev, h_prev = h_prev, w_prev
                if w_curr < h_curr: w_curr, h_curr = h_curr, w_curr

                # --- æ­¥éª¤4: å®šä¹‰å¹¶åº”ç”¨ä¼˜åŒ–åçš„å¤šç»´åº¦åˆå¹¶æ¡ä»¶ ---
                
                # æ¡ä»¶1: å‚ç›´ä¸­å¿ƒç‚¹å¯¹é½ (é˜ˆå€¼å·²æ”¾å®½)
                # ä½¿ç”¨ä¸¤ä¸ªåŒºåŸŸä¸­è¾ƒé«˜è€…çš„é«˜åº¦ä½œä¸ºåŸºå‡†
                max_height = max(h_prev, h_curr, 1) # æ·»åŠ 1ä»¥é¿å…é™¤ä»¥é›¶
                vertical_dist = abs(cy_prev - cy_curr)
                # åªè¦å‚ç›´åå·®å°äºæœ€å¤§é«˜åº¦çš„70%ï¼Œå°±è®¤ä¸ºæ˜¯å¯¹é½çš„
                is_vertically_aligned = vertical_dist < max_height * 0.7

                # æ¡ä»¶2: æ°´å¹³é—´éš™åˆç† (é‡‡ç”¨æ–°ç®—æ³•ï¼Œæ›´ç²¾ç¡®ï¼Œé˜ˆå€¼å·²æ”¾å®½)
                # è·å–å‰ä¸€ä¸ªåŒºåŸŸçš„æœ€å³ä¾§xåæ ‡å’Œå½“å‰åŒºåŸŸçš„æœ€å·¦ä¾§xåæ ‡
                prev_max_x = np.max(prev_info['points'][:, 0])
                curr_min_x = np.min(current_info['points'][:, 0])
                # è®¡ç®—å®ƒä»¬ä¹‹é—´çš„çœŸå®æ°´å¹³é—´éš™
                horizontal_gap = curr_min_x - prev_max_x
                # é—´éš™åº”è¯¥ä¸ºæ­£ï¼ˆå³ä¸é‡å ï¼‰ï¼Œä¸”å°äºä¸€ä¸ªè¾ƒå¤§çš„é˜ˆå€¼ï¼ˆä¾‹å¦‚æœ€å¤§é«˜åº¦çš„3å€ï¼Œå…è®¸å‡ ä¸ªå­—ç¬¦çš„ç©ºæ ¼ï¼‰
                is_horizontally_close = 0 <= horizontal_gap < max_height * 3.0

                # æ¡ä»¶3: é«˜åº¦ç›¸ä¼¼æ€§ (è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„çº¦æŸï¼Œä¿æŒä¸å˜)
                height_ratio = min(h_prev, h_curr) / (max_height + 1e-6) # åŠ epsiloné˜²æ­¢é™¤é›¶
                is_height_similar = height_ratio > 0.6

                # ç»¼åˆåˆ¤æ–­ï¼šä¸‰ä¸ªæ¡ä»¶å¿…é¡»åŒæ—¶æ»¡è¶³
                if is_vertically_aligned and is_horizontally_close and is_height_similar:
                    # å¦‚æœæ»¡è¶³ï¼Œå°†å½“å‰åŒºåŸŸåŠ å…¥æ­£åœ¨æ„å»ºçš„åˆå¹¶ç»„
                    current_merge_group.append(current_info)
                else:
                    # å¦‚æœä¸æ»¡è¶³ï¼Œè¯´æ˜ä¸€ä¸ªåˆå¹¶ç»„ç»“æŸäº†
                    # å¤„ç†ä¸Šä¸€ä¸ªåˆå¹¶ç»„
                    group_regions = [info['region'] for info in current_merge_group]
                    if len(group_regions) > 1:
                        # å¦‚æœç»„é‡Œæœ‰å¤šä¸ªåŒºåŸŸï¼Œå°†å®ƒä»¬çš„æ‰€æœ‰ç‚¹åˆå¹¶ï¼Œå¹¶è®¡ç®—ä¸€ä¸ªæ–°çš„ã€èƒ½åŒ…å›´æ‰€æœ‰ç‚¹çš„æœ€å°å¤–æ¥çŸ©å½¢
                        all_points = np.vstack(group_regions)
                        merged_rect = cv2.minAreaRect(all_points)
                        merged_box = cv2.boxPoints(merged_rect)
                        merged_regions.append(merged_box.astype(np.float32))
                    else:
                        # å¦‚æœç»„é‡Œåªæœ‰ä¸€ä¸ªåŒºåŸŸï¼Œç›´æ¥å°†å…¶æ·»åŠ åˆ°ç»“æœä¸­
                        merged_regions.append(group_regions[0])
                    
                    # å¼€å¯ä¸€ä¸ªæ–°çš„åˆå¹¶ç»„ï¼Œå¹¶å°†å½“å‰åŒºåŸŸä½œä¸ºæ–°ç»„çš„ç¬¬ä¸€ä¸ªæˆå‘˜
                    current_merge_group = [current_info]

            # æ­¥éª¤5: å¾ªç¯ç»“æŸåï¼Œä¸è¦å¿˜è®°å¤„ç†æœ€åä¸€ç»„
            group_regions = [info['region'] for info in current_merge_group]
            if len(group_regions) > 1:
                all_points = np.vstack(group_regions)
                merged_rect = cv2.minAreaRect(all_points)
                merged_box = cv2.boxPoints(merged_rect)
                merged_regions.append(merged_box.astype(np.float32))
            else:
                merged_regions.append(group_regions[0])
                
            return merged_regions

        except Exception as e:
            # æ•è·æ•´ä¸ªæ–¹æ³•çš„æ„å¤–é”™è¯¯ï¼Œå¹¶è®°å½•æ—¥å¿—
            logger.error(f"æ™ºèƒ½è¡Œåˆå¹¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)
            # åœ¨å‘ç”Ÿé”™è¯¯æ—¶ï¼Œå®‰å…¨åœ°è¿”å›åŸå§‹æœªåˆå¹¶çš„åŒºåŸŸåˆ—è¡¨ï¼Œé¿å…ç¨‹åºå´©æºƒ
            return regions
    def detect_text_regions_advanced(self, image: np.ndarray, 
                                 enabled_algorithms: List[str]) -> Tuple[List[np.ndarray], Dict]:
        """
        é«˜çº§æ–‡æœ¬åŒºåŸŸæ£€æµ‹ (V5 - æ•´ä½“èšåˆç‰ˆ)
        - å¼•å…¥ä¸¤é˜¶æ®µâ€œèšç±»-èšåˆâ€å·¥ä½œæµã€‚
        - å½»åº•æ”¾å¼ƒâ€œæˆå¯¹åˆå¹¶â€ï¼Œæ”¹ç”¨åŸºäºå‡¸åŒ…çš„â€œæ•´ä½“èšåˆâ€ç­–ç•¥ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³ç¢ç‰‡åŒ–é—®é¢˜ã€‚
        """
        try:
            algorithms_key = "_".join(sorted(enabled_algorithms))
            merge_status_key = f"merge_on" if self.config.get('enable_smart_line_merge', True) else "merge_off"
            cache_key = f"{hash(image.tobytes())}_{algorithms_key}_{merge_status_key}"

            if cache_key in self._segmentation_cache:
                cached_result = self._segmentation_cache[cache_key]
                logger.info("ä½¿ç”¨ç¼“å­˜çš„åˆ†å‰²ç»“æœ")
                return cached_result['regions'], cached_result['metadata']
            
            start_time = time.time()
            
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image.copy()

            # æ­¥éª¤ 1: æ”¶é›†æ‰€æœ‰åŸå§‹ã€ç²¾ç»†çš„å€™é€‰åŒºåŸŸ
            all_raw_regions = []
            methods_used = []
            
            algorithm_map = {
                'simple_high_contrast': self._simple_high_contrast_detection,
                'improved_mser': self._improved_mser_detection,
                'multiscale_contour': self._multiscale_contour_detection,
                'gradient_based': self._gradient_based_detection,
                'multilevel_mser': lambda g: self._multilevel_mser_detection(g)[0],
                'stroke_width_transform': lambda g: self._stroke_width_transform_detection(g)[0],
                'connected_components': lambda g: self._connected_component_analysis(g)[0],
                'character_level': lambda g: self._character_level_detection(g)[0]
            }

            for algo_name in enabled_algorithms:
                if algo_name in algorithm_map:
                    try:
                        regions = algorithm_map[algo_name](gray)
                        all_raw_regions.extend(regions)
                        methods_used.append(algo_name)
                    except Exception as e:
                        logger.error(f"æ‰§è¡Œç®—æ³• '{algo_name}' æ—¶å¤±è´¥: {e}")
            
            # æ­¥éª¤ 2: (å¯é€‰) å¯¹æ‰€æœ‰æ”¶é›†åˆ°çš„åŸå§‹åŒºåŸŸè¿›è¡Œæ™ºèƒ½è¡Œèšåˆ
            regions_to_optimize = []
            if self.config.get('enable_smart_line_merge', True):
                logger.info(f"æ”¶é›†åˆ° {len(all_raw_regions)} ä¸ªåŸå§‹åŒºåŸŸï¼Œå¼€å§‹æ‰§è¡Œæ™ºèƒ½è¡Œèšåˆ...")
                
                if not all_raw_regions:
                    regions_to_optimize = []
                else:
                    # 2a. å…¨å±€æ’åº
                    all_raw_regions.sort(key=lambda r: (cv2.boundingRect(r.astype(np.int32))[1], 
                                                        cv2.boundingRect(r.astype(np.int32))[0]))
                    
                    # 2b. åŠ¨æ€è¡Œèšç±»
                    lines = [[all_raw_regions[0]]]
                    for i in range(1, len(all_raw_regions)):
                        current_region = all_raw_regions[i]
                        last_line = lines[-1]
                        
                        line_y_centers = [cv2.minAreaRect(r.astype(np.int32))[0][1] for r in last_line]
                        line_heights = [min(cv2.minAreaRect(r.astype(np.int32))[1]) for r in last_line]
                        
                        avg_line_y = np.mean(line_y_centers)
                        avg_line_h = np.mean(line_heights) if line_heights else 1

                        curr_cy = cv2.minAreaRect(current_region.astype(np.int32))[0][1]
                        
                        if abs(curr_cy - avg_line_y) < avg_line_h * 0.7:
                            last_line.append(current_region)
                        else:
                            lines.append([current_region])
                
                    # 2c. ã€é©å‘½æ€§æ”¹å˜ã€‘å¯¹æ¯ä¸ªèšç±»å¥½çš„è¡Œï¼Œè¿›è¡Œæ•´ä½“èšåˆ
                    merged_lines = []
                    for line_regions in lines:
                        # è°ƒç”¨å…¨æ–°çš„ã€æ›´å¼ºå¤§çš„èšåˆå‡½æ•°
                        aggregated_line = self._aggregate_line_fragments(line_regions)
                        merged_lines.extend(aggregated_line)
                    
                    regions_to_optimize = merged_lines
                    logger.info(f"æ™ºèƒ½è¡Œèšåˆå®Œæˆï¼ŒåŒºåŸŸæ•°ä» {len(all_raw_regions)} èšåˆä¸º {len(regions_to_optimize)}ã€‚")
            else:
                logger.info("æ™ºèƒ½è¡Œèšåˆæœªå¯ç”¨ï¼Œå°†ç›´æ¥ä¼˜åŒ–åŸå§‹åŒºåŸŸã€‚")
                regions_to_optimize = all_raw_regions

            # æ­¥éª¤ 3: æœ€ç»ˆä¼˜åŒ–
            final_regions = self._optimize_text_regions(regions_to_optimize, gray.shape)
            final_regions = self._sort_regions_by_reading_order(final_regions)
            
            # æ­¥éª¤ 4: æ•´ç†å…ƒæ•°æ®å¹¶è¿”å›
            processing_time = time.time() - start_time
            
            metadata = {
                'processing_time': processing_time,
                'detection_mode': 'custom_combination',
                'algorithms_used': methods_used,
                'total_regions': len(final_regions),
                'raw_regions_count': len(all_raw_regions),
            }
            if self.config.get('enable_smart_line_merge', True):
                metadata['merged_regions_count'] = len(regions_to_optimize)
            
            self._manage_segmentation_cache(cache_key, {'regions': final_regions, 'metadata': metadata})
            logger.info(f"é«˜çº§æ–‡æœ¬æ£€æµ‹å®Œæˆ: {len(final_regions)}ä¸ªåŒºåŸŸ, è€—æ—¶: {processing_time:.3f}ç§’, ä½¿ç”¨ç®—æ³•: {methods_used}")
            
            return final_regions, metadata
            
        except Exception as e:
            logger.error(f"é«˜çº§æ–‡æœ¬åŒºåŸŸæ£€æµ‹å¤±è´¥: {e}", exc_info=True)
            return [], {'error': str(e)}
    def _simple_high_contrast_detection(self, gray: np.ndarray) -> List[np.ndarray]:
        """
        ä¸€ä¸ªç®€å•é«˜æ•ˆçš„æ£€æµ‹æ–¹æ³•ï¼Œä¸“é—¨ç”¨äºå¤„ç†é«˜å¯¹æ¯”åº¦ã€ä½å™ªå£°çš„å›¾åƒã€‚(V2 - å¢å¼ºç‰ˆ)
        - å¢åŠ äº®åº¦å‡åŒ€åŒ–é¢„å¤„ç†ï¼Œä»¥åº”å¯¹è½»å¾®çš„å…‰ç…§ä¸å‡ã€‚
        - å¢åŠ åŸºäºâ€œå®å¿ƒåº¦â€çš„è½®å»“åè¿‡æ»¤ï¼Œä»¥æ’é™¤éæ–‡æœ¬çš„å™ªå£°ã€‚
        """
        try:
            regions = []
            
            # --- æ–°å¢ï¼šäº®åº¦å‡åŒ€åŒ– ---
            # ä½¿ç”¨ä¸€ä¸ªå¤§æ ¸çš„æ¨¡ç³Šæ¥ä¼°è®¡èƒŒæ™¯å…‰ç…§
            blurred = cv2.GaussianBlur(gray, (55, 55), 0)
            # ä»åŸå›¾ä¸­é™¤ä»¥èƒŒæ™¯ï¼Œè¿›è¡Œå…‰ç…§è¡¥å¿
            # æ·»åŠ ä¸€ä¸ªå°çš„epsiloné˜²æ­¢é™¤ä»¥é›¶
            uniform_gray = (gray / (blurred + 1e-5)) * np.mean(blurred)
            uniform_gray = cv2.normalize(uniform_gray, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

            # ä½¿ç”¨Otsuæ–¹æ³•è¿›è¡Œå…¨å±€äºŒå€¼åŒ–
            _, binary = cv2.threshold(uniform_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
            # æŸ¥æ‰¾å¤–éƒ¨è½®å»“
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            img_h, img_w = gray.shape
            
            for contour in contours:
                area = cv2.contourArea(contour)
                x, y, w, h = cv2.boundingRect(contour)

                if (area > self.config['min_text_size']) and \
                   (w < img_w * 0.95 and h < img_h * 0.95):
                    
                    aspect_ratio = w / h if h > 0 else 0
                    if 0.01 < aspect_ratio < 100:
                        
                        # --- æ–°å¢ï¼šåŸºäºå®å¿ƒåº¦çš„è¿‡æ»¤ ---
                        hull = cv2.convexHull(contour)
                        hull_area = cv2.contourArea(hull)
                        solidity = float(area) / (hull_area + 1e-6)
                        
                        # æ–‡æœ¬è½®å»“é€šå¸¸æ¯”è¾ƒâ€œå®å¿ƒâ€ï¼Œè€Œå™ªç‚¹åˆ™å½¢çŠ¶ä¸è§„åˆ™
                        if solidity > 0.4:
                            rect = cv2.minAreaRect(contour)
                            box = cv2.boxPoints(rect)
                            regions.append(box.astype(np.float32))

            logger.info(f"ç®€å•é«˜å¯¹æ¯”åº¦æ£€æµ‹å®Œæˆï¼Œæ‰¾åˆ° {len(regions)} ä¸ªå€™é€‰åŒºåŸŸã€‚")
            return regions
            
        except Exception as e:
            logger.error(f"ç®€å•é«˜å¯¹æ¯”åº¦æ£€æµ‹å¤±è´¥: {e}")
            return []
    def _improved_mser_detection(self, gray: np.ndarray) -> List[np.ndarray]:
        """
        æ”¹è¿›çš„MSERæ£€æµ‹ (V3 - APIå…¼å®¹æœ€ç»ˆç‰ˆ)
        - é‡‡ç”¨åˆ›å»ºå®ä¾‹åé€ä¸€è®¾ç½®å‚æ•°çš„æ–¹å¼ï¼Œå½»åº•è§£å†³å„OpenCVç‰ˆæœ¬é—´çš„å…³é”®å­—å‚æ•°å…¼å®¹æ€§é—®é¢˜ã€‚
        - ä¿ç•™äº†åŠ¨æ€Deltaã€åŒå‘æ£€æµ‹å’ŒNMSç­‰æ‰€æœ‰å¢å¼ºåŠŸèƒ½ã€‚
        """
        try:
            all_regions_with_scores = []
            
            contrast_std = np.std(gray)
            delta = int(max(2, min(10, 5.0 * (contrast_std / 128.0))))
            logger.debug(f"MSERåŠ¨æ€Deltaè®¾ç½®ä¸º: {delta} (åŸºäºå›¾åƒæ ‡å‡†å·®: {contrast_std:.2f})")

            for image_pass in [gray, cv2.bitwise_not(gray)]:
                try:
                    # --- æ ¸å¿ƒä¿®æ­£ï¼šé‡‡ç”¨ Setter æ–¹æ³•é…ç½® MSER ---
                    # 1. åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„ MSER å¯¹è±¡
                    mser = cv2.MSER_create()
                    
                    # 2. é€ä¸€è°ƒç”¨ setter æ–¹æ³•æ¥è®¾ç½®å‚æ•°
                    mser.setDelta(delta)
                    mser.setMinArea(30)
                    mser.setMaxArea(14400)
                    mser.setMaxVariation(0.25)
                    mser.setMinDiversity(0.2)
                    # --- ä¿®æ­£ç»“æŸ ---
                    
                    mser_regions, _ = mser.detectRegions(image_pass)
                    
                    for region in mser_regions:
                        hull = cv2.convexHull(region.reshape(-1, 1, 2))
                        rect = cv2.minAreaRect(hull)
                        box = cv2.boxPoints(rect)
                        
                        if self._validate_text_region(box, gray):
                            score = cv2.contourArea(box)
                            all_regions_with_scores.append((box, score))

                except Exception as e:
                    logger.warning(f"MSERåˆ›å»ºæˆ–æ£€æµ‹å¤±è´¥: {e}")

            if not all_regions_with_scores:
                return []

            boxes = [item[0] for item in all_regions_with_scores]
            scores = [item[1] for item in all_regions_with_scores]
            rects_for_nms = [cv2.boundingRect(box.astype(np.int32)) for box in boxes]
            
            indices = cv2.dnn.NMSBoxes(rects_for_nms, scores, score_threshold=0.1, nms_threshold=0.3)
            
            final_regions = []
            if len(indices) > 0:
                for i in indices.flatten():
                    final_regions.append(boxes[i].astype(np.float32))
            
            return final_regions
            
        except Exception as e:
            logger.error(f"æ”¹è¿›MSERæ£€æµ‹å¤±è´¥: {e}")
            return []
    
    
    def _multiscale_contour_detection(self, gray: np.ndarray) -> List[np.ndarray]:
        """
        å¤šå°ºåº¦è½®å»“æ£€æµ‹ (V2 - å¢å¼ºç‰ˆ)
        - ä½¿ç”¨å¤šæ–¹å‘å½¢æ€å­¦æ ¸ï¼ˆæ°´å¹³ã€å‚ç›´ã€æ–¹å½¢ï¼‰ï¼Œä»¥é€‚åº”ä¸åŒæ–¹å‘çš„æ–‡æœ¬ã€‚
        - å½¢æ€å­¦æ ¸çš„å¤§å°ä¸å½“å‰å¤„ç†çš„å›¾åƒå°ºåº¦åŠ¨æ€å…³è”ã€‚
        - å¢åŠ è½®å»“å±‚çº§åˆ†æï¼Œä»¥è¿‡æ»¤æ‰å†…éƒ¨å­”æ´ç­‰éæ–‡æœ¬è½®å»“ã€‚
        """
        try:
            regions = []
            scales = [0.8, 1.0, 1.2, 1.5]
            
            for scale in scales:
                if scale != 1.0:
                    h, w = gray.shape
                    new_h, new_w = int(h * scale), int(w * scale)
                    scaled_gray = cv2.resize(gray, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                else:
                    scaled_gray = gray
                
                for threshold_size in self.config['adaptive_threshold_sizes']:
                    try:
                        binary = cv2.adaptiveThreshold(
                            scaled_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                            cv2.THRESH_BINARY_INV, threshold_size, 2
                        )
                        
                        # --- æ–°å¢ï¼šå¤šæ–¹å‘å’Œè‡ªé€‚åº”å¤§å°çš„å½¢æ€å­¦æ ¸ ---
                        # æ ¸çš„å¤§å°æ ¹æ®å½“å‰å›¾åƒç¼©æ”¾æ¯”ä¾‹è°ƒæ•´
                        base_kernel_w = max(3, int(5 * scale))
                        base_kernel_h = max(3, int(5 * scale))
                        
                        kernels = [
                            cv2.getStructuringElement(cv2.MORPH_RECT, (base_kernel_w, 1)), # æ°´å¹³
                            cv2.getStructuringElement(cv2.MORPH_RECT, (1, base_kernel_h)), # å‚ç›´
                            cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))              # æ–¹å½¢
                        ]
                        
                        merged_morph = np.zeros_like(binary)
                        for kernel in kernels:
                            processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, 
                                                       iterations=self.config['morphology_iterations'])
                            # å°†ä¸åŒæ–¹å‘å¤„ç†çš„ç»“æœåˆå¹¶
                            merged_morph = cv2.bitwise_or(merged_morph, processed)

                        # --- æ–°å¢ï¼šä½¿ç”¨è½®å»“å±‚çº§åˆ†æ ---
                        # RETR_CCOMP æŸ¥æ‰¾æ‰€æœ‰è½®å»“å¹¶ç»„ç»‡æˆä¸¤å±‚ï¼šå¤–éƒ¨å’Œå†…éƒ¨ï¼ˆå­”æ´ï¼‰
                        contours, hierarchy = cv2.findContours(merged_morph, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
                        
                        if hierarchy is None: continue

                        # åªå¤„ç†å¤–éƒ¨è½®å»“ (hierarchy[0][i][3] == -1 è¡¨ç¤ºæ²¡æœ‰çˆ¶è½®å»“)
                        for i, contour in enumerate(contours):
                            if hierarchy[0][i][3] == -1:
                                area = cv2.contourArea(contour)
                                if area > self.config['connected_component_min_area']:
                                    rect = cv2.minAreaRect(contour)
                                    box = cv2.boxPoints(rect)
                                    
                                    if scale != 1.0:
                                        box = box / scale
                                    
                                    regions.append(box.astype(np.float32))
                                    
                    except Exception as e:
                        logger.warning(f"é˜ˆå€¼{threshold_size}å¤„ç†å¤±è´¥: {e}")
                        continue
            
            return regions
            
        except Exception as e:
            logger.error(f"å¤šå°ºåº¦è½®å»“æ£€æµ‹å¤±è´¥: {e}")
            return []
    def _gradient_based_detection(self, gray: np.ndarray) -> List[np.ndarray]:
        """
        åŸºäºæ¢¯åº¦çš„æ–‡æœ¬æ£€æµ‹ (V2 - å¢å¼ºç‰ˆ)
        - ä½¿ç”¨æ›´ç²¾ç¡®çš„ Scharr ç®—å­ä»£æ›¿ Sobelã€‚
        - å¼•å…¥æ¢¯åº¦æ–¹å‘ä¿¡æ¯ï¼Œè¿‡æ»¤æ‰å†…éƒ¨æ¢¯åº¦æ–¹å‘æ··ä¹±çš„éæ–‡æœ¬åŒºåŸŸã€‚
        """
        try:
            regions = []
            
            # --- æ”¹è¿›ï¼šä½¿ç”¨ Scharr ç®—å­ ---
            grad_x = cv2.Scharr(gray, cv2.CV_64F, 1, 0)
            grad_y = cv2.Scharr(gray, cv2.CV_64F, 0, 1)
            
            magnitude = np.sqrt(grad_x**2 + grad_y**2)
            # æ¢¯åº¦æ–¹å‘ï¼Œå•ä½ä¸ºåº¦
            angle = np.arctan2(grad_y, grad_x) * (180 / np.pi)
            
            magnitude_norm = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
            
            _, binary = cv2.threshold(magnitude_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            kernel_horizontal = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 1))
            kernel_vertical = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 5))
            
            horizontal = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_horizontal)
            vertical = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_vertical)
            
            combined = cv2.bitwise_or(horizontal, vertical)
            
            contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > self.config['min_text_size'] ** 2:
                    rect = cv2.minAreaRect(contour)
                    box = cv2.boxPoints(rect)
                    
                    # --- æ–°å¢ï¼šä½¿ç”¨æ¢¯åº¦æ–¹å‘è¿›è¡ŒéªŒè¯ ---
                    # æ–‡æœ¬åŒºåŸŸå†…éƒ¨çš„æ¢¯åº¦æ–¹å‘åº”è¯¥æ¯”è¾ƒé›†ä¸­
                    mask = np.zeros_like(gray, dtype=np.uint8)
                    cv2.fillPoly(mask, [box.astype(np.int32)], 255)
                    
                    # æå–åŒºåŸŸå†…çš„æ¢¯åº¦æ–¹å‘
                    region_angles = angle[mask > 0]
                    if len(region_angles) > 10: # è‡³å°‘éœ€è¦10ä¸ªç‚¹æ‰æœ‰ç»Ÿè®¡æ„ä¹‰
                        # è®¡ç®—æ¢¯åº¦æ–¹å‘çš„æ ‡å‡†å·®ï¼Œå€¼è¶Šå°è¯´æ˜æ–¹å‘è¶Šä¸€è‡´
                        angle_std = np.std(region_angles)
                        # æ–‡æœ¬åŒºåŸŸçš„æ¢¯åº¦æ–¹å‘æ ‡å‡†å·®é€šå¸¸è¾ƒå°
                        if angle_std < 45: # é˜ˆå€¼å¯è°ƒ
                            regions.append(box.astype(np.float32))
            
            return regions
            
        except Exception as e:
            logger.error(f"æ¢¯åº¦æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _stroke_width_transform_detection(self, gray: np.ndarray) -> Tuple[List[np.ndarray], Dict]:
        """
        ç¬”ç”»å®½åº¦å˜æ¢æ£€æµ‹ (V2 - å¢å¼ºç‰ˆ)
        - å®ç°åŒå‘è¿½è¸ªä»¥è·å¾—æ›´å‡†ç¡®çš„ç¬”ç”»å®½åº¦ã€‚
        - å¯¹ç”Ÿæˆçš„SWTå›¾åƒè¿›è¡Œä¸­å€¼æ»¤æ³¢åå¤„ç†ã€‚
        - å¢åŠ ä¸€ä¸ªç®€å•çš„å­—ç¬¦ç»„ä»¶åˆå¹¶æ­¥éª¤ã€‚
        """
        try:
            # å¼•å…¥ä¸€ä¸ªå†…éƒ¨çš„ SWT è¿½è¸ªå‡½æ•°
            def trace_stroke(x, y, grad_x, grad_y, edges, max_len=50):
                points = []
                # æ²¿æ¢¯åº¦æ–¹å‘è¿½è¸ª
                for i in range(1, max_len):
                    nx = int(x + grad_x * i)
                    ny = int(y + grad_y * i)
                    if not (0 <= nx < edges.shape[1] and 0 <= ny < edges.shape[0]):
                        break
                    points.append((nx, ny))
                    if edges[ny, nx] > 0:
                        # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å¤§è‡´ç›¸å
                        g_nx, g_ny = grad_x_norm[ny, nx], grad_y_norm[ny, nx]
                        if np.dot([grad_x, grad_y], [g_nx, g_ny]) < -0.8:
                            return points
                return None

            edges = cv2.Canny(gray, 50, 150)
            grad_x = cv2.Sobel(gray.astype(np.float32), cv2.CV_32F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray.astype(np.float32), cv2.CV_32F, 0, 1, ksize=3)
            magnitude = np.sqrt(grad_x**2 + grad_y**2)
            grad_x_norm = grad_x / (magnitude + 1e-9)
            grad_y_norm = grad_y / (magnitude + 1e-9)

            swt = np.full(gray.shape, np.inf, dtype=np.float32)
            rays = []
            
            # å¯»æ‰¾è¾¹ç¼˜ç‚¹å¹¶è¿½è¸ª
            edge_coords = np.argwhere(edges > 0)
            for y, x in edge_coords:
                gx, gy = grad_x_norm[y, x], grad_y_norm[y, x]
                ray = trace_stroke(x, y, gx, gy, edges)
                if ray:
                    stroke_width = np.linalg.norm(np.array(ray[-1]) - np.array((x,y)))
                    for p in ray:
                        swt[p[1], p[0]] = min(swt[p[1], p[0]], stroke_width)
                    rays.append(ray)

            # SWT åå¤„ç†
            swt[swt == np.inf] = 0
            swt_norm = cv2.normalize(swt, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
            _, swt_binary = cv2.threshold(swt_norm, 1, 255, cv2.THRESH_BINARY)
            
            # --- æ–°å¢ï¼šä¸­å€¼æ»¤æ³¢å¹³æ»‘SWTå›¾ ---
            swt_binary = cv2.medianBlur(swt_binary, 3)

            num_labels, labels, stats_cc, _ = cv2.connectedComponentsWithStats(swt_binary)

            # --- æ–°å¢ï¼šç®€å•çš„å­—ç¬¦ç»„ä»¶åˆå¹¶ ---
            char_boxes = []
            for i in range(1, num_labels):
                if stats_cc[i, cv2.CC_STAT_AREA] > self.config['connected_component_min_area']:
                    x, y, w, h = stats_cc[i, cv2.CC_STAT_LEFT], stats_cc[i, cv2.CC_STAT_TOP], \
                                 stats_cc[i, cv2.CC_STAT_WIDTH], stats_cc[i, cv2.CC_STAT_HEIGHT]
                    if 0.1 < w/h < 10 and h > 8:
                        char_boxes.append([x, y, x+w, y+h])

            # æ°´å¹³åˆå¹¶å­—ç¬¦æ¡†
            def merge_boxes(boxes):
                if not boxes: return []
                boxes.sort(key=lambda b: b[0])
                merged = [boxes[0]]
                for box in boxes[1:]:
                    last = merged[-1]
                    # å¦‚æœå‚ç›´é‡å ä¸”æ°´å¹³æ¥è¿‘ï¼Œåˆ™åˆå¹¶
                    if (box[1] < last[3] and box[3] > last[1]) and \
                       (box[0] - last[2] < (last[3] - last[1])): # é—´è·å°äºé«˜åº¦
                        last[2] = max(last[2], box[2])
                        last[3] = max(last[3], box[3])
                        last[1] = min(last[1], box[1])
                    else:
                        merged.append(box)
                return merged

            merged_box_coords = merge_boxes(char_boxes)
            final_regions = []
            for box in merged_box_coords:
                x1, y1, x2, y2 = box
                final_regions.append(np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype=np.float32))

            return final_regions, {'swt_rays': len(rays)}

        except Exception as e:
            logger.error(f"SWTæ£€æµ‹å¤±è´¥: {e}", exc_info=True)
            return [], {'error': str(e)}
    
    def _trace_stroke_width(self, edges: np.ndarray, gradient_direction: np.ndarray, 
                           start_x: int, start_y: int, direction: float, shape: Tuple[int, int]) -> float:
        """è¿½è¸ªç¬”ç”»å®½åº¦"""
        try:
            h, w = shape
            x, y = start_x, start_y
            dx, dy = np.cos(direction), np.sin(direction)
            
            distance = 0
            max_distance = 100  # æœ€å¤§è¿½è¸ªè·ç¦»
            
            while distance < max_distance:
                x += dx
                y += dy
                distance += 1
                
                # æ£€æŸ¥è¾¹ç•Œ
                if x < 0 or x >= w or y < 0 or y >= h:
                    break
                
                xi, yi = int(round(x)), int(round(y))
                
                # å¦‚æœé‡åˆ°å¦ä¸€ä¸ªè¾¹ç¼˜ç‚¹
                if edges[yi, xi] > 0:
                    # æ£€æŸ¥æ¢¯åº¦æ–¹å‘æ˜¯å¦ç›¸å
                    opposite_direction = gradient_direction[yi, xi]
                    angle_diff = abs(direction - opposite_direction)
                    
                    if angle_diff > np.pi / 2 and angle_diff < 3 * np.pi / 2:
                        return distance
            
            return -1  # æœªæ‰¾åˆ°åŒ¹é…çš„è¾¹ç¼˜
            
        except Exception:
            return -1
    
    def _validate_stroke_consistency(self, box: np.ndarray, swt: np.ndarray) -> bool:
        """éªŒè¯ç¬”ç”»å®½åº¦ä¸€è‡´æ€§"""
        try:
            # åˆ›å»ºåŒºåŸŸæ©è†œ
            mask = np.zeros(swt.shape, dtype=np.uint8)
            cv2.fillPoly(mask, [box.astype(np.int32)], 255)
            
            # æå–åŒºåŸŸå†…çš„ç¬”ç”»å®½åº¦å€¼
            region_swt = swt[mask > 0]
            valid_swt = region_swt[region_swt < np.inf]
            
            if len(valid_swt) < 5:  # å¤ªå°‘çš„æœ‰æ•ˆç¬”ç”»ç‚¹
                return False
            
            # è®¡ç®—ç¬”ç”»å®½åº¦çš„å˜å¼‚ç³»æ•°
            mean_stroke = np.mean(valid_swt)
            std_stroke = np.std(valid_swt)
            
            if mean_stroke == 0:
                return False
            
            cv = std_stroke / mean_stroke
            
            # ç¬”ç”»å®½åº¦åº”è¯¥ç›¸å¯¹ä¸€è‡´
            return cv < 0.8  # å˜å¼‚ç³»æ•°å°äº0.8
            
        except Exception:
            return False
    
    def _connected_component_analysis(self, gray: np.ndarray) -> Tuple[List[np.ndarray], Dict]:
        """
        è¿é€šåˆ†é‡åˆ†æ (V2 - å¢å¼ºç‰ˆ)
        - å¢åŠ æ–­è£‚å­—ç¬¦åˆå¹¶é€»è¾‘ï¼ˆå¦‚åˆå¹¶ 'i' çš„ç‚¹å’Œæ ï¼‰ã€‚
        - å¢åŠ ç²˜è¿å­—ç¬¦åˆ†å‰²çš„åˆæ­¥å°è¯•ï¼ˆåŸºäºå½¢æ€å­¦ï¼‰ã€‚
        """
        try:
            regions = []
            stats = {'total_components': 0, 'valid_components': 0, 'merged': 0, 'split': 0}
            
            binary_methods = [
                lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2),
                lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
            ]
            
            all_components = []
            for binary_method in binary_methods:
                try:
                    binary = binary_method(gray)
                    
                    # --- æ–°å¢ï¼šå°è¯•åˆ†å‰²ç²˜è¿å­—ç¬¦ ---
                    # ä½¿ç”¨å½¢æ€å­¦å¼€è¿ç®—æ¥æ–­å¼€ç»†å°çš„è¿æ¥
                    kernel = np.ones((3,1), np.uint8)
                    binary_split = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
                    
                    num_labels, _, stats_cc, centroids = cv2.connectedComponentsWithStats(binary_split, connectivity=8)
                    stats['total_components'] += num_labels - 1
                    
                    for i in range(1, num_labels):
                        area, w, h = stats_cc[i, cv2.CC_STAT_AREA], stats_cc[i, cv2.CC_STAT_WIDTH], stats_cc[i, cv2.CC_STAT_HEIGHT]
                        if (area > self.config['connected_component_min_area'] and 
                            self.config['char_min_width'] <= w <= self.config['char_max_width'] and
                            self.config['char_min_height'] <= h <= self.config['char_max_height']):
                            
                            x, y = stats_cc[i, cv2.CC_STAT_LEFT], stats_cc[i, cv2.CC_STAT_TOP]
                            all_components.append({'bbox': [x, y, x+w, y+h], 'centroid': centroids[i]})
                            stats['valid_components'] += 1

                except Exception as e:
                    logger.warning(f"è¿é€šåˆ†é‡æ–¹æ³•å¤±è´¥: {e}")
                    continue
            
            # --- æ–°å¢ï¼šæ–­è£‚å­—ç¬¦åˆå¹¶é€»è¾‘ ---
            if not all_components: return [], stats
            
            merged_components = []
            all_components.sort(key=lambda c: (c['bbox'][1], c['bbox'][0])) # ä»ä¸Šåˆ°ä¸‹ï¼Œä»å·¦åˆ°å³æ’åº
            used = [False] * len(all_components)

            for i in range(len(all_components)):
                if used[i]: continue
                
                comp1 = all_components[i]
                bbox1 = comp1['bbox']
                merged_bbox = list(bbox1)
                
                for j in range(i + 1, len(all_components)):
                    if used[j]: continue
                    comp2 = all_components[j]
                    bbox2 = comp2['bbox']

                    # æ£€æŸ¥æ˜¯å¦å‚ç›´å¯¹é½ä¸”è¶³å¤Ÿè¿‘ (åˆå¹¶ 'i' çš„ç‚¹)
                    is_vertically_aligned = abs(comp1['centroid'][0] - comp2['centroid'][0]) < (bbox1[2] - bbox1[0])
                    vertical_gap = bbox2[1] - bbox1[3]
                    is_close = 0 <= vertical_gap < (bbox1[3] - bbox1[1]) * 0.5

                    if is_vertically_aligned and is_close:
                        # åˆå¹¶bbox
                        merged_bbox[0] = min(merged_bbox[0], bbox2[0])
                        merged_bbox[1] = min(merged_bbox[1], bbox2[1])
                        merged_bbox[2] = max(merged_bbox[2], bbox2[2])
                        merged_bbox[3] = max(merged_bbox[3], bbox2[3])
                        used[j] = True
                        stats['merged'] += 1
                
                merged_components.append(merged_bbox)

            for bbox in merged_components:
                x1, y1, x2, y2 = bbox
                box = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype=np.float32)
                regions.append(box)

            return regions, stats
            
        except Exception as e:
            logger.error(f"è¿é€šåˆ†é‡åˆ†æå¤±è´¥: {e}")
            return [], {'error': str(e)}
    
    def _validate_component_shape(self, box: np.ndarray, mask: np.ndarray) -> bool:
        """éªŒè¯è¿é€šåˆ†é‡å½¢çŠ¶"""
        try:
            # è®¡ç®—è¾¹ç•Œæ¡†
            x_coords = box[:, 0]
            y_coords = box[:, 1]
            width = np.max(x_coords) - np.min(x_coords)
            height = np.max(y_coords) - np.min(y_coords)
            
            if width <= 0 or height <= 0:
                return False
            
            # æ£€æŸ¥å®½é«˜æ¯”
            aspect_ratio = width / height
            if not (self.config['char_aspect_ratio_min'] <= aspect_ratio <= self.config['char_aspect_ratio_max']):
                return False
            
            # è®¡ç®—å¡«å……æ¯”ä¾‹
            box_area = width * height
            mask_roi = mask[int(np.min(y_coords)):int(np.max(y_coords))+1, 
                           int(np.min(x_coords)):int(np.max(x_coords))+1]
            
            if mask_roi.size == 0:
                return False
            
            filled_pixels = np.sum(mask_roi > 0)
            fill_ratio = filled_pixels / box_area
            
            return fill_ratio >= self.config['min_fill_ratio']
            
        except Exception:
            return False
    
    def _character_level_detection(self, gray: np.ndarray) -> Tuple[List[np.ndarray], Dict]:
        """
        å­—ç¬¦çº§æ£€æµ‹ (V2 - å¢å¼ºç‰ˆ)
        - ä½¿ç”¨è·ç¦»å˜æ¢ + åˆ†æ°´å²­ç®—æ³•ä»£æ›¿é²æ£’æ€§å·®çš„å‚ç›´æŠ•å½±æ³•ã€‚
        - èƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šå¤„ç†å€¾æ–œå’Œç²˜è¿çš„å­—ç¬¦ã€‚
        """
        try:
            stats = {'char_candidates': 0, 'valid_chars': 0}
            
            # 1. é¢„å¤„ç†
            binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                           cv2.THRESH_BINARY_INV, 15, 4)
            
            # ç§»é™¤å°çš„å™ªå£°
            kernel = np.ones((2,2), np.uint8)
            opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)
            
            # ç¡®å®šèƒŒæ™¯åŒºåŸŸ
            sure_bg = cv2.dilate(opening, kernel, iterations=3)

            # 2. è·ç¦»å˜æ¢
            dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
            # å½’ä¸€åŒ–ä»¥æ–¹ä¾¿è®¾ç½®é˜ˆå€¼
            cv2.normalize(dist_transform, dist_transform, 0, 1.0, cv2.NORM_MINMAX)
            
            # ç¡®å®šå‰æ™¯åŒºåŸŸï¼ˆå­—ç¬¦çš„æ ¸å¿ƒï¼‰
            # è·ç¦»å˜æ¢å›¾ä¸­å€¼è¶Šå¤§çš„ç‚¹ï¼Œè¶Šæ˜¯å­—ç¬¦çš„ä¸­å¿ƒ
            _, sure_fg = cv2.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)
            sure_fg = np.uint8(sure_fg)

            # æ‰¾åˆ°æœªçŸ¥åŒºåŸŸï¼ˆå¯èƒ½æ˜¯å­—ç¬¦è¾¹ç•Œï¼‰
            unknown = cv2.subtract(sure_bg, sure_fg)

            # 3. è¿é€šåˆ†é‡æ ‡è®°
            # sure_fg é‡Œçš„æ¯ä¸ªè¿é€šåŒºåŸŸéƒ½æ˜¯ä¸€ä¸ªå­—ç¬¦çš„æ ¸å¿ƒ
            num_labels, markers = cv2.connectedComponents(sure_fg)
            # å°†èƒŒæ™¯æ ‡è®°ä¸º0
            markers = markers + 1
            # å°†æœªçŸ¥åŒºåŸŸæ ‡è®°ä¸º0ï¼Œè¿™æ ·åˆ†æ°´å²­ç®—æ³•å°±ä¼šåœ¨è¿™é‡Œç”»å‡ºè¾¹ç•Œ
            markers[unknown == 255] = 0
            
            # 4. åˆ†æ°´å²­ç®—æ³•
            # åˆ†æ°´å²­ç®—æ³•éœ€è¦ä¸€ä¸ª3é€šé“å›¾åƒ
            gray_3channel = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
            markers = cv2.watershed(gray_3channel, markers)

            # 5. æå–åˆ†å‰²åçš„å­—ç¬¦åŒºåŸŸ
            final_regions = []
            for label in np.unique(markers):
                # -1æ˜¯è¾¹ç•Œï¼Œ1æ˜¯èƒŒæ™¯
                if label <= 1: continue

                # åˆ›å»ºä¸€ä¸ªåªåŒ…å«å½“å‰å­—ç¬¦çš„æ©ç 
                mask = np.zeros(gray.shape, dtype="uint8")
                mask[markers == label] = 255
                
                # æŸ¥æ‰¾è¯¥å­—ç¬¦çš„è½®å»“
                contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    # ä½¿ç”¨æœ€å°å¤–æ¥çŸ©å½¢ä½œä¸ºè¾¹ç•Œæ¡†
                    contour = max(contours, key=cv2.contourArea)
                    rect = cv2.minAreaRect(contour)
                    box = cv2.boxPoints(rect)
                    
                    if self._validate_character_region(box, gray):
                        final_regions.append(box.astype(np.float32))
                        stats['valid_chars'] += 1

            return final_regions, stats
            
        except Exception as e:
            logger.error(f"å­—ç¬¦çº§æ£€æµ‹å¤±è´¥: {e}", exc_info=True)
            return [], {'error': str(e)}
    
    def _separate_characters(self, gray: np.ndarray) -> List[np.ndarray]:
        """åˆ†ç¦»å•ä¸ªå­—ç¬¦"""
        try:
            regions = []
            
            # è‡ªé€‚åº”é˜ˆå€¼
            binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                         cv2.THRESH_BINARY_INV, 11, 2)
            
            # å‚ç›´æŠ•å½±åˆ†æ
            vertical_projection = np.sum(binary, axis=0)
            
            # æŸ¥æ‰¾å­—ç¬¦åˆ†ç•Œç‚¹
            separation_points = []
            in_char = False
            char_start = 0
            
            min_char_width = self.config['char_min_width']
            
            for i, projection in enumerate(vertical_projection):
                if projection > 0 and not in_char:
                    # å­—ç¬¦å¼€å§‹
                    char_start = i
                    in_char = True
                elif projection == 0 and in_char:
                    # å­—ç¬¦ç»“æŸ
                    char_width = i - char_start
                    if char_width >= min_char_width:
                        separation_points.append((char_start, i))
                    in_char = False
            
            # å¤„ç†æœ€åä¸€ä¸ªå­—ç¬¦
            if in_char and len(vertical_projection) - char_start >= min_char_width:
                separation_points.append((char_start, len(vertical_projection)))
            
            # ä¸ºæ¯ä¸ªåˆ†ç¦»çš„å­—ç¬¦åˆ›å»ºè¾¹ç•Œæ¡†
            for start_x, end_x in separation_points:
                # åœ¨å­—ç¬¦åŒºåŸŸå†…è¿›è¡Œæ°´å¹³æŠ•å½±
                char_region = binary[:, start_x:end_x]
                horizontal_projection = np.sum(char_region, axis=1)
                
                # æŸ¥æ‰¾å­—ç¬¦çš„ä¸Šä¸‹è¾¹ç•Œ
                non_zero_rows = np.where(horizontal_projection > 0)[0]
                if len(non_zero_rows) > 0:
                    start_y = non_zero_rows[0]
                    end_y = non_zero_rows[-1] + 1
                    
                    # åˆ›å»ºå­—ç¬¦è¾¹ç•Œæ¡†
                    char_box = np.array([
                        [start_x, start_y],
                        [end_x, start_y],
                        [end_x, end_y],
                        [start_x, end_y]
                    ], dtype=np.float32)
                    
                    regions.append(char_box)
            
            return regions
            
        except Exception as e:
            logger.error(f"å­—ç¬¦åˆ†ç¦»å¤±è´¥: {e}")
            return []
    
    def _validate_character_region(self, box: np.ndarray, gray: np.ndarray) -> bool:
        """éªŒè¯å­—ç¬¦åŒºåŸŸ"""
        try:
            # è®¡ç®—å°ºå¯¸
            x_coords = box[:, 0]
            y_coords = box[:, 1]
            width = np.max(x_coords) - np.min(x_coords)
            height = np.max(y_coords) - np.min(y_coords)
            
            # å°ºå¯¸æ£€æŸ¥
            if (width < self.config['char_min_width'] or width > self.config['char_max_width'] or
                height < self.config['char_min_height'] or height > self.config['char_max_height']):
                return False
            
            # å®½é«˜æ¯”æ£€æŸ¥
            aspect_ratio = width / height if height > 0 else 0
            if not (self.config['char_aspect_ratio_min'] <= aspect_ratio <= self.config['char_aspect_ratio_max']):
                return False
            
            # å†…å®¹å¯†åº¦æ£€æŸ¥
            mask = np.zeros(gray.shape, dtype=np.uint8)
            cv2.fillPoly(mask, [box.astype(np.int32)], 255)
            
            # æå–åŒºåŸŸ
            roi = cv2.bitwise_and(gray, gray, mask=mask)
            non_zero_pixels = np.sum(roi > 0)
            total_pixels = np.sum(mask > 0)
            
            if total_pixels == 0:
                return False
            
            density = non_zero_pixels / total_pixels
            return density >= self.config['min_fill_ratio']
            
        except Exception:
            return False
    def _optimize_text_regions(self, regions: List[np.ndarray], image_shape: Tuple[int, int]) -> List[np.ndarray]:
        """ä¼˜åŒ–æ–‡æœ¬åŒºåŸŸ"""
        try:
            if not regions:
                return []
            
            # 1. åŸºæœ¬è¿‡æ»¤
            filtered_regions = []
            h, w = image_shape[:2]
            
            for region in regions:
                if self._is_valid_region_geometry(region, (w, h)):
                    filtered_regions.append(region)
            
            # 2. å»é‡å¤„ç†
            deduplicated_regions = self._remove_duplicate_regions(filtered_regions)
            
            # 3. é‡å å¤„ç†
            non_overlapping_regions = self._resolve_overlapping_regions(deduplicated_regions)
            
            # 4. è¾¹ç•Œä¼˜åŒ–
            boundary_optimized = self._optimize_region_boundaries(non_overlapping_regions, image_shape)
            
            return boundary_optimized
            
        except Exception as e:
            logger.error(f"åŒºåŸŸä¼˜åŒ–å¤±è´¥: {e}")
            return regions
    
    def _is_valid_region_geometry(self, region: np.ndarray, image_size: Tuple[int, int]) -> bool:
        """éªŒè¯åŒºåŸŸå‡ ä½•å½¢çŠ¶"""
        try:
            w, h = image_size
            
            # è®¡ç®—åŒºåŸŸå±æ€§
            x_coords = region[:, 0]
            y_coords = region[:, 1]
            
            min_x, max_x = np.min(x_coords), np.max(x_coords)
            min_y, max_y = np.min(y_coords), np.max(y_coords)
            
            width = max_x - min_x
            height = max_y - min_y
            area = width * height
            
            # åŸºæœ¬å°ºå¯¸æ£€æŸ¥
            if (width < self.config['min_text_size'] or height < self.config['min_text_size'] or
                width > w * 0.95 or height > h * 0.95):
                return False
            
            # é¢ç§¯æ£€æŸ¥
            if area < self.config['min_text_size'] ** 2 or area > (w * h * 0.8):
                return False
            
            # å®½é«˜æ¯”æ£€æŸ¥
            aspect_ratio = width / height if height > 0 else float('inf')
            if aspect_ratio < 0.05 or aspect_ratio > 20:
                return False
            
            # è¾¹ç•Œæ£€æŸ¥
            if min_x < 0 or min_y < 0 or max_x > w or max_y > h:
                return False
            
            return True
            
        except Exception:
            return False
    
    def _remove_duplicate_regions(self, regions: List[np.ndarray]) -> List[np.ndarray]:
        """ç§»é™¤é‡å¤åŒºåŸŸ"""
        try:
            if len(regions) <= 1:
                return regions
            
            unique_regions = []
            
            for i, region1 in enumerate(regions):
                is_duplicate = False
                
                for j, region2 in enumerate(unique_regions):
                    if self._calculate_region_similarity(region1, region2) > 0.9:
                        is_duplicate = True
                        break
                
                if not is_duplicate:
                    unique_regions.append(region1)
            
            return unique_regions
            
        except Exception as e:
            logger.error(f"å»é‡å¤±è´¥: {e}")
            return regions
    
    def _calculate_region_similarity(self, region1: np.ndarray, region2: np.ndarray) -> float:
        """è®¡ç®—åŒºåŸŸç›¸ä¼¼åº¦"""
        try:
            # è®¡ç®—IoU (Intersection over Union)
            def get_bbox(region):
                x_coords = region[:, 0]
                y_coords = region[:, 1]
                return np.min(x_coords), np.min(y_coords), np.max(x_coords), np.max(y_coords)
            
            x1_min, y1_min, x1_max, y1_max = get_bbox(region1)
            x2_min, y2_min, x2_max, y2_max = get_bbox(region2)
            
            # è®¡ç®—äº¤é›†
            intersection_x_min = max(x1_min, x2_min)
            intersection_y_min = max(y1_min, y2_min)
            intersection_x_max = min(x1_max, x2_max)
            intersection_y_max = min(y1_max, y2_max)
            
            if intersection_x_min >= intersection_x_max or intersection_y_min >= intersection_y_max:
                return 0.0
            
            intersection_area = (intersection_x_max - intersection_x_min) * (intersection_y_max - intersection_y_min)
            
            # è®¡ç®—å¹¶é›†
            area1 = (x1_max - x1_min) * (y1_max - y1_min)
            area2 = (x2_max - x2_min) * (y2_max - y2_min)
            union_area = area1 + area2 - intersection_area
            
            if union_area <= 0:
                return 0.0
            
            return intersection_area / union_area
            
        except Exception:
            return 0.0
    
    def _resolve_overlapping_regions(self, regions: List[np.ndarray]) -> List[np.ndarray]:
        """å¤„ç†é‡å åŒºåŸŸ"""
        try:
            if len(regions) <= 1:
                return regions
            
            resolved_regions = []
            region_groups = []
            
            # æ‰¾åˆ°é‡å çš„åŒºåŸŸç»„
            for region in regions:
                added_to_group = False
                
                for group in region_groups:
                    for group_region in group:
                        if self._calculate_region_similarity(region, group_region) > self.config['max_overlap_ratio']:
                            group.append(region)
                            added_to_group = True
                            break
                    if added_to_group:
                        break
                
                if not added_to_group:
                    region_groups.append([region])
            
            # å¤„ç†æ¯ä¸ªç»„
            for group in region_groups:
                if len(group) == 1:
                    resolved_regions.append(group[0])
                else:
                    # åˆå¹¶é‡å åŒºåŸŸ
                    merged_region = self._merge_region_group(group)
                    if merged_region is not None:
                        resolved_regions.append(merged_region)
            
            return resolved_regions
            
        except Exception as e:
            logger.error(f"é‡å åŒºåŸŸå¤„ç†å¤±è´¥: {e}")
            return regions
    
    def _merge_region_group(self, regions: List[np.ndarray]) -> Optional[np.ndarray]:
        """åˆå¹¶åŒºåŸŸç»„"""
        try:
            if not regions:
                return None
            
            if len(regions) == 1:
                return regions[0]
            
            # è®¡ç®—æ‰€æœ‰åŒºåŸŸçš„è¾¹ç•Œ
            all_x_coords = []
            all_y_coords = []
            
            for region in regions:
                all_x_coords.extend(region[:, 0])
                all_y_coords.extend(region[:, 1])
            
            # åˆ›å»ºåˆå¹¶åçš„è¾¹ç•Œæ¡†
            min_x, max_x = np.min(all_x_coords), np.max(all_x_coords)
            min_y, max_y = np.min(all_y_coords), np.max(all_y_coords)
            
            merged_region = np.array([
                [min_x, min_y],
                [max_x, min_y],
                [max_x, max_y],
                [min_x, max_y]
            ], dtype=np.float32)
            
            return merged_region
            
        except Exception:
            return None
    
    def _optimize_region_boundaries(self, regions: List[np.ndarray], image_shape: Tuple[int, int]) -> List[np.ndarray]:
        """ä¼˜åŒ–åŒºåŸŸè¾¹ç•Œ"""
        try:
            optimized_regions = []
            h, w = image_shape[:2]
            
            for region in regions:
                # æ·»åŠ è¾¹è·
                margin = self.config['add_margin']
                
                x_coords = region[:, 0]
                y_coords = region[:, 1]
                
                # è®¡ç®—å½“å‰è¾¹ç•Œ
                min_x, max_x = np.min(x_coords), np.max(x_coords)
                min_y, max_y = np.min(y_coords), np.max(y_coords)
                
                width = max_x - min_x
                height = max_y - min_y
                
                # æ·»åŠ è‡ªé€‚åº”è¾¹è·
                x_margin = width * margin
                y_margin = height * margin
                
                # åº”ç”¨è¾¹è·å¹¶ç¡®ä¿åœ¨å›¾åƒè¾¹ç•Œå†…
                new_min_x = max(0, min_x - x_margin)
                new_max_x = min(w, max_x + x_margin)
                new_min_y = max(0, min_y - y_margin)
                new_max_y = min(h, max_y + y_margin)
                
                # åˆ›å»ºä¼˜åŒ–åçš„åŒºåŸŸ
                optimized_region = np.array([
                    [new_min_x, new_min_y],
                    [new_max_x, new_min_y],
                    [new_max_x, new_max_y],
                    [new_min_x, new_max_y]
                ], dtype=np.float32)
                
                optimized_regions.append(optimized_region)
            
            return optimized_regions
            
        except Exception as e:
            logger.error(f"è¾¹ç•Œä¼˜åŒ–å¤±è´¥: {e}")
            return regions
    
    def _reorganize_text_lines(self, regions: List[np.ndarray], gray: np.ndarray) -> List[np.ndarray]:
        """é‡ç»„æ–‡æœ¬è¡Œ"""
        try:
            if not regions:
                return []
            
            # 1. æŒ‰Yåæ ‡æ’åºåŒºåŸŸ
            regions_with_y = [(region, np.mean(region[:, 1])) for region in regions]
            regions_with_y.sort(key=lambda x: x[1])
            
            # 2. åˆ†ç»„ç›¸è¿‘çš„Yåæ ‡åŒºåŸŸ
            line_groups = []
            current_group = []
            current_y = None
            
            height_threshold = self.config['text_line_merge_distance']
            
            for region, y_coord in regions_with_y:
                if current_y is None or abs(y_coord - current_y) <= height_threshold:
                    current_group.append(region)
                    current_y = y_coord if current_y is None else (current_y + y_coord) / 2
                else:
                    if current_group:
                        line_groups.append(current_group)
                    current_group = [region]
                    current_y = y_coord
            
            if current_group:
                line_groups.append(current_group)
            
            # 3. å¤„ç†æ¯ä¸ªè¡Œç»„
            reorganized_lines = []
            
            for group in line_groups:
                if len(group) == 1:
                    reorganized_lines.append(group[0])
                else:
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥åˆå¹¶ä¸ºä¸€è¡Œ
                    if self._should_merge_as_text_line(group, gray):
                        merged_line = self._merge_text_line(group)
                        if merged_line is not None:
                            reorganized_lines.append(merged_line)
                    else:
                        # ä½œä¸ºç‹¬ç«‹åŒºåŸŸä¿ç•™
                        reorganized_lines.extend(group)
            
            return reorganized_lines
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬è¡Œé‡ç»„å¤±è´¥: {e}")
            return regions
    
    def _should_merge_as_text_line(self, regions: List[np.ndarray], gray: np.ndarray) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆå¹¶ä¸ºæ–‡æœ¬è¡Œ"""
        try:
            if len(regions) < 2:
                return False
            
            # è®¡ç®—åŒºåŸŸé—´çš„æ°´å¹³è·ç¦»
            regions_with_x = [(region, np.mean(region[:, 0])) for region in regions]
            regions_with_x.sort(key=lambda x: x[1])
            
            # æ£€æŸ¥é—´è·æ˜¯å¦åˆç†
            distances = []
            for i in range(len(regions_with_x) - 1):
                region1, x1 = regions_with_x[i]
                region2, x2 = regions_with_x[i + 1]
                
                # è®¡ç®—åŒºåŸŸå³è¾¹ç•Œåˆ°ä¸‹ä¸€ä¸ªåŒºåŸŸå·¦è¾¹ç•Œçš„è·ç¦»
                right_x1 = np.max(region1[:, 0])
                left_x2 = np.min(region2[:, 0])
                distance = left_x2 - right_x1
                distances.append(distance)
            
            # æ£€æŸ¥è·ç¦»æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
            if not distances:
                return False
            
            max_reasonable_distance = 50  # å¯è°ƒæ•´çš„å‚æ•°
            return all(0 <= d <= max_reasonable_distance for d in distances)
            
        except Exception:
            return False
    
    def _merge_text_line(self, regions: List[np.ndarray]) -> Optional[np.ndarray]:
        """åˆå¹¶æ–‡æœ¬è¡Œ"""
        try:
            if not regions:
                return None
            
            # è®¡ç®—åˆå¹¶è¾¹ç•Œ
            all_x_coords = []
            all_y_coords = []
            
            for region in regions:
                all_x_coords.extend(region[:, 0])
                all_y_coords.extend(region[:, 1])
            
            min_x, max_x = np.min(all_x_coords), np.max(all_x_coords)
            min_y, max_y = np.min(all_y_coords), np.max(all_y_coords)
            
            # åˆ›å»ºåˆå¹¶åçš„æ–‡æœ¬è¡Œ
            merged_line = np.array([
                [min_x, min_y],
                [max_x, min_y],
                [max_x, max_y],
                [min_x, max_y]
            ], dtype=np.float32)
            
            return merged_line
            
        except Exception:
            return None
    
    def _manage_segmentation_cache(self, cache_key: str, result: Dict):
        """ç®¡ç†åˆ†å‰²ç¼“å­˜"""
        try:
            if len(self._segmentation_cache) >= self._cache_max_size:
                # åˆ é™¤æœ€æ—§çš„ç¼“å­˜æ¡ç›®
                oldest_key = next(iter(self._segmentation_cache))
                del self._segmentation_cache[oldest_key]
            
            self._segmentation_cache[cache_key] = result
            
        except Exception as e:
            logger.error(f"åˆ†å‰²ç¼“å­˜ç®¡ç†å¤±è´¥: {e}")
    
    def clear_segmentation_cache(self):
        """æ¸…ç†åˆ†å‰²ç¼“å­˜"""
        try:
            self._segmentation_cache.clear()
            logger.info("æ–‡æœ¬åˆ†å‰²ç¼“å­˜å·²æ¸…ç†")
        except Exception as e:
            logger.error(f"æ¸…ç†åˆ†å‰²ç¼“å­˜å¤±è´¥: {e}")
    
    def get_segmentation_stats(self) -> Dict:
        """è·å–åˆ†å‰²ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'cache_size': len(self._segmentation_cache),
            'max_cache_size': self._cache_max_size,
            'config': self.config.copy()
        }
    
    # æ–°å¢é«˜çº§åˆ†å‰²æ–¹æ³•
    def _multilevel_mser_detection(self, gray: np.ndarray) -> Tuple[List[np.ndarray], Dict]:
        """
        å¤šå±‚æ¬¡MSERæ£€æµ‹ (V3 - APIå…¼å®¹æœ€ç»ˆç‰ˆ)
        - åŒæ ·é‡‡ç”¨åˆ›å»ºå®ä¾‹åé€ä¸€è®¾ç½®å‚æ•°çš„æ–¹å¼ï¼Œè§£å†³å…¼å®¹æ€§é—®é¢˜ã€‚
        """
        try:
            all_regions_with_scores_levels = []
            stats = {'levels_processed': 0, 'raw_regions_per_level': []}

            # ç°åœ¨ config å­—å…¸ä¸­çš„é”®åæ˜¯ä»€ä¹ˆå·²ä¸å†é‡è¦ï¼Œå› ä¸ºæˆ‘ä»¬å°†é€šè¿‡ setter è°ƒç”¨
            mser_levels_configs = [
                {'delta': 3, 'min_area': 15, 'max_area': 2000, 'max_variation': 0.15, 'min_diversity': 0.3},
                {'delta': 5, 'min_area': 50, 'max_area': 8000, 'max_variation': 0.25, 'min_diversity': 0.2},
                {'delta': 7, 'min_area': 150, 'max_area': 15000, 'max_variation': 0.35, 'min_diversity': 0.15},
            ]
            
            for level, config in enumerate(mser_levels_configs):
                level_regions_scores = []
                for image_pass in [gray, cv2.bitwise_not(gray)]:
                    try:
                        # --- æ ¸å¿ƒä¿®æ­£ï¼šé‡‡ç”¨ Setter æ–¹æ³•é…ç½® MSER ---
                        mser = cv2.MSER_create()
                        mser.setDelta(config['delta'])
                        mser.setMinArea(config['min_area'])
                        mser.setMaxArea(config['max_area'])
                        mser.setMaxVariation(config['max_variation'])
                        mser.setMinDiversity(config['min_diversity'])
                        # --- ä¿®æ­£ç»“æŸ ---

                        level_regions, _ = mser.detectRegions(image_pass)
                        
                        for region in level_regions:
                            hull = cv2.convexHull(region.reshape(-1, 1, 2))
                            rect = cv2.minAreaRect(hull)
                            box = cv2.boxPoints(rect)
                            
                            if self._validate_multilevel_region(box, gray, level):
                                score = cv2.contourArea(box)
                                level_regions_scores.append((box, score, level))

                    except Exception as e:
                        logger.warning(f"MSERçº§åˆ«{level}å¤±è´¥: {e}")
                
                stats['raw_regions_per_level'].append(len(level_regions_scores))
                all_regions_with_scores_levels.extend(level_regions_scores)
                stats['levels_processed'] += 1
            
            if not all_regions_with_scores_levels:
                return [], stats

            boxes = [item[0] for item in all_regions_with_scores_levels]
            scores = [item[1] for item in all_regions_with_scores_levels]
            rects_for_nms = [cv2.boundingRect(box.astype(np.int32)) for box in boxes]
            
            indices = cv2.dnn.NMSBoxes(rects_for_nms, scores, score_threshold=0.1, nms_threshold=0.4)
            
            final_regions = []
            if len(indices) > 0:
                for i in indices.flatten():
                    final_regions.append(boxes[i].astype(np.float32))

            return final_regions, stats
            
        except Exception as e:
            logger.error(f"å¤šå±‚æ¬¡MSERæ£€æµ‹å¤±è´¥: {e}")
            return [], {'error': str(e)}
    
    def _validate_multilevel_region(self, box: np.ndarray, gray: np.ndarray, level: int) -> bool:
        """å¤šå±‚æ¬¡åŒºåŸŸéªŒè¯"""
        try:
            # åŸºæœ¬å‡ ä½•éªŒè¯
            if not self._validate_text_region(box, gray):
                return False
            
            # æ ¹æ®å±‚æ¬¡è¿›è¡Œä¸åŒçš„éªŒè¯
            x_coords = box[:, 0]
            y_coords = box[:, 1]
            width = np.max(x_coords) - np.min(x_coords)
            height = np.max(y_coords) - np.min(y_coords)
            
            # å±‚æ¬¡ç‰¹å®šçš„å°ºå¯¸è¦æ±‚
            if level == 0:  # ç»†ç²’åº¦ - å­—ç¬¦çº§
                return (4 <= width <= 80 and 8 <= height <= 120)
            elif level == 1:  # ä¸­ç­‰ç²’åº¦ - è¯è¯­çº§
                return (20 <= width <= 200 and 10 <= height <= 150)
            elif level == 2:  # ç²—ç²’åº¦ - çŸ­å¥çº§
                return (50 <= width <= 400 and 15 <= height <= 100)
            else:  # è¶…å¤§åŒºåŸŸ - æ®µè½çº§
                return (100 <= width <= 800 and 20 <= height <= 200)
            
        except Exception:
            return False
    
    def _adaptive_multithreshold_detection(self, gray: np.ndarray) -> Tuple[List[np.ndarray], Dict]:
        """è‡ªé€‚åº”å¤šé˜ˆå€¼æ£€æµ‹"""
        try:
            regions = []
            stats = {'thresholds_used': [], 'regions_per_threshold': []}
            
            # è‡ªé€‚åº”ç¡®å®šé˜ˆå€¼èŒƒå›´
            mean_intensity = np.mean(gray)
            std_intensity = np.std(gray)
            
            # åŠ¨æ€ç”Ÿæˆé˜ˆå€¼
            base_thresholds = [
                mean_intensity - 2 * std_intensity,
                mean_intensity - std_intensity,
                mean_intensity,
                mean_intensity + std_intensity,
                mean_intensity + 2 * std_intensity
            ]
            
            # ç¡®ä¿é˜ˆå€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
            thresholds = [max(0, min(255, t)) for t in base_thresholds]
            thresholds = sorted(list(set(thresholds)))  # å»é‡å¹¶æ’åº
            
            for threshold in thresholds:
                try:
                    # å›ºå®šé˜ˆå€¼äºŒå€¼åŒ–
                    _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)
                    
                    # å¤šç§å½¢æ€å­¦æ“ä½œ
                    morphology_configs = [
                        (cv2.MORPH_RECT, (2, 1)),
                        (cv2.MORPH_RECT, (1, 2)),
                        (cv2.MORPH_RECT, (3, 3)),
                        (cv2.MORPH_ELLIPSE, (3, 3))
                    ]
                    
                    threshold_regions = []
                    
                    for morph_type, kernel_size in morphology_configs:
                        kernel = cv2.getStructuringElement(morph_type, kernel_size)
                        processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
                        
                        # æŸ¥æ‰¾è½®å»“
                        contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        
                        for contour in contours:
                            area = cv2.contourArea(contour)
                            if area > self.config['connected_component_min_area']:
                                rect = cv2.minAreaRect(contour)
                                box = cv2.boxPoints(rect)
                                
                                if self._validate_threshold_region(box, binary):
                                    threshold_regions.append(box.astype(np.float32))
                    
                    regions.extend(threshold_regions)
                    stats['thresholds_used'].append(threshold)
                    stats['regions_per_threshold'].append(len(threshold_regions))
                    
                except Exception as e:
                    logger.warning(f"é˜ˆå€¼{threshold}å¤„ç†å¤±è´¥: {e}")
                    continue
            
            return regions, stats
            
        except Exception as e:
            logger.error(f"è‡ªé€‚åº”å¤šé˜ˆå€¼æ£€æµ‹å¤±è´¥: {e}")
            return [], {'error': str(e)}
    
    def _validate_threshold_region(self, box: np.ndarray, binary: np.ndarray) -> bool:
        """éªŒè¯é˜ˆå€¼åŒºåŸŸ"""
        try:
            # åˆ›å»ºåŒºåŸŸæ©è†œ
            mask = np.zeros(binary.shape, dtype=np.uint8)
            cv2.fillPoly(mask, [box.astype(np.int32)], 255)
            
            # è®¡ç®—åŒºåŸŸå†…çš„å‰æ™¯åƒç´ æ¯”ä¾‹
            region_pixels = cv2.bitwise_and(binary, binary, mask=mask)
            foreground_pixels = np.sum(region_pixels > 0)
            total_pixels = np.sum(mask > 0)
            
            if total_pixels == 0:
                return False
            
            fill_ratio = foreground_pixels / total_pixels
            
            # é˜ˆå€¼åŒºåŸŸåº”è¯¥æœ‰é€‚å½“çš„å¡«å……æ¯”ä¾‹
            return 0.1 <= fill_ratio <= 0.9
            
        except Exception:
            return False
    
    def _orientation_adaptive_detection(self, gray: np.ndarray) -> Tuple[List[np.ndarray], Dict]:
        """æ–¹å‘è‡ªé€‚åº”æ£€æµ‹"""
        try:
            regions = []
            stats = {'orientations_tested': [], 'regions_per_orientation': []}
            
            # æ£€æµ‹ä¸»è¦æ–‡æœ¬æ–¹å‘
            dominant_angles = self._detect_dominant_text_orientations(gray)
            
            for angle in dominant_angles:
                try:
                    # æ—‹è½¬å›¾åƒåˆ°æ°´å¹³æ–¹å‘
                    if abs(angle) > 1:  # åªæœ‰è§’åº¦è¶³å¤Ÿå¤§æ—¶æ‰æ—‹è½¬
                        center = (gray.shape[1] // 2, gray.shape[0] // 2)
                        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
                        rotated_gray = cv2.warpAffine(gray, rotation_matrix, (gray.shape[1], gray.shape[0]),
                                                    flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=255)
                    else:
                        rotated_gray = gray
                    
                    # åœ¨æ—‹è½¬åçš„å›¾åƒä¸Šè¿›è¡Œæ–‡æœ¬æ£€æµ‹
                    orientation_regions = self._detect_horizontal_text_regions(rotated_gray)
                    
                    # å°†æ£€æµ‹åˆ°çš„åŒºåŸŸæ—‹è½¬å›åŸå§‹æ–¹å‘
                    if abs(angle) > 1:
                        inverse_rotation_matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)
                        for i, region in enumerate(orientation_regions):
                            # æ—‹è½¬åŒºåŸŸåæ ‡
                            ones = np.ones(shape=(len(region), 1))
                            points_ones = np.hstack([region, ones])
                            transformed_points = inverse_rotation_matrix.dot(points_ones.T).T
                            orientation_regions[i] = transformed_points.astype(np.float32)
                    
                    regions.extend(orientation_regions)
                    stats['orientations_tested'].append(angle)
                    stats['regions_per_orientation'].append(len(orientation_regions))
                    
                except Exception as e:
                    logger.warning(f"æ–¹å‘{angle}åº¦æ£€æµ‹å¤±è´¥: {e}")
                    continue
            
            return regions, stats
            
        except Exception as e:
            logger.error(f"æ–¹å‘è‡ªé€‚åº”æ£€æµ‹å¤±è´¥: {e}")
            return [], {'error': str(e)}
    
    def _detect_dominant_text_orientations(self, gray: np.ndarray) -> List[float]:
        """æ£€æµ‹ä¸»è¦æ–‡æœ¬æ–¹å‘"""
        try:
            # ä½¿ç”¨éœå¤«å˜æ¢æ£€æµ‹ç›´çº¿
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
            
            angles = []
            if lines is not None:
                for line in lines:
                    rho, theta = line[0]
                    angle = np.degrees(theta - np.pi/2)  # è½¬æ¢ä¸ºæ–‡æœ¬è§’åº¦
                    angles.append(angle)
            
            # è§’åº¦èšç±»
            if not angles:
                return [0.0]  # é»˜è®¤æ°´å¹³æ–¹å‘
            
            # ç®€å•çš„è§’åº¦èšç±»
            angle_bins = {}
            bin_size = 5  # 5åº¦ä¸ºä¸€ä¸ªåŒºé—´
            
            for angle in angles:
                bin_key = round(angle / bin_size) * bin_size
                bin_key = bin_key % 180  # è§„èŒƒåŒ–åˆ°0-180åº¦
                if bin_key > 90:
                    bin_key = bin_key - 180  # è½¬æ¢åˆ°-90åˆ°90åº¦èŒƒå›´
                
                if bin_key not in angle_bins:
                    angle_bins[bin_key] = 0
                angle_bins[bin_key] += 1
            
            # é€‰æ‹©æœ€é¢‘ç¹çš„æ–¹å‘
            if angle_bins:
                dominant_angles = sorted(angle_bins.keys(), key=lambda x: angle_bins[x], reverse=True)
                return dominant_angles[:3]  # è¿”å›å‰3ä¸ªä¸»è¦æ–¹å‘
            else:
                return [0.0]
            
        except Exception as e:
            logger.warning(f"ä¸»è¦æ–¹å‘æ£€æµ‹å¤±è´¥: {e}")
            return [0.0]
    
    def _detect_horizontal_text_regions(self, gray: np.ndarray) -> List[np.ndarray]:
        """
        æ£€æµ‹æ°´å¹³æ–‡æœ¬åŒºåŸŸã€‚
        æ­¤æ–¹æ³•ä¸“é—¨ä¼˜åŒ–ç”¨äºæ£€æµ‹æ¨ªå‘æ’åˆ—çš„æ–‡æœ¬è¡Œã€‚
        å®ƒä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼å’Œæ°´å¹³æ–¹å‘çš„å½¢æ€å­¦æ“ä½œæ¥è¿æ¥å­—ç¬¦ï¼Œ
        ç„¶åæå–è½®å»“å¹¶æ ¹æ®å®½é«˜æ¯”è¿›è¡Œè¿‡æ»¤ã€‚
        """
        try:
            regions = []

            # é’ˆå¯¹æ°´å¹³æ–‡æœ¬ä¼˜åŒ–çš„å½¢æ€å­¦æ“ä½œ
            # ä¿®æ­£ï¼šå°†æ‰€æœ‰ 'cv.' æ›¿æ¢ä¸º 'cv2.'
            binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                           cv2.THRESH_BINARY_INV, 11, 2)

            # æ°´å¹³è¿æ¥æ ¸ï¼Œç”¨äºè¿æ¥åŒä¸€è¡Œå†…çš„å­—ç¬¦
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 1))
            # é—­è¿ç®—è¿æ¥æ–­è£‚çš„æ–‡æœ¬éƒ¨åˆ†
            horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, horizontal_kernel)

            # æŸ¥æ‰¾æ°´å¹³æ–‡æœ¬åŒºåŸŸçš„è½®å»“
            contours, _ = cv2.findContours(horizontal_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for contour in contours:
                area = cv2.contourArea(contour)
                # è¿‡æ»¤æ‰è¿‡å°çš„å™ªå£°åŒºåŸŸ
                if area > self.config['min_text_size'] ** 2:
                    # è·å–è¾¹ç•ŒçŸ©å½¢
                    x, y, w, h = cv2.boundingRect(contour)

                    # éªŒè¯æ˜¯å¦ä¸ºæ°´å¹³æ–‡æœ¬ï¼šå®½åº¦è¿œå¤§äºé«˜åº¦
                    aspect_ratio = w / h if h > 0 else 0
                    if aspect_ratio > 1.5:  # æ°´å¹³æ–‡æœ¬çš„å®½é«˜æ¯”é€šå¸¸å¤§äº1.5
                        box = np.array([
                            [x, y],
                            [x + w, y],
                            [x + w, y + h],
                            [x, y + h]
                        ], dtype=np.float32)
                        regions.append(box)
            
            return regions

        except Exception as e:
            # æ•è·ä»»ä½•æ½œåœ¨é”™è¯¯å¹¶è®°å½•ï¼Œè¿”å›ç©ºåˆ—è¡¨
            logger.error(f"æ°´å¹³æ–‡æœ¬æ£€æµ‹å¤±è´¥: {e}")
            return []     
    def _ultra_precise_merging(self, regions: List[np.ndarray], gray: np.ndarray) -> List[np.ndarray]:
        """è¶…ç²¾ç¡®åˆå¹¶"""
        try:
            if not regions:
                return []
            
            # åŸºäºå¤šç§ç›¸ä¼¼åº¦åº¦é‡çš„æ™ºèƒ½åˆå¹¶
            merged_regions = []
            region_groups = []
            
            # è®¡ç®—æ‰€æœ‰åŒºåŸŸå¯¹çš„ç›¸ä¼¼åº¦
            similarity_matrix = np.zeros((len(regions), len(regions)))
            
            for i, region1 in enumerate(regions):
                for j, region2 in enumerate(regions):
                    if i != j:
                        # ç»¼åˆç›¸ä¼¼åº¦è¯„åˆ†
                        geo_sim = self._calculate_geometric_similarity(region1, region2)
                        spatial_sim = self._calculate_spatial_similarity(region1, region2)
                        content_sim = self._calculate_content_similarity(region1, region2, gray)
                        
                        # åŠ æƒå¹³å‡
                        total_sim = (geo_sim * 0.3 + spatial_sim * 0.4 + content_sim * 0.3)
                        similarity_matrix[i, j] = total_sim
            
            # åŸºäºç›¸ä¼¼åº¦çŸ©é˜µè¿›è¡Œèšç±»
            visited = [False] * len(regions)
            
            for i in range(len(regions)):
                if visited[i]:
                    continue
                
                group = [i]
                visited[i] = True
                
                # æ‰¾åˆ°ç›¸ä¼¼çš„åŒºåŸŸ
                for j in range(len(regions)):
                    if not visited[j] and similarity_matrix[i, j] > self.config['merge_threshold']:
                        group.append(j)
                        visited[j] = True
                
                # åˆå¹¶ç»„å†…åŒºåŸŸ
                if len(group) == 1:
                    merged_regions.append(regions[group[0]])
                else:
                    group_regions = [regions[idx] for idx in group]
                    merged_region = self._intelligent_merge_group(group_regions, gray)
                    if merged_region is not None:
                        merged_regions.append(merged_region)
            
            return merged_regions
            
        except Exception as e:
            logger.error(f"è¶…ç²¾ç¡®åˆå¹¶å¤±è´¥: {e}")
            return regions
    
    def _calculate_geometric_similarity(self, region1: np.ndarray, region2: np.ndarray) -> float:
        """è®¡ç®—å‡ ä½•ç›¸ä¼¼åº¦"""
        try:
            # è®¡ç®—å°ºå¯¸ç›¸ä¼¼åº¦
            def get_dimensions(region):
                x_coords = region[:, 0]
                y_coords = region[:, 1]
                width = np.max(x_coords) - np.min(x_coords)
                height = np.max(y_coords) - np.min(y_coords)
                return width, height
            
            w1, h1 = get_dimensions(region1)
            w2, h2 = get_dimensions(region2)
            
            if w1 <= 0 or h1 <= 0 or w2 <= 0 or h2 <= 0:
                return 0.0
            
            # å°ºå¯¸æ¯”ä¾‹ç›¸ä¼¼åº¦
            width_ratio = min(w1, w2) / max(w1, w2)
            height_ratio = min(h1, h2) / max(h1, h2)
            
            # é¢ç§¯ç›¸ä¼¼åº¦
            area1, area2 = w1 * h1, w2 * h2
            area_ratio = min(area1, area2) / max(area1, area2)
            
            # å®½é«˜æ¯”ç›¸ä¼¼åº¦
            aspect1, aspect2 = w1 / h1, w2 / h2
            aspect_ratio = min(aspect1, aspect2) / max(aspect1, aspect2)
            
            return (width_ratio + height_ratio + area_ratio + aspect_ratio) / 4
            
        except Exception:
            return 0.0
    
    def _calculate_spatial_similarity(self, region1: np.ndarray, region2: np.ndarray) -> float:
        """è®¡ç®—ç©ºé—´ç›¸ä¼¼åº¦"""
        try:
            # è®¡ç®—åŒºåŸŸä¸­å¿ƒç‚¹
            center1 = np.mean(region1, axis=0)
            center2 = np.mean(region2, axis=0)
            
            # è®¡ç®—è·ç¦»
            distance = np.linalg.norm(center1 - center2)
            
            # è®¡ç®—åŒºåŸŸå°ºå¯¸
            def get_max_dimension(region):
                x_coords = region[:, 0]
                y_coords = region[:, 1]
                width = np.max(x_coords) - np.min(x_coords)
                height = np.max(y_coords) - np.min(y_coords)
                return max(width, height)
            
            max_dim1 = get_max_dimension(region1)
            max_dim2 = get_max_dimension(region2)
            max_dim = max(max_dim1, max_dim2)
            
            if max_dim <= 0:
                return 0.0
            
            # å½’ä¸€åŒ–è·ç¦»ï¼ˆè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
            normalized_distance = distance / max_dim
            spatial_similarity = max(0, 1 - normalized_distance)
            
            return spatial_similarity
            
        except Exception:
            return 0.0
    
    def _calculate_content_similarity(self, region1: np.ndarray, region2: np.ndarray, gray: np.ndarray) -> float:
        """è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦"""
        try:
            # æå–åŒºåŸŸå†…å®¹
            def extract_region_content(region, image):
                mask = np.zeros(image.shape, dtype=np.uint8)
                cv2.fillPoly(mask, [region.astype(np.int32)], 255)
                
                # è®¡ç®—ç›´æ–¹å›¾
                hist = cv2.calcHist([image], [0], mask, [32], [0, 256])
                hist = cv2.normalize(hist, hist).flatten()
                
                # è®¡ç®—æ¢¯åº¦ç‰¹å¾
                roi = cv2.bitwise_and(image, image, mask=mask)
                grad_x = cv2.Sobel(roi, cv2.CV_64F, 1, 0, ksize=3)
                grad_y = cv2.Sobel(roi, cv2.CV_64F, 0, 1, ksize=3)
                grad_mag = np.sqrt(grad_x**2 + grad_y**2)
                
                # æ¢¯åº¦ç»Ÿè®¡
                grad_mean = np.mean(grad_mag[mask > 0]) if np.sum(mask > 0) > 0 else 0
                grad_std = np.std(grad_mag[mask > 0]) if np.sum(mask > 0) > 0 else 0
                
                return hist, grad_mean, grad_std
            
            hist1, grad_mean1, grad_std1 = extract_region_content(region1, gray)
            hist2, grad_mean2, grad_std2 = extract_region_content(region2, gray)
            
            # ç›´æ–¹å›¾ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ç›¸å…³ç³»æ•°ï¼‰
            hist_similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            
            # æ¢¯åº¦ç‰¹å¾ç›¸ä¼¼åº¦
            grad_mean_sim = 1 - abs(grad_mean1 - grad_mean2) / (max(grad_mean1, grad_mean2) + 1e-8)
            grad_std_sim = 1 - abs(grad_std1 - grad_std2) / (max(grad_std1, grad_std2) + 1e-8)
            
            # ç»¼åˆå†…å®¹ç›¸ä¼¼åº¦
            content_similarity = (hist_similarity + grad_mean_sim + grad_std_sim) / 3
            return max(0, content_similarity)
            
        except Exception:
            return 0.0
    
    def _intelligent_merge_group(self, regions: List[np.ndarray], gray: np.ndarray) -> Optional[np.ndarray]:
        """æ™ºèƒ½åˆå¹¶åŒºåŸŸç»„"""
        try:
            if not regions:
                return None
            
            if len(regions) == 1:
                return regions[0]
            
            # è®¡ç®—æœ€ä½³åˆå¹¶è¾¹ç•Œ
            all_points = np.vstack(regions)
            
            # ä½¿ç”¨å‡¸åŒ…è·å¾—æ›´å¥½çš„è¾¹ç•Œ
            hull = cv2.convexHull(all_points)
            
            # å¦‚æœå‡¸åŒ…ç‚¹å¤ªå°‘ï¼Œä½¿ç”¨è¾¹ç•Œæ¡†
            if len(hull) < 4:
                x_coords = all_points[:, 0]
                y_coords = all_points[:, 1]
                min_x, max_x = np.min(x_coords), np.max(x_coords)
                min_y, max_y = np.min(y_coords), np.max(y_coords)
                
                merged_region = np.array([
                    [min_x, min_y],
                    [max_x, min_y],
                    [max_x, max_y],
                    [min_x, max_y]
                ], dtype=np.float32)
            else:
                # ç®€åŒ–å‡¸åŒ…åˆ°å››ä¸ªä¸»è¦ç‚¹
                merged_region = self._simplify_hull_to_rectangle(hull)
            
            return merged_region
            
        except Exception:
            return None
    
    def _simplify_hull_to_rectangle(self, hull: np.ndarray) -> np.ndarray:
        """å°†å‡¸åŒ…ç®€åŒ–ä¸ºçŸ©å½¢"""
        try:
            # æ‰¾åˆ°æœ€å°å¤–æ¥çŸ©å½¢
            rect = cv2.minAreaRect(hull)
            box = cv2.boxPoints(rect)
            return box.astype(np.float32)
            
        except Exception:
            # å¦‚æœå¤±è´¥ï¼Œè¿”å›è¾¹ç•Œæ¡†
            x_coords = hull[:, 0, 0]
            y_coords = hull[:, 0, 1]
            min_x, max_x = np.min(x_coords), np.max(x_coords)
            min_y, max_y = np.min(y_coords), np.max(y_coords)
            
            return np.array([
                [min_x, min_y],
                [max_x, min_y],
                [max_x, max_y],
                [min_x, max_y]
            ], dtype=np.float32)
    
    def _final_optimization(self, regions: List[np.ndarray], gray: np.ndarray) -> List[np.ndarray]:
        """æœ€ç»ˆä¼˜åŒ–"""
        try:
            if not regions:
                return []
            
            optimized_regions = []
            
            for region in regions:
                # å¤šé‡ä¼˜åŒ–
                optimized_region = self._optimize_single_region(region, gray)
                
                # æœ€ç»ˆéªŒè¯
                if self._final_region_validation(optimized_region, gray):
                    optimized_regions.append(optimized_region)
            
            # æœ€ç»ˆæ’åºï¼ˆæŒ‰é˜…è¯»é¡ºåºï¼‰
            return self._sort_regions_by_reading_order(optimized_regions)
            
        except Exception as e:
            logger.error(f"æœ€ç»ˆä¼˜åŒ–å¤±è´¥: {e}")
            return regions
    
    def _optimize_single_region(self, region: np.ndarray, gray: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–å•ä¸ªåŒºåŸŸ"""
        try:
            # è¾¹ç•Œç´§ç¼©ä¼˜åŒ–
            optimized_region = self._tight_boundary_optimization(region, gray)
            
            # è§’åº¦å¾®è°ƒ
            optimized_region = self._fine_tune_rotation(optimized_region, gray)
            
            return optimized_region
            
        except Exception:
            return region
    
    def _tight_boundary_optimization(self, region: np.ndarray, gray: np.ndarray) -> np.ndarray:
        """ç´§ç¼©è¾¹ç•Œä¼˜åŒ–"""
        try:
            # åˆ›å»ºæ©è†œ
            mask = np.zeros(gray.shape, dtype=np.uint8)
            cv2.fillPoly(mask, [region.astype(np.int32)], 255)
            
            # æŸ¥æ‰¾å®é™…å†…å®¹è¾¹ç•Œ
            coords = np.where(mask > 0)
            if len(coords[0]) == 0:
                return region
            
            min_y, max_y = np.min(coords[0]), np.max(coords[0])
            min_x, max_x = np.min(coords[1]), np.max(coords[1])
            
            # æ·»åŠ å°çš„è¾¹è·
            margin = 2
            min_x = max(0, min_x - margin)
            min_y = max(0, min_y - margin)
            max_x = min(gray.shape[1], max_x + margin)
            max_y = min(gray.shape[0], max_y + margin)
            
            tight_region = np.array([
                [min_x, min_y],
                [max_x, min_y],
                [max_x, max_y],
                [min_x, max_y]
            ], dtype=np.float32)
            
            return tight_region
            
        except Exception:
            return region
    
    def _fine_tune_rotation(self, region: np.ndarray, gray: np.ndarray) -> np.ndarray:
        """å¾®è°ƒæ—‹è½¬è§’åº¦"""
        try:
            # æå–åŒºåŸŸå†…å®¹
            mask = np.zeros(gray.shape, dtype=np.uint8)
            cv2.fillPoly(mask, [region.astype(np.int32)], 255)
            
            # æŸ¥æ‰¾æ–‡æœ¬è½®å»“
            roi = cv2.bitwise_and(gray, gray, mask=mask)
            binary = cv2.adaptiveThreshold(roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                         cv2.THRESH_BINARY_INV, 11, 2)
            
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return region
            
            # æ‰¾åˆ°æœ€å¤§è½®å»“
            largest_contour = max(contours, key=cv2.contourArea)
            
            # è®¡ç®—æœ€å°é¢ç§¯çŸ©å½¢
            rect = cv2.minAreaRect(largest_contour)
            fine_tuned_box = cv2.boxPoints(rect)
            
            return fine_tuned_box.astype(np.float32)
            
        except Exception:
            return region
    
    def _final_region_validation(self, region: np.ndarray, gray: np.ndarray) -> bool:
        """æœ€ç»ˆåŒºåŸŸéªŒè¯"""
        try:
            # å‡ ä½•éªŒè¯
            if not self._validate_text_region(region, gray):
                return False
            
            # å†…å®¹å¯†åº¦éªŒè¯
            mask = np.zeros(gray.shape, dtype=np.uint8)
            cv2.fillPoly(mask, [region.astype(np.int32)], 255)
            
            roi = cv2.bitwise_and(gray, gray, mask=mask)
            
            # è®¡ç®—å˜å¼‚ç³»æ•°
            roi_pixels = roi[mask > 0]
            if len(roi_pixels) == 0:
                return False
            
            mean_intensity = np.mean(roi_pixels)
            std_intensity = np.std(roi_pixels)
            
            if mean_intensity == 0:
                return False
            
            cv = std_intensity / mean_intensity
            
            # æ–‡æœ¬åŒºåŸŸåº”è¯¥æœ‰é€‚å½“çš„å˜å¼‚
            return 0.1 <= cv <= 2.0
            
        except Exception:
            return False
    
    def _sort_regions_by_reading_order(self, regions: List[np.ndarray]) -> List[np.ndarray]:
        """æŒ‰é˜…è¯»é¡ºåºæ’åºåŒºåŸŸ"""
        try:
            if not regions:
                return []
            
            # è®¡ç®—æ¯ä¸ªåŒºåŸŸçš„ä¸­å¿ƒç‚¹å’Œè¾¹ç•Œ
            region_info = []
            for region in regions:
                center = np.mean(region, axis=0)
                y_min = np.min(region[:, 1])
                region_info.append((region, center, y_min))
            
            # æŒ‰è¡Œæ’åºï¼ˆé¦–å…ˆæŒ‰Yåæ ‡åˆ†ç»„ï¼Œç„¶åæŒ‰Xåæ ‡æ’åºï¼‰
            region_info.sort(key=lambda x: (x[2], x[1][0]))
            
            return [info[0] for info in region_info]
            
        except Exception as e:
            logger.error(f"é˜…è¯»é¡ºåºæ’åºå¤±è´¥: {e}")
            return regions
    
    # æ·»åŠ ä¸€äº›è¾…åŠ©éªŒè¯æ–¹æ³•
    def _validate_text_region(self, box: np.ndarray, gray: np.ndarray) -> bool:
        """éªŒè¯æ–‡æœ¬åŒºåŸŸ - åŸºç¡€éªŒè¯æ–¹æ³•"""
        try:
            # åŸºæœ¬å‡ ä½•æ£€æŸ¥
            x_coords = box[:, 0]
            y_coords = box[:, 1]
            width = np.max(x_coords) - np.min(x_coords)
            height = np.max(y_coords) - np.min(y_coords)
            
            # å°ºå¯¸æ£€æŸ¥
            if (width < self.config['min_text_size'] or height < self.config['min_text_size'] or
                width > self.config['max_text_size'] or height > self.config['max_text_size']):
                return False
            
            # å®½é«˜æ¯”æ£€æŸ¥
            if height > 0:
                aspect_ratio = width / height
                if aspect_ratio < 0.05 or aspect_ratio > 20:
                    return False
            
            return True
            
        except Exception:
            return False
    
    def _validate_gradient_region(self, box: np.ndarray, magnitude: np.ndarray) -> bool:
        """éªŒè¯æ¢¯åº¦åŒºåŸŸ"""
        try:
            # åˆ›å»ºæ©è†œ
            mask = np.zeros(magnitude.shape, dtype=np.uint8)
            cv2.fillPoly(mask, [box.astype(np.int32)], 255)
            
            # è®¡ç®—åŒºåŸŸå†…æ¢¯åº¦å¼ºåº¦
            region_magnitude = magnitude[mask > 0]
            if len(region_magnitude) == 0:
                return False
            
            mean_magnitude = np.mean(region_magnitude)
            
            # æ–‡æœ¬åŒºåŸŸåº”è¯¥æœ‰è¶³å¤Ÿçš„æ¢¯åº¦å¼ºåº¦
            return mean_magnitude > 20  # é˜ˆå€¼å¯è°ƒ
            
        except Exception:
            return False



class PPOCRv3TextDetector:
    """
    ä½¿ç”¨OpenCV DNNæ¨¡å—å’ŒPP-OCRv3æ¨¡å‹çš„ç°ä»£æ–‡æœ¬æ£€æµ‹å™¨ã€‚
    è¿™æ˜¯å½“å‰OpenCV Zooä¸­å®˜æ–¹æ”¯æŒçš„ç¨³å®šæ–¹æ¡ˆã€‚
    """
    def __init__(self, model_name="text_detection_cn_ppocrv3_2023may.onnx", threshold=0.3, nms_threshold=0.4):
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹æ–‡ä»¶å
        self.model_name = model_name
            
        self.threshold = threshold
        self.nms_threshold = nms_threshold
        self.net = None
        self.input_size = (736, 736)
        self._initialize_model()

    def _download_model(self, model_path, url):
        """ä¸‹è½½PP-OCRv3æ¨¡å‹æ–‡ä»¶"""
        if requests is None:
            logger.error("âŒ PP-OCRv3æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼š'requests'åº“æœªå®‰è£…ã€‚")
            return False
        try:
            logger.info(f"PP-OCRv3æ¨¡å‹æ–‡ä»¶ '{model_path}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨ä»å®˜æ–¹æºä¸‹è½½...")
            with requests.get(url, stream=True, timeout=300) as r:
                r.raise_for_status()
                with open(model_path, 'wb') as f:
                    shutil.copyfileobj(r.raw, f)
            logger.info(f"âœ… PP-OCRv3æ¨¡å‹ä¸‹è½½æˆåŠŸï¼Œå·²ä¿å­˜è‡³: {model_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ PP-OCRv3æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}", exc_info=True)
            if os.path.exists(model_path):
                os.remove(model_path)
            return False

    def _initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸‹è½½"""
        model_url = f"https://raw.githubusercontent.com/opencv/opencv_zoo/main/models/text_detection_ppocr/{self.model_name}"
        
        if not os.path.exists(self.model_name):
            if not self._download_model(self.model_name, model_url):
                error_message = (
                    "PP-OCRv3 æ–‡æœ¬æ£€æµ‹æ¨¡å‹è‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼\n\n"
                    "è¿™å°†å¯¼è‡´é«˜çº§æ–‡æœ¬åˆ†å‰²åŠŸèƒ½æ— æ³•ä½¿ç”¨ã€‚\n\n"
                    "è¯·æ‰‹åŠ¨ä»ä»¥ä¸‹åœ°å€ä¸‹è½½æ¨¡å‹ï¼š\n"
                    f"{model_url}\n\n"
                    f"ç„¶åå°† '{self.model_name}' æ–‡ä»¶æ”¾ç½®äºç¨‹åºè¿è¡Œç›®å½•ä¸‹ï¼Œå¹¶é‡å¯ç¨‹åºã€‚"
                )
                logger.error(error_message)
                try:
                    messagebox.showerror("å…³é”®æ¨¡å‹ä¸‹è½½å¤±è´¥", error_message)
                except Exception:
                    pass
                return

        try:
            self.net = cv2.dnn.readNet(self.model_name)
            logger.info(f"âœ… PP-OCRv3æ–‡æœ¬æ£€æµ‹æ¨¡å‹ '{self.model_name}' åŠ è½½æˆåŠŸã€‚")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½PP-OCRv3æ¨¡å‹å¤±è´¥: {e}", exc_info=True)
            self.net = None

    def detect_text_regions_advanced(self, image: np.ndarray, 
                                 enabled_algorithms: Optional[List[str]] = None) -> Tuple[List[np.ndarray], Dict]:
        """
        ä½¿ç”¨PP-OCRv3è¿›è¡Œé«˜çº§æ–‡æœ¬åŒºåŸŸæ£€æµ‹ã€‚
        """
        if self.net is None:
            logger.error("PP-OCRv3æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œæ–‡æœ¬æ£€æµ‹ã€‚")
            return [], {'error': 'PP-OCRv3 model not loaded'}

        start_time = time.time()
        
        original_height, original_width = image.shape[:2]
        
        blob = cv2.dnn.blobFromImage(image, scalefactor=1.0/255.0, size=self.input_size, mean=(122.67891434, 116.66876762, 104.00698793), swapRB=True, crop=False)
        self.net.setInput(blob)
        
        # --- å…³é”®ä¿®æ­£ï¼šæ­£ç¡®å¤„ç†å¤šè¾“å‡ºæ¨¡å‹ ---
        # .forward() å¯¹äºå¤šè¾“å‡ºæ¨¡å‹è¿”å›ä¸€ä¸ªå…ƒç»„æˆ–åˆ—è¡¨
        outputs = self.net.forward()

        # æ ¹æ®PP-OCRv3çš„ç»“æ„ï¼Œç¬¬ä¸€ä¸ªè¾“å‡ºæ˜¯scoresï¼Œç¬¬äºŒä¸ªæ˜¯geometry
        # å®ƒä»¬çš„å½¢çŠ¶é€šå¸¸æ˜¯ (N, C, H, W)ï¼Œæˆ‘ä»¬éœ€è¦å»æ‰å¤šä½™çš„æ‰¹å¤„ç†(N)å’Œé€šé“(C)ç»´åº¦
        scores = outputs[0].squeeze()   # squeeze() ä¼šç§»é™¤æ‰€æœ‰å¤§å°ä¸º1çš„ç»´åº¦
        geometry = outputs[1].squeeze() # ä¾‹å¦‚ (1, 5, H, W) -> (5, H, W)
        
        if scores.ndim != 2 or geometry.ndim != 3 or geometry.shape[0] != 5:
            error_msg = f"Unexpected output shapes after squeeze. Scores: {scores.shape}, Geometry: {geometry.shape}"
            logger.error(error_msg)
            return [], {'error': error_msg}
        # --- ä¿®æ­£ç»“æŸ ---

        rects, confidences = self._decode_predictions(scores, geometry)
        
        indices = cv2.dnn.NMSBoxesRotated(rects, confidences, self.threshold, self.nms_threshold)
        
        final_regions = []
        if len(indices) > 0:
            scale_x = original_width / self.input_size[0]
            scale_y = original_height / self.input_size[1]
            for i in indices:
                rot_rect = rects[i]
                # è°ƒæ•´æ—‹è½¬çŸ©å½¢çš„ä¸­å¿ƒç‚¹å’Œå¤§å°ä»¥åŒ¹é…åŸå§‹å›¾åƒå°ºå¯¸
                (cx, cy), (w, h), angle = rot_rect
                orig_cx, orig_cy = cx * scale_x, cy * scale_y
                orig_w, orig_h = w * scale_x, h * scale_y
                
                # è·å–ç¼©æ”¾åçš„æ—‹è½¬çŸ©å½¢çš„å››ä¸ªè§’ç‚¹
                points = cv2.boxPoints(((orig_cx, orig_cy), (orig_w, orig_h), angle))
                final_regions.append(points.astype(np.float32))

        processing_time = time.time() - start_time
        metadata = {
            'processing_time': processing_time,
            'detection_mode': 'ppocr_v3', # <--- ä½¿ç”¨ä¸€ä¸ªå›ºå®šçš„å€¼æˆ–ç§»é™¤æ­¤é”®
            'total_regions': len(final_regions),
            'detection_method': 'PP-OCRv3'
        }
        
        logger.info(f"PP-OCRv3æ–‡æœ¬æ£€æµ‹å®Œæˆ: {len(final_regions)}ä¸ªåŒºåŸŸ, è€—æ—¶: {processing_time:.3f}ç§’")
        return final_regions, metadata

    def _decode_predictions(self, scores, geometry):
        """ä»æ¨¡å‹è¾“å‡ºè§£ç è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦ (é€‚é…PP-OCRçš„EAST-likeè¾“å‡º)"""
        rects = []
        confidences = []
        height, width = scores.shape
        
        for y in range(height):
            for x in range(width):
                score = scores[y, x]
                if score < self.threshold:
                    continue
                
                # å‡ ä½•ä¿¡æ¯è§£ç 
                geo = geometry[:, y, x]
                d1, d2, d3, d4, angle = geo
                
                # è®¡ç®—æ—‹è½¬çŸ©å½¢
                cos, sin = math.cos(angle), math.sin(angle)
                offset_x, offset_y = x * 4.0, y * 4.0
                
                box_height = d1 + d3
                box_width = d2 + d4
                
                # è®¡ç®—ä¸­å¿ƒç‚¹
                center_x = offset_x + cos * (d2 - d4) / 2 - sin * (d1 - d3) / 2
                center_y = offset_y + sin * (d2 - d4) / 2 + cos * (d1 - d3) / 2
                
                # PP-OCRçš„æ—‹è½¬è§’åº¦å®šä¹‰æ˜¯ä»æ°´å¹³è½´é€†æ—¶é’ˆï¼ŒèŒƒå›´[-45, 45]ï¼ŒOpenCVéœ€è¦åº¦æ•°
                angle_deg = angle * (180 / math.pi)
                
                rot_rect = ((center_x, center_y), (box_width, box_height), angle_deg)
                
                rects.append(rot_rect)
                confidences.append(float(score))
                
        return rects, confidences
class UnifiedObjectDetector:
    """
    ä¸€ä¸ªç»Ÿä¸€çš„ç›®æ ‡æ£€æµ‹å™¨ï¼Œä½¿ç”¨YOLOv4-tinyè¯†åˆ«æ–‡æœ¬ã€è¡¨æ ¼å’ŒåŸºç¡€å›¾å½¢ã€‚
    ç‰ˆæœ¬: 2.0 - å®ç°äº†æ¨¡å‹çš„è‡ªåŠ¨ä¸‹è½½ã€éªŒè¯ä¸åŠ è½½ã€‚
    """
    def __init__(self, logger_func: Callable, cfg_path: str, weights_path: str, names_path: str):
        """
        UnifiedObjectDetector çš„æ„é€ å‡½æ•° (V3.32 - ç”¨æˆ·å¯é…ç½®æ¨¡å‹ç‰ˆ)ã€‚
        - ä½¿ç”¨ç”¨æˆ·æä¾›çš„è·¯å¾„åŠ è½½YOLOv4-tinyæ¨¡å‹ã€‚
        - ä¸å†æ‰§è¡Œè‡ªåŠ¨ä¸‹è½½ï¼Œåªæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚
        """
        self.log = logger_func
        self.net = None
        self.classes = []
        self.output_layers = []
        self.class_map = {
            "person": "text", "book": "text", "cell phone": "text",
            "laptop": "graphic", "tv": "graphic", "remote": "graphic",
            "dining table": "table"
        }

        # 1. æ£€æŸ¥ç”¨æˆ·æä¾›çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        for path, name in [(weights_path, "æƒé‡æ–‡ä»¶"), (cfg_path, "é…ç½®æ–‡ä»¶"), (names_path, "ç±»åˆ«æ–‡ä»¶")]:
            if not os.path.exists(path):
                self.log(f"âŒ YOLO {name} '{path}' ä¸å­˜åœ¨ï¼Œç»Ÿä¸€å¯¹è±¡æ£€æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚", "ERROR")
                messagebox.showerror("YOLOæ¨¡å‹æ–‡ä»¶ç¼ºå¤±", f"YOLO {name}æœªæ‰¾åˆ°ï¼š\n{path}\n\nè¯·åœ¨â€œå…¨å…ƒç´ æ£€æµ‹å¼•æ“â€è®¾ç½®ä¸­æŒ‡å®šæ­£ç¡®çš„æ–‡ä»¶è·¯å¾„ã€‚")
                return

        # 2. å°è¯•åŠ è½½YOLOç½‘ç»œ
        try:
            self.net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)
            self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
            self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            with open(names_path, "r", encoding='utf-8') as f:
                self.classes = [line.strip() for line in f.readlines()]

            layer_names = self.net.getLayerNames()
            unconnected_layers_indices = self.net.getUnconnectedOutLayers()
            if isinstance(unconnected_layers_indices, np.ndarray):
                unconnected_layers_indices = unconnected_layers_indices.flatten()
            self.output_layers = [layer_names[i - 1] for i in unconnected_layers_indices]
            
            self.log("âœ… ç”¨æˆ·æŒ‡å®šçš„YOLOv4-tinyç»Ÿä¸€å¯¹è±¡æ£€æµ‹å™¨åŠ è½½æˆåŠŸã€‚", "SUCCESS")

        except Exception as e:
            self.log(f"âŒ åŠ è½½ç”¨æˆ·æŒ‡å®šçš„YOLOæ¨¡å‹å¤±è´¥: {e}", "ERROR")
            messagebox.showerror("YOLOæ¨¡å‹åŠ è½½å¤±è´¥", f"åŠ è½½YOLOæ¨¡å‹æ—¶å‡ºé”™ï¼š\n{e}\n\nè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸”æœªæŸåã€‚")
            self.net = None
    
    
    
    
    def detect_all_objects(self, image: np.ndarray) -> List[Dict]:
        """
        åœ¨å›¾åƒä¸­æ£€æµ‹æ‰€æœ‰å¯¹è±¡ï¼ˆæ–‡æœ¬ã€è¡¨æ ¼ã€å›¾å½¢ï¼‰ã€‚
        è¿™æ˜¯ä¸€ä¸ªæ··åˆæ–¹æ³•ï¼Œç»“åˆäº†YOLOçš„æ·±åº¦å­¦ä¹ æ£€æµ‹å’Œç»å…¸CVçš„è½®å»“åˆ†æã€‚
        Args:
            image (np.ndarray): è¾“å…¥çš„BGRå›¾åƒã€‚
        Returns:
            List[Dict]: åŒ…å«æ‰€æœ‰æ£€æµ‹åˆ°å¯¹è±¡ä¿¡æ¯çš„åˆ—è¡¨ã€‚
        """
        if self.net is None:
            self.log("âš ï¸ YOLOç½‘ç»œæœªåŠ è½½ï¼Œè·³è¿‡ç»Ÿä¸€å¯¹è±¡æ£€æµ‹ã€‚", "WARNING")
            return []

        height, width, _ = image.shape
        
        # 1. ä½¿ç”¨YOLOè¿›è¡Œæ·±åº¦å­¦ä¹ å¯¹è±¡æ£€æµ‹
        blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)
        self.net.setInput(blob)
        outs = self.net.forward(self.output_layers)

        boxes = []
        confidences = []
        class_ids = []

        for out in outs:
            for detection in out:
                scores = detection[5:]
                class_id = np.argmax(scores)
                confidence = scores[class_id]
                if confidence > 0.3:  # ç½®ä¿¡åº¦é˜ˆå€¼
                    center_x = int(detection[0] * width)
                    center_y = int(detection[1] * height)
                    w = int(detection[2] * width)
                    h = int(detection[3] * height)
                    x = int(center_x - w / 2)
                    y = int(center_y - h / 2)
                    boxes.append([x, y, w, h])
                    confidences.append(float(confidence))
                    class_ids.append(class_id)
        
        # åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰ä»¥æ¶ˆé™¤é‡å çš„è¾¹ç•Œæ¡†
        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.3, 0.4)
        
        detected_objects = []
        if len(indexes) > 0:
            for i in indexes.flatten():
                x, y, w, h = boxes[i]
                label = self.classes[class_ids[i]]
                
                # ä½¿ç”¨ç±»åˆ«æ˜ å°„è½¬æ¢æ ‡ç­¾
                mapped_label = self.class_map.get(label, "unknown")
                
                # åªæ·»åŠ è¢«æ˜ å°„ä¸ºæœ‰æ•ˆç±»åˆ«çš„å¯¹è±¡
                if mapped_label != "unknown":
                    detected_objects.append({
                        "bbox": [x, y, x + w, y + h],
                        "label": mapped_label,
                        "confidence": confidences[i]
                    })

        # 2. ä½¿ç”¨ç»å…¸è®¡ç®—æœºè§†è§‰æ–¹æ³•è¡¥å……åŸºç¡€å›¾å½¢æ£€æµ‹
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        canny_edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(canny_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 200 or area > width * height * 0.8:
                continue

            peri = cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, 0.03 * peri, True)
            x, y, w, h = cv2.boundingRect(approx)
            shape_label = "unknown"

            if len(approx) == 4:
                roi = gray[y:y+h, x:x+w]
                # æ£‹ç›˜æ ¼/å›¾æ¡ˆçš„ç‰¹å¾ï¼šå†…éƒ¨æœ‰å¤§é‡è§’ç‚¹
                corners = cv2.goodFeaturesToTrack(roi, 30, 0.01, 10)
                if corners is not None and len(corners) > 20:
                    shape_label = "pattern"
                else:
                    shape_label = "rectangle"
            elif len(approx) > 7: # è¿‘ä¼¼ä¸ºåœ†
                (cx, cy), radius = cv2.minEnclosingCircle(contour)
                circle_area = np.pi * (radius ** 2)
                if circle_area > 0 and 0.8 < area / circle_area < 1.2:
                    shape_label = "ellipse"

            # çº¿æ¡çš„ç‰¹å¾ï¼šå®½é«˜æ¯”æç«¯
            if w > h * 8 or h > w * 8:
                shape_label = "line"
            
            if shape_label != "unknown":
                detected_objects.append({
                    "bbox": [x, y, x + w, y + h],
                    "label": shape_label,
                    "confidence": 0.95  # å‡ ä½•æ–¹æ³•ç¡®å®šæ€§é«˜ï¼Œç»™ä¸€ä¸ªè¾ƒé«˜çš„ç½®ä¿¡åº¦
                })

        return detected_objects
class OCRLanguage(Enum):
    """OCRè¯­è¨€æšä¸¾"""
    AUTO = "auto"          # è‡ªåŠ¨æ£€æµ‹
    CHINESE = "chi_sim"    # ç®€ä½“ä¸­æ–‡
    ENGLISH = "eng"        # è‹±æ–‡
    CHINESE_TRAD = "chi_tra"  # ç¹ä½“ä¸­æ–‡
    JAPANESE = "jpn"       # æ—¥æ–‡
    KOREAN = "kor"         # éŸ©æ–‡
    MULTI = "chi_sim+eng"  # ä¸­è‹±æ··åˆ


class TextQualityLevel(Enum):
    """æ–‡æœ¬å›¾åƒè´¨é‡ç­‰çº§æšä¸¾"""
    EXCELLENT = "excellent" # ä¼˜ç§€
    GOOD = "good"           # è‰¯å¥½
    FAIR = "fair"           # ä¸€èˆ¬
    POOR = "poor"           # å·®

class CVOCRException(Exception):
    """CVOCRè‡ªå®šä¹‰å¼‚å¸¸"""
    def __init__(self, message: str, error_code: str = None, details: dict = None):
        super().__init__(message)
        self.error_code = error_code
        self.details = details or {}






class ImageQualityLevel(Enum):
    """å›¾åƒè´¨é‡ç­‰çº§æšä¸¾"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
class TextOrientation(Enum):
    """æ–‡æœ¬æ–¹å‘æšä¸¾"""
    HORIZONTAL = "horizontal"
    VERTICAL = "vertical"
    MIXED = "mixed"


class CVOCRVersionManager:
    """CVOCRç‰ˆæœ¬ç®¡ç†å™¨ - å¤„ç†ä¸åŒç‰ˆæœ¬çš„å…¼å®¹æ€§"""
    
    @staticmethod
    def get_system_info() -> Dict[str, str]:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        return {
            'python_version': sys.version.split()[0],
            'platform': platform.system(),
            'platform_version': platform.version(),
            'architecture': platform.architecture()[0],
            'processor': platform.processor(),
            'hostname': platform.node()
        }
    
    @staticmethod
    def get_tesseract_version(tesseract_path: Optional[str] = None) -> str:
        """è·å–Tesseractç‰ˆæœ¬"""
        try:
            import pytesseract
            # å°è¯•ä½¿ç”¨ä¼ å…¥çš„è·¯å¾„ï¼Œå¦åˆ™ä½¿ç”¨ pytesseract.pytesseract.tesseract_cmd
            # å¦‚æœéƒ½æ²¡æœ‰ï¼Œåˆ™å›é€€åˆ°ç³»ç»ŸPATHä¸­çš„tesseract
            original_cmd = None
            if tesseract_path and os.path.exists(tesseract_path):
                original_cmd = pytesseract.pytesseract.tesseract_cmd
                pytesseract.pytesseract.tesseract_cmd = tesseract_path
            
            version = pytesseract.get_tesseract_version()
            
            
            if original_cmd is not None: 
                pytesseract.pytesseract.tesseract_cmd = original_cmd # æ¢å¤åŸè·¯å¾„
            return str(version)
        except ImportError:
            return "unknown (pytesseract not installed)"
        except Exception as e:
            logger.warning(f"è·å–Tesseractç‰ˆæœ¬å¤±è´¥: {e}")
            return "unknown (Error)"
    
    @staticmethod
    def get_transformers_version() -> str:
        """è·å–Transformersç‰ˆæœ¬"""
        try:
            import transformers
            return transformers.__version__
        except ImportError:
            return "unknown (transformers not installed)"
        except Exception as e:
            logger.warning(f"è·å–Transformersç‰ˆæœ¬å¤±è´¥: {e}")
            return "unknown (Error)"
    
    @staticmethod
    def get_opencv_version() -> str:
        """è·å–OpenCVç‰ˆæœ¬"""
        try:
            import cv2
            return cv2.__version__
        except ImportError:
            return "unknown (opencv not installed)"
        except Exception as e:
            logger.warning(f"è·å–OpenCVç‰ˆæœ¬å¤±è´¥: {e}")
            return "unknown (Error)"
    
    @staticmethod
    def get_torch_version() -> str:
        """è·å–PyTorchç‰ˆæœ¬"""
        try:
            import torch
            return torch.__version__
        except ImportError:
            return "unknown (torch not installed)"
        except Exception as e:
            logger.warning(f"è·å–PyTorchç‰ˆæœ¬å¤±è´¥: {e}")
            return "unknown (Error)"
    
    @staticmethod
    def check_compatibility(tesseract_path: Optional[str] = None) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§"""
        issues = []
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        python_version = tuple(map(int, sys.version.split()[0].split('.')[:2]))
        if python_version < (3, 8):
            issues.append(f"Pythonç‰ˆæœ¬è¿‡ä½: {sys.version.split()[0]}ï¼Œå»ºè®®å‡çº§åˆ°3.8+")
        
        # æ£€æŸ¥PyTorch
        try:
            import torch
            torch_version = torch.__version__
            if tuple(map(int, torch_version.split('.')[:2])) < (1, 12):
                issues.append(f"PyTorchç‰ˆæœ¬è¿‡ä½: {torch_version}ï¼Œå»ºè®®å‡çº§åˆ°1.12+")
        except ImportError:
            issues.append("PyTorchæœªå®‰è£… - é«˜çº§åŠŸèƒ½éœ€è¦PyTorchæ”¯æŒ")
        except Exception as e:
            issues.append(f"æ£€æŸ¥PyTorchç‰ˆæœ¬å¼‚å¸¸: {e}")
        
        # æ£€æŸ¥Tesseract
        try:
            import pytesseract
            # å°è¯•è·å–ç‰ˆæœ¬ï¼Œä¼šè§¦å‘ Tesseract å¯æ‰§è¡Œæ–‡ä»¶çš„æ£€æŸ¥
            CVOCRVersionManager.get_tesseract_version(tesseract_path)
        except ImportError:
            issues.append("pytesseractæœªå®‰è£… - åŸºç¡€OCRåŠŸèƒ½ä¸å¯ç”¨")
        except Exception as e:
            issues.append(f"Tesseractä¸å¯ç”¨: {e}")
        
        # æ£€æŸ¥OpenCV
        try:
            import cv2
            cv_version = cv2.__version__
            if tuple(map(int, cv_version.split('.')[:2])) < (4, 5):
                issues.append(f"OpenCVç‰ˆæœ¬è¿‡ä½: {cv_version}ï¼Œå»ºè®®å‡çº§åˆ°4.5+")
        except ImportError:
            issues.append("OpenCVæœªå®‰è£… - å›¾åƒå¤„ç†åŠŸèƒ½ä¸å¯ç”¨")
        except Exception as e:
            issues.append(f"æ£€æŸ¥OpenCVç‰ˆæœ¬å¼‚å¸¸: {e}")
        
        # æ£€æŸ¥transformers
        try:
            import transformers
            trans_version = transformers.__version__
            if tuple(map(int, trans_version.split('.')[:2])) < (4, 25):
                issues.append(f"Transformersç‰ˆæœ¬è¿‡ä½: {trans_version}ï¼Œå»ºè®®å‡çº§åˆ°4.25+")
        except ImportError:
            issues.append("Transformersæœªå®‰è£… - AIå¢å¼ºåŠŸèƒ½ä¸å¯ç”¨")
        except Exception as e:
            issues.append(f"æ£€æŸ¥Transformersç‰ˆæœ¬å¼‚å¸¸: {e}")
        
        # æ£€æŸ¥PIL/Pillow
        try:
            from PIL import Image
            import PIL
            pil_version = PIL.__version__
            if tuple(map(int, pil_version.split('.')[:2])) < (9, 0):
                issues.append(f"Pillowç‰ˆæœ¬è¿‡ä½: {pil_version}ï¼Œå»ºè®®å‡çº§åˆ°9.0+")
        except ImportError:
            issues.append("Pillowæœªå®‰è£… - å›¾åƒå¤„ç†åŠŸèƒ½ä¸å¯ç”¨")
        
        # æ£€æŸ¥NumPy
        try:
            import numpy
            np_version = numpy.__version__
            if tuple(map(int, np_version.split('.')[:2])) < (1, 21):
                issues.append(f"NumPyç‰ˆæœ¬è¿‡ä½: {np_version}ï¼Œå»ºè®®å‡çº§åˆ°1.21+")
        except ImportError:
            issues.append("NumPyæœªå®‰è£…")
        
        return len(issues) == 0, issues
    
    @staticmethod
    def get_dependency_versions(tesseract_path: Optional[str] = None) -> Dict[str, str]:
        """è·å–æ‰€æœ‰ä¾èµ–ç‰ˆæœ¬ä¿¡æ¯"""
        versions = {
            'cvocr_gui': CVOCRConstants.VERSION,
            'python': sys.version.split()[0],
            'tesseract': CVOCRVersionManager.get_tesseract_version(tesseract_path),
            'transformers': CVOCRVersionManager.get_transformers_version(),
            'opencv': CVOCRVersionManager.get_opencv_version(),
            'torch': CVOCRVersionManager.get_torch_version()
        }
        
        # è·å–å…¶ä»–åº“ç‰ˆæœ¬
        # --- ä¿®æ­£5: æ·»åŠ  'psutil' åˆ°ç‰ˆæœ¬æ£€æŸ¥åˆ—è¡¨ ---
        for lib_name in ['numpy', 'PIL', 'tkinter', 'psutil']:
            try:
                lib = __import__(lib_name)
                # tkinter and PIL might not have __version__ in the same way
                if lib_name == 'PIL':
                    # Pillowåº“çš„ç‰ˆæœ¬ä¿¡æ¯å­˜å‚¨åœ¨PIL.__version__
                    from PIL import __version__ as pil_version
                    versions[lib_name] = pil_version
                elif lib_name == 'tkinter':
                    # tkinterçš„ç‰ˆæœ¬ä¸å…¶ä¾èµ–çš„Tcl/Tkç‰ˆæœ¬ç›¸å…³
                    import tkinter as tk
                    versions[lib_name] = tk.Tcl().eval('info patchlevel')
                else:
                    # å¯¹äºå¤§å¤šæ•°åº“ï¼Œå¯ä»¥ç›´æ¥è·å–__version__å±æ€§
                    versions[lib_name] = getattr(lib, '__version__', 'unknown')
            except ImportError:
                versions[lib_name] = 'not installed'
            except Exception:
                versions[lib_name] = 'unknown'
        
        return versions
        
        
class AdvancedTextImageProcessor:
    """é«˜çº§æ–‡æœ¬å›¾åƒå¤„ç†å™¨ - ä¸ºOCRè¯†åˆ«ä¼˜åŒ–"""
    
    def __init__(self):
        # é»˜è®¤é…ç½®ï¼Œè¿™äº›å€¼ä¼šè¢«ä¼ å…¥çš„ options æˆ– GUI çš„è®¾ç½®è¦†ç›–
        self.config = {
            # å›¾åƒå°ºå¯¸å‚æ•°
            'target_input_size': 1024,
            'max_image_size': CVOCRConstants.MAX_IMAGE_SIZE,
            'optimal_ocr_size': 1024,
            'min_image_size': CVOCRConstants.MIN_IMAGE_SIZE,
            
            # å¢å¼ºçš„å¯¹æ¯”åº¦å’Œé”åŒ–å‚æ•°èŒƒå›´ (å¦‚æœä¸ç”¨GUI sliderï¼Œå¯ç›´æ¥è®¾ä¸ºå›ºå®šå€¼)
            'contrast_factor_range': (1.1, 2.0),
            'brightness_adjustment_range': (-0.15, 0.25),
            'sharpness_factor_range': (1.0, 2.5),
            'gamma_correction_range': (0.8, 1.4),
            
            # é«˜çº§é™å™ªå‚æ•°èŒƒå›´
            'bilateral_d_range': (5, 13),
            'bilateral_sigma_color_range': (25, 100),
            'bilateral_sigma_space_range': (25, 100),
            'gaussian_kernel_size_range': (3, 7),
            
            # OCRä¼˜åŒ–å‚æ•° (åœ¨GUIä¸­é€šè¿‡settingsä¼ é€’ï¼Œè¿™é‡Œä½œä¸ºé»˜è®¤å€¼)
            'enable_deskew': True,
            'deskew_angle_threshold': 0.5,
            'enable_deblur': True, # æ¨¡ç³Šæ£€æµ‹/ä¿®å¤ï¼Œç›®å‰ä»£ç ä¸­æœªæ˜ç¡®å®ç°ï¼Œå¯ä½œä¸ºæœªæ¥æ‰©å±•ç‚¹
            'enable_text_enhancement': True, # æ–‡æœ¬å¢å¼ºï¼Œç”±å½¢æ€å­¦å’Œé”åŒ–ç­‰å®ç°
            'enable_morphology': True, # å½¢æ€å­¦æ“ä½œ
            'enable_adaptive_threshold': True, # è‡ªé€‚åº”äºŒå€¼åŒ–
            'remove_borders': True, # ç§»é™¤å›¾åƒè¾¹æ¡†
            'border_threshold': 10, # è¾¹æ¡†ç§»é™¤é˜ˆå€¼
            'crop_to_content': True, # è£å‰ªåˆ°å®é™…å†…å®¹
            'page_border_detection': True, # é¡µé¢è¾¹æ¡†æ£€æµ‹ (ç”¨äºé€è§†æ ¡æ­£ç­‰)
            'shadow_removal': True, # é˜´å½±ç§»é™¤
            'denoise_strength': 0.1, # é«˜çº§é™å™ªå¼ºåº¦ (å¯¹åº”fastNlMeansDenoising)
            'edge_preservation': 0.8, # è¾¹ç¼˜ä¿ç•™å¼ºåº¦ (ä¸é«˜çº§é™å™ªé…åˆ)
            'unsharp_mask': True,     # åé”åŒ–æ©æ¨¡
            'unsharp_radius': 1.0,    # åé”åŒ–æ©æ¨¡åŠå¾„
            'unsharp_amount': 1.0,    # åé”åŒ–æ©æ¨¡å¼ºåº¦
            'histogram_equalization': True, # ç›´æ–¹å›¾å‡è¡¡åŒ–
            'bilateral_filter': True, # åŒè¾¹æ»¤æ³¢
            'bilateral_d': 9, # åŒè¾¹æ»¤æ³¢ç›´å¾„
            'bilateral_sigma_color': 75.0, # åŒè¾¹æ»¤æ³¢é¢œè‰²ç©ºé—´æ ‡å‡†å·®
            'bilateral_sigma_space': 75.0, # åŒè¾¹æ»¤æ³¢ç©ºé—´æ ‡å‡†å·®
            'apply_clahe': True, # CLAHE (å¯¹æ¯”åº¦å—é™è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡)
            'clahe_clip_limit': 2.0, # CLAHE è£å‰ªé™åˆ¶
            'clahe_tile_grid_size': (8, 8), # CLAHE ç½‘æ ¼å¤§å°
            'adaptive_block_size': 11, # è‡ªé€‚åº”é˜ˆå€¼å—å¤§å°
            'adaptive_c_constant': 2, # è‡ªé€‚åº”é˜ˆå€¼ C å¸¸é‡
        }
        
        # å¤„ç†ç»“æœç¼“å­˜
        self._processing_cache = {}
        self._cache_max_size = 50 # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        self._cache_expiry = {} # ç¼“å­˜è¿‡æœŸæ—¶é—´è®°å½•
        
        # æ€§èƒ½ç›‘æ§
        self._processing_stats = {
            'total_processed': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'average_processing_time': 0.0,
            'processing_times': deque(maxlen=100) # è®°å½•æœ€è¿‘100æ¬¡å¤„ç†æ—¶é—´
        }
        
        logger.info("é«˜çº§æ–‡æœ¬å›¾åƒå¤„ç†å™¨å·²åˆå§‹åŒ–")

    @staticmethod
    def validate_image(image_path: str) -> Tuple[bool, str]:
        """
        å¢å¼ºç‰ˆå›¾åƒéªŒè¯æ–¹æ³•ã€‚
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€å¤§å°ã€æ ¼å¼ã€å°ºå¯¸åŠæ•°æ®å®Œæ•´æ€§ã€‚
        """
        if not isinstance(image_path, (str, Path)):
            return False, "æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„ç±»å‹"
        
        image_path = str(image_path)
        
        if not os.path.exists(image_path):
            return False, "æ–‡ä»¶ä¸å­˜åœ¨"
        
        try:
            file_size = os.path.getsize(image_path)
            if file_size == 0:
                return False, "æ–‡ä»¶ä¸ºç©º"
            
            if file_size > CVOCRConstants.MAX_FILE_SIZE:
                return False, f"æ–‡ä»¶è¿‡å¤§ (è¶…è¿‡{CVOCRConstants.MAX_FILE_SIZE // (1024*1024)}MB)"
            
            file_ext = os.path.splitext(image_path)[1].lower()
            if file_ext not in CVOCRConstants.SUPPORTED_IMAGE_FORMATS:
                return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}"
            
            with Image.open(image_path) as img:
                width, height = img.size
                
                if width == 0 or height == 0:
                    return False, "å›¾åƒå°ºå¯¸ä¸ºé›¶"
                
                if width < CVOCRConstants.MIN_IMAGE_SIZE or height < CVOCRConstants.MIN_IMAGE_SIZE:
                    return False, f"å›¾åƒå°ºå¯¸è¿‡å° (å°äº{CVOCRConstants.MIN_IMAGE_SIZE}x{CVOCRConstants.MIN_IMAGE_SIZE}åƒç´ )"
                
                if width > CVOCRConstants.MAX_IMAGE_SIZE or height > CVOCRConstants.MAX_IMAGE_SIZE:
                    return False, f"å›¾åƒå°ºå¯¸è¿‡å¤§ (å¤§äº{CVOCRConstants.MAX_IMAGE_SIZE}x{CVOCRConstants.MAX_IMAGE_SIZE}åƒç´ )"
                
                if img.mode not in ['RGB', 'RGBA', 'L', 'P', '1', 'CMYK']:
                    return False, f"ä¸æ”¯æŒçš„å›¾åƒæ¨¡å¼: {img.mode}"
                
                try:
                    img.load()
                    img_array = np.array(img)
                    
                    if img_array.std() < 1: # æ£€æŸ¥å›¾åƒå†…å®¹å¤šæ ·æ€§ï¼Œé˜²æ­¢å…¨é»‘/å…¨ç™½æˆ–æŸåå›¾åƒ
                        return False, "å›¾åƒå†…å®¹è¿‡äºå•è°ƒï¼Œå¯èƒ½æŸåæˆ–æ— æœ‰æ•ˆå†…å®¹"
                    
                    if len(img_array.shape) > 3: # ä¸æ”¯æŒ4Dä»¥ä¸Šå›¾åƒ
                        return False, "ä¸æ”¯æŒçš„å›¾åƒç»´åº¦"
                        
                except Exception as e:
                    return False, f"å›¾åƒæ•°æ®æŸå: {str(e)}"
                
                return True, "å›¾åƒæœ‰æ•ˆ"
                
        except Exception as e:
            return False, f"å›¾åƒæ ¼å¼é”™è¯¯æˆ–æŸå: {str(e)}"
    
    def intelligent_preprocess_image(self, image_path: str, **options) -> Tuple[Optional[np.ndarray], str, Dict]:
        """
        ã€æœ€ç»ˆé‡æ„ç‰ˆã€‘æ™ºèƒ½å›¾åƒé¢„å¤„ç†æ ¸å¿ƒæ–¹æ³•
        - æ ¹æ®ç”¨æˆ·è®¾ç½®ï¼ˆå…¨å…ƒç´ æ£€æµ‹ vs çº¯æ–‡æœ¬è¯†åˆ«ï¼‰é€‰æ‹©åˆé€‚çš„é¢„å¤„ç†ç­–ç•¥ã€‚
        - åŠ¨æ€åº”ç”¨UIé€‰é¡¹ï¼Œç¡®ä¿ç”¨æˆ·è®¾ç½®åœ¨æ‰€æœ‰å­æµç¨‹ä¸­ç”Ÿæ•ˆã€‚
        - ä¸ºé¢„è§ˆå’Œæ—¥å¿—æä¾›æ¸…æ™°ã€è¯¦ç»†çš„å¤„ç†æ­¥éª¤ä¿¡æ¯ã€‚
        """
        start_time = time.time()
        
        try:
            # 1. éªŒè¯è¾“å…¥å›¾åƒçš„æœ‰æ•ˆæ€§
            is_valid, validation_msg = self.validate_image(image_path)
            if not is_valid:
                logger.error(f"å›¾åƒéªŒè¯å¤±è´¥: {validation_msg}")
                return None, f"å›¾åƒéªŒè¯å¤±è´¥: {validation_msg}", {}

            # 2. å…³é”®æ­¥éª¤ï¼šå°†ä¼ å…¥çš„optionsåŠ¨æ€æ›´æ–°åˆ°å®ä¾‹é…ç½®ä¸­
            self.config.update(options)
            logger.debug(f"DEBUG: Preprocessing config updated with options from UI: {options}")
            
            # 3. ç”Ÿæˆç¼“å­˜é”®å¹¶æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(image_path, options)
            cached_result = self._get_from_cache(cache_key)
            if cached_result is not None:
                self._processing_stats['cache_hits'] += 1
                logger.info("ä½¿ç”¨ç¼“å­˜çš„å›¾åƒé¢„å¤„ç†ç»“æœã€‚")
                return cached_result['image'], cached_result['message'], cached_result['metadata']
            
            self._processing_stats['cache_misses'] += 1
            
            # 4. è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                try:
                    pil_img = Image.open(image_path).convert('RGB')
                    image = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                except Exception as e:
                    raise CVOCRException(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {str(e)}", "IMAGE_READ_ERROR")
            
            original_shape = image.shape
            logger.info(f"å¼€å§‹æ™ºèƒ½OCRé¢„å¤„ç†å›¾åƒ: {image_path}, åŸå§‹å°ºå¯¸: {original_shape}")
            
            # 5. æ ¹æ®æ›´æ–°åçš„ self.config å†³å®šé¢„å¤„ç†ç­–ç•¥
            enable_preprocessing = self.config.get('enable_preprocessing', False)
            use_advanced_segmentation = self.config.get('enable_advanced_segmentation', False)
            
            processed_image = image.copy()
            process_operations = []
            quality_level = TextQualityLevel.FAIR
            quality_metrics = {}

            if enable_preprocessing:
                if use_advanced_segmentation:
                    logger.info("å·¥ä½œæµ: ä¸ºå…¨å…ƒç´ æ£€æµ‹å‡†å¤‡å›¾åƒï¼ˆç®€åŒ–é¢„å¤„ç†ï¼‰")
                    process_operations.append("[æ¨¡å¼: å…¨å…ƒç´ æ£€æµ‹å‡†å¤‡]")
                    processed_image = self._optimize_image_size(processed_image)
                    process_operations.append("å°ºå¯¸ä¸é€šé“æ ‡å‡†åŒ–")
                    if len(processed_image.shape) == 2:
                        processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR)
                    elif processed_image.shape[2] == 4:
                        processed_image = cv2.cvtColor(processed_image, cv2.COLOR_BGRA2BGR)
                    if self.config.get('enable_deskew', False):
                        gray_for_deskew = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                        deskewed_gray, angle = self._deskew_image(gray_for_deskew, self.config.get('deskew_angle_threshold', 0.5))
                        if angle != 0.0:
                            center = (image.shape[1] // 2, image.shape[0] // 2)
                            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
                            processed_image = cv2.warpAffine(processed_image, rotation_matrix,
                                                       (image.shape[1], image.shape[0]),
                                                       flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
                            process_operations.append(f"å€¾æ–œæ ¡æ­£({angle:.2f}Â°)")
                    process_operations.append("(æ³¨: æ­¤æ¨¡å¼ä¸‹è·³è¿‡å¤æ‚å¢å¼ºä»¥ä¿è¯æ£€æµ‹ç²¾åº¦)")
                else:
                    logger.info("å·¥ä½œæµ: ä¸ºæ•´é¡µçº¯æ–‡æœ¬è¯†åˆ«è¿›è¡Œå…¨é¢é¢„å¤„ç†")
                    process_operations.append("[æ¨¡å¼: æ•´é¡µçº¯æ–‡æœ¬è¯†åˆ«]")
                    processed_image, adaptive_ops = self.adaptive_text_preprocessing(image, **self.config)
                    process_operations.extend(adaptive_ops)
            else:
                logger.info("å·¥ä½œæµ: æ™ºèƒ½é¢„å¤„ç†å·²ç¦ç”¨")
                process_operations.append("[æ¨¡å¼: é¢„å¤„ç†å·²ç¦ç”¨]")
                processed_image = self._optimize_image_size(image)
                process_operations.append("åŸºç¡€å°ºå¯¸ä¼˜åŒ–")
                if len(processed_image.shape) == 2:
                    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR)
                    process_operations.append("ç°åº¦è½¬BGR")

            # 6. è®°å½•å¤„ç†æ—¶é—´å’Œå…ƒæ•°æ®
            processing_time = time.time() - start_time
            self._update_processing_stats(processing_time)
            
            
            

            metadata = {
                
                'quality_level': quality_level.value if enable_preprocessing and not use_advanced_segmentation else 'N/A',
                'quality_score': quality_metrics.get('quality_score', 0) if enable_preprocessing and not use_advanced_segmentation else 'N/A',
                'quality_metrics': quality_metrics if enable_preprocessing and not use_advanced_segmentation else {},
                'operations': process_operations,
                'processing_time': processing_time,
                'original_shape': original_shape,
                'final_shape': processed_image.shape,
                'settings': options,
                'timestamp': datetime.now().isoformat()
            }
            
            # 7. å°†å¤„ç†ç»“æœæ·»åŠ åˆ°ç¼“å­˜
            cache_data = {
                'image': processed_image.copy(),
                'message': "æ™ºèƒ½OCRé¢„å¤„ç†æˆåŠŸ" if enable_preprocessing else "åŸºç¡€å¤„ç†æˆåŠŸ",
                'metadata': metadata
            }
            self._add_to_cache(cache_key, cache_data)
            
            success_msg = f"{'æ™ºèƒ½OCRé¢„å¤„ç†æˆåŠŸ' if enable_preprocessing else 'åŸºç¡€å¤„ç†æˆåŠŸ'} (è€—æ—¶: {processing_time:.2f}s)"
            logger.info(f"{success_msg}, åº”ç”¨æ“ä½œ: {', '.join(metadata['operations'])}")
            
            self._processing_stats['total_processed'] += 1
            
            return processed_image, success_msg, metadata
            
        except CVOCRException as e:
            raise e
        except Exception as e:
            error_msg = f"æ™ºèƒ½OCRé¢„å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(f"{error_msg}\n{traceback.format_exc()}")
            return None, error_msg, {'error': str(e), 'traceback': traceback.format_exc()}
    
    
    
    
    def assess_text_image_quality(self, image: np.ndarray) -> Tuple[TextQualityLevel, Dict]:
        """
        æ–‡æœ¬å›¾åƒè´¨é‡è¯„ä¼°æ–¹æ³•ã€‚
        è¯„ä¼°å›¾åƒçš„å¯¹æ¯”åº¦ã€æ¸…æ™°åº¦ã€äº®åº¦ã€å™ªå£°å’Œæ–‡æœ¬ç‰¹å¾ï¼Œè¿”å›ä¸€ä¸ªè´¨é‡ç­‰çº§å’Œè¯¦ç»†æŒ‡æ ‡ã€‚
        """
        try:
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()
            
            metrics = {}
            
            # å¯¹æ¯”åº¦è¯„ä¼° (æ ‡å‡†å·®å’Œå‡å€¼)
            contrast_std = np.std(gray)
            contrast_mean = np.mean(gray)
            metrics['contrast_std'] = float(contrast_std)
            metrics['contrast_mean'] = float(contrast_mean)
            
            # æ¸…æ™°åº¦è¯„ä¼° (æ‹‰æ™®æ‹‰æ–¯ç®—å­æ–¹å·®å’ŒSobelè¾¹ç¼˜å¼ºåº¦)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)
            sobel_mean = np.mean(sobel_combined)
            
            metrics['sharpness_laplacian'] = float(laplacian_var)
            metrics['sharpness_sobel'] = float(sobel_mean)
            
            # äº®åº¦åˆ†å¸ƒè¯„ä¼° (å‡å€¼ã€æ ‡å‡†å·®å’Œç†µ)
            brightness_mean = np.mean(gray)
            brightness_std = np.std(gray)
            brightness_hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            brightness_entropy = -np.sum((brightness_hist / np.sum(brightness_hist)) * 
                                        np.log2((brightness_hist / np.sum(brightness_hist)) + 1e-10))
            
            metrics['brightness_mean'] = float(brightness_mean)
            metrics['brightness_std'] = float(brightness_std)
            metrics['brightness_entropy'] = float(brightness_entropy)
            
            # å™ªå£°è¯„ä¼°
            noise_level = self._estimate_noise(gray)
            metrics['noise_level'] = float(noise_level)
            
            # æ–‡æœ¬ç‰¹å¾æ£€æµ‹
            text_features_score = self._assess_text_features(gray)
            metrics['text_features_score'] = float(text_features_score)
            
            # ç»“æ„ç‰¹å¾è¯„ä¼°
            structure_score = self._assess_structure_features(gray)
            metrics['structure_score'] = float(structure_score)
            
            # ç»¼åˆè´¨é‡è¯„åˆ†
            quality_score = self._calculate_text_quality_score(metrics)
            metrics['quality_score'] = float(quality_score)
            
            # æ ¹æ®ç»¼åˆè¯„åˆ†ç¡®å®šè´¨é‡ç­‰çº§
            if quality_score >= 85:
                level = TextQualityLevel.EXCELLENT
            elif quality_score >= 70:
                level = TextQualityLevel.GOOD
            elif quality_score >= 50:
                level = TextQualityLevel.FAIR
            else:
                level = TextQualityLevel.POOR
            
            return level, metrics
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬å›¾åƒè´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return TextQualityLevel.FAIR, {'error': str(e)}
    
    def _assess_text_features(self, gray: np.ndarray) -> float:
        """è¯„ä¼°æ–‡æœ¬ç‰¹å¾ï¼Œä¾‹å¦‚è¾¹ç¼˜å¯†åº¦ã€çº¿æ¡å¯†åº¦å’Œæ–‡æœ¬åŒºåŸŸæ•°é‡ã€‚"""
        try:
            # è¾¹ç¼˜æ£€æµ‹ (Canny)
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])
            
            # æ°´å¹³å’Œå‚ç›´çº¿æ£€æµ‹ (å½¢æ€å­¦å¼€è¿ç®—)
            kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
            kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))
            
            horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_h)
            vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel_v)
            
            h_line_density = np.sum(horizontal_lines > 0) / (gray.shape[0] * gray.shape[1])
            v_line_density = np.sum(vertical_lines > 0) / (gray.shape[0] * gray.shape[1])
            
            # æ–‡æœ¬åŒºåŸŸæ£€æµ‹ (MSERï¼Œéœ€è¦å®‰è£…opencv-contrib-python)
            try:
                mser = cv2.MSER_create()
                regions, _ = mser.detectRegions(gray)
                text_region_score = min(len(regions) / 100, 1.0)  # å½’ä¸€åŒ–å¾—åˆ†
            except Exception:
                logger.warning("MSERæ–‡æœ¬åŒºåŸŸæ£€æµ‹å¤±è´¥ï¼Œå¯èƒ½ç¼ºå°‘opencv-contrib-pythonã€‚ä½¿ç”¨é»˜è®¤åˆ†æ•°ã€‚")
                text_region_score = 0.5 # å¤±è´¥æ—¶ä½¿ç”¨ä¸€ä¸ªä¸­ç­‰åˆ†æ•°
            
            # æ–‡æœ¬ç‰¹å¾ç»¼åˆè¯„åˆ†
            text_score = (
                edge_density * 100 + 
                h_line_density * 200 + 
                v_line_density * 100 +
                text_region_score * 50
            )
            return min(text_score, 100)
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬ç‰¹å¾è¯„ä¼°å¤±è´¥: {e}")
            return 50.0
    
    def _assess_structure_features(self, gray: np.ndarray) -> float:
        """è¯„ä¼°å›¾åƒçš„ç»“æ„ç‰¹å¾ï¼Œä¾‹å¦‚æ¢¯åº¦å¹…åº¦å’Œå±€éƒ¨äºŒå€¼æ¨¡å¼ (LBP) ç‰¹å¾ã€‚"""
        try:
            # è®¡ç®—å›¾åƒçš„æ¢¯åº¦ (Sobel)
            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            
            # æ¢¯åº¦å¹…å€¼å‡å€¼
            grad_mag = np.sqrt(grad_x**2 + grad_y**2)
            structure_score = np.mean(grad_mag) / 255 * 100
            
            # LBPç‰¹å¾ (éœ€è¦scikit-imageåº“)
            try:
                from skimage import feature
                lbp = feature.local_binary_pattern(gray, 8, 1, method='uniform')
                lbp_hist = np.histogram(lbp, bins=10)[0]
                lbp_uniformity = np.std(lbp_hist)
                structure_score += lbp_uniformity / 100 # å°†å‡åŒ€æ€§åŠ å…¥ç»“æ„å¾—åˆ†
            except ImportError:
                logger.warning("scikit-imageæœªå®‰è£…ï¼Œæ— æ³•è¿›è¡ŒLBPç‰¹å¾è¯„ä¼°ã€‚")
                pass # å¦‚æœæ²¡æœ‰scikit-imageï¼Œåˆ™è·³è¿‡LBP
            
            return min(structure_score, 100)
            
        except Exception as e:
            logger.error(f"ç»“æ„ç‰¹å¾è¯„ä¼°å¤±è´¥: {e}")
            return 50.0
    
    def _estimate_noise(self, gray: np.ndarray) -> float:
        """å™ªå£°ä¼°è®¡æ–¹æ³•ï¼Œä½¿ç”¨é«˜é€šæ»¤æ³¢å™¨å’Œç®€åŒ–çš„Wieneræ»¤æ³¢åŸç†ã€‚"""
        try:
            # ä½¿ç”¨é«˜é€šæ»¤æ³¢å™¨ä¼°è®¡å™ªå£° (æ‹‰æ™®æ‹‰æ–¯ç®—å­)
            kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])
            convolved = cv2.filter2D(gray, cv2.CV_64F, kernel)
            noise = np.var(convolved) / 1000 # ç»éªŒæ€§ç¼©æ”¾
            
            # ä½¿ç”¨Wieneræ»¤æ³¢åŸç†ä¼°è®¡å™ªå£° (å›¾åƒå‡å»é«˜æ–¯æ¨¡ç³Šåçš„å·®å¼‚)
            try:
                blurred = cv2.GaussianBlur(gray, (5, 5), 0)
                noise_alt = np.mean((gray.astype(float) - blurred.astype(float))**2)
                noise = (noise + noise_alt / 1000) / 2 # ç»“åˆä¸¤ç§ä¼°è®¡
            except Exception:
                pass # å¤±è´¥æ—¶ä¿æŒåŸæ ·
            
            return min(noise, 100)
            
        except Exception as e:
            logger.error(f"å™ªå£°ä¼°è®¡å¤±è´¥: {e}")
            return 50.0
    
    def _calculate_text_quality_score(self, metrics: Dict) -> float:
        """æ ¹æ®å„é¡¹è¯„ä¼°æŒ‡æ ‡ï¼Œè®¡ç®—æœ€ç»ˆçš„ç»¼åˆæ–‡æœ¬è´¨é‡è¯„åˆ†ã€‚"""
        try:
            # å¯¹æ¯”åº¦è¯„åˆ† (å½’ä¸€åŒ–åˆ°0-100)
            contrast_score = min(max(metrics.get('contrast_std', 0) / 80 * 100, 0), 100)
            
            # æ¸…æ™°åº¦è¯„åˆ† (ç»“åˆæ‹‰æ™®æ‹‰æ–¯å’ŒSobel)
            sharpness_score = min(metrics.get('sharpness_laplacian', 0) / 1000 * 100, 100)
            sobel_score = min(metrics.get('sharpness_sobel', 0) / 50 * 100, 100)
            combined_sharpness = (sharpness_score + sobel_score) / 2
            
            # å™ªå£°è¯„åˆ† (100 - å™ªå£°çº§åˆ«)
            noise_score = max(100 - metrics.get('noise_level', 0), 0)
            
            # æ–‡æœ¬ç‰¹å¾è¯„åˆ† (ç›´æ¥ä½¿ç”¨è¯„ä¼°ç»“æœ)
            text_features_score = metrics.get('text_features_score', 0)
            
            # äº®åº¦è¯„åˆ† (ä¸­å¿ƒå€¼128æœ€ä½³ï¼Œåç¦»è¶Šå¤§åˆ†æ•°è¶Šä½)
            brightness = metrics.get('brightness_mean', 128)
            brightness_score = 100 - abs(brightness - 128) / 128 * 100
            brightness_score = max(brightness_score, 0)
            
            # ç»“æ„ç‰¹å¾è¯„åˆ†
            structure_score = metrics.get('structure_score', 50)
            
            # äº®åº¦åˆ†å¸ƒç†µè¯„åˆ† (ç†µè¶Šé«˜ï¼Œåˆ†å¸ƒè¶Šå‡åŒ€ï¼Œè¶Šå¥½)
            brightness_entropy = metrics.get('brightness_entropy', 5)
            entropy_score = min(brightness_entropy / 8 * 100, 100) # ç»éªŒæ€§å½’ä¸€åŒ–
            
            # æƒé‡åˆ†é…ï¼Œè®¡ç®—æ€»åˆ†
            total_score = (
                contrast_score * 0.20 +
                combined_sharpness * 0.25 +
                noise_score * 0.15 +
                brightness_score * 0.15 +
                text_features_score * 0.15 +
                structure_score * 0.05 +
                entropy_score * 0.05
            )
            
            return max(min(total_score, 100), 0) # ç¡®ä¿åˆ†æ•°åœ¨0-100ä¹‹é—´
            
        except Exception as e:
            logger.error(f"è´¨é‡è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
            return 50.0 # å¤±è´¥æ—¶è¿”å›ä¸­ç­‰åˆ†æ•°
    
    def adaptive_text_preprocessing(self, image: np.ndarray, quality_level: TextQualityLevel = None, **options) -> Tuple[np.ndarray, List[str]]:
        """
        ã€V4.1 - å®Œå…¨æ‰‹åŠ¨æ§åˆ¶æœ€ç»ˆç‰ˆã€‘
        é¢„å¤„ç†æµç¨‹ä¸¥æ ¼ç”±ç”¨æˆ·é€šè¿‡ `options` å­—å…¸ä¼ é€’çš„å¼€å…³å†³å®šã€‚
        åºŸé™¤æ‰€æœ‰åŸºäºå›¾åƒè´¨é‡çš„è‡ªåŠ¨åˆ¤æ–­ç­–ç•¥ï¼Œå®ç°å®Œå…¨çš„ç”¨æˆ·æ§åˆ¶ã€‚
        """
        try:
            operations = []
            # ä»åŸå§‹å›¾åƒå¼€å§‹ï¼Œæ ¹æ®åç»­æ­¥éª¤å†³å®šæ˜¯å¦è½¬æ¢é¢œè‰²ç©ºé—´
            processed_image = image.copy()
            
            # --- æ ¸å¿ƒæµç¨‹ï¼šä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·å¼€å…³é¡ºåºæ‰§è¡Œ ---

            # æ­¥éª¤ 1: è½¬æ¢ä¸ºç°åº¦å›¾ (å¦‚æœå¯ç”¨)
            # è¿™æ˜¯åç»­å¾ˆå¤šæ“ä½œçš„åŸºç¡€
            is_gray = False
            if options.get('enable_grayscale', False):
                if len(processed_image.shape) == 3:
                    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                    operations.append("è½¬æ¢ä¸ºç°åº¦å›¾")
                is_gray = True
            
            # æ­¥éª¤ 2: å‡ ä½•æ ¡æ­£
            if options.get('enable_deskew', False):
                # ç¡®ä¿æœ‰ç°åº¦å›¾ç”¨äºå€¾æ–œæ£€æµ‹
                gray_for_op = processed_image if is_gray else cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                deskewed_image, angle = self._deskew_image(gray_for_op, options.get('deskew_angle_threshold', 0.5))
                if angle != 0.0:
                    # å°†æ—‹è½¬åº”ç”¨åˆ°å½“å‰æ­£åœ¨å¤„ç†çš„å›¾åƒä¸Šï¼ˆå¯èƒ½æ˜¯å½©è‰²æˆ–ç°åº¦ï¼‰
                    center = (processed_image.shape[1] // 2, processed_image.shape[0] // 2)
                    M = cv2.getRotationMatrix2D(center, angle, 1.0)
                    processed_image = cv2.warpAffine(processed_image, M, (processed_image.shape[1], processed_image.shape[0]), 
                                                     flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
                    operations.append(f"å‡ ä½•: å€¾æ–œæ ¡æ­£({angle:.2f}Â°)")
            
            if options.get('page_border_detection', False):
                 # é¡µé¢æ£€æµ‹æœ€å¥½åœ¨æ¥è¿‘åŸå§‹çš„å›¾åƒä¸Šåš
                 img_for_detect = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
                 processed_after_perspective = self._detect_and_crop_page(img_for_detect)
                 if processed_after_perspective.shape != img_for_detect.shape:
                     processed_image = processed_after_perspective
                     # å¦‚æœç»è¿‡æ­¤æ­¥éª¤ï¼Œå›¾åƒè‚¯å®šæ˜¯ç°åº¦å›¾äº†
                     is_gray = True
                     operations.append("å‡ ä½•: é¡µé¢æ£€æµ‹ä¸æ ¡æ­£")

            # æ­¥éª¤ 3: å›¾åƒå¢å¼ºä¸æ¸…ç† (è¿™äº›æ“ä½œé€šå¸¸åœ¨ç°åº¦å›¾ä¸Šæ•ˆæœæ›´å¥½)
            if options.get('shadow_removal', False):
                gray_for_op = processed_image if is_gray else cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                processed_image = self._remove_shadows(gray_for_op)
                is_gray = True
                operations.append("å¢å¼º: é˜´å½±ç§»é™¤")
            
            if options.get('bilateral_filter', False):
                # åŒè¾¹æ»¤æ³¢å¯ä»¥ä½œç”¨äºå½©è‰²æˆ–ç°åº¦å›¾
                processed_image = cv2.bilateralFilter(processed_image, 
                                                   d=options.get('bilateral_d', 9),
                                                   sigmaColor=int(options.get('bilateral_sigma_color', 75.0)),
                                                   sigmaSpace=int(options.get('bilateral_sigma_space', 75.0)))
                operations.append("é™å™ª: åŒè¾¹æ»¤æ³¢")
            
            if options.get('histogram_equalization', False):
                gray_for_op = processed_image if is_gray else cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                processed_image = cv2.equalizeHist(gray_for_op)
                is_gray = True
                operations.append("å¢å¼º: ç›´æ–¹å›¾å‡è¡¡åŒ–")
            
            if options.get('apply_clahe', False):
                gray_for_op = processed_image if is_gray else cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                clahe = cv2.createCLAHE(clipLimit=options.get('clahe_clip_limit', 2.0), 
                                      tileGridSize=options.get('clahe_tile_grid_size', (8, 8)))
                processed_image = clahe.apply(gray_for_op)
                is_gray = True
                operations.append("å¢å¼º: CLAHE")

            if options.get('unsharp_mask', False):
                gray_for_op = processed_image if is_gray else cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                processed_image = self._unsharp_mask(gray_for_op, 
                                              radius=options.get('unsharp_radius', 1.0), 
                                              amount=options.get('unsharp_amount', 1.0))
                is_gray = True
                operations.append("å¢å¼º: åé”åŒ–æ©æ¨¡")

            # æ­¥éª¤ 4: äºŒå€¼åŒ– (å¦‚æœå¯ç”¨)
            if options.get('enable_binarization', False):
                gray_for_op = processed_image if is_gray else cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                block_size = options.get('adaptive_block_size', 11); C_val = options.get('adaptive_c_constant', 2)
                if block_size % 2 == 0: block_size += 1
                processed_image = cv2.adaptiveThreshold(gray_for_op, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                                        cv2.THRESH_BINARY_INV, block_size, C_val)
                is_gray = True # äºŒå€¼åŒ–åè‚¯å®šæ˜¯å•é€šé“å›¾
                operations.append("è½¬æ¢: è‡ªé€‚åº”äºŒå€¼åŒ–")

            # æ­¥éª¤ 5: æœ€ç»ˆè£å‰ªæ“ä½œ (é€šå¸¸åœ¨äºŒå€¼åŒ–åæ•ˆæœæ›´å¥½)
            if options.get('remove_borders', False):
                gray_for_op = processed_image if is_gray else cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                processed_image = self._remove_borders(gray_for_op, options.get('border_threshold', 10))
                is_gray = True
                operations.append("å‡ ä½•: ç§»é™¤è¾¹æ¡†")

            if options.get('crop_to_content', False):
                gray_for_op = processed_image if is_gray else cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                processed_image, _ = self._crop_to_content(gray_for_op)
                is_gray = True
                operations.append("å‡ ä½•: è£å‰ªåˆ°å†…å®¹")

            # --- æœ€ç»ˆè¾“å‡ºå‡†å¤‡ ---
            # OCRå¼•æ“é€šå¸¸éœ€è¦3é€šé“BGRå›¾åƒï¼Œè¿™æ˜¯ä¸ºäº†æœ€å¥½çš„å…¼å®¹æ€§
            if is_gray:
                final_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR)
                operations.append("è¾“å‡º: è½¬æ¢ä¸ºBGR")
            else:
                final_image = processed_image

            if not operations:
                operations.append("æ— ä»»ä½•é¢„å¤„ç†æ“ä½œ")

            return final_image, operations
            
        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ§åˆ¶é¢„å¤„ç†å¤±è´¥: {e}\n{traceback.format_exc()}")
            # å‘ç”Ÿå¼‚å¸¸æ—¶ï¼Œå®‰å…¨åœ°è¿”å›åŸå§‹å›¾åƒçš„BGRç‰ˆæœ¬
            if len(image.shape) == 2:
                return cv2.cvtColor(image, cv2.COLOR_BGR2BGR), ['é”™è¯¯: é¢„å¤„ç†å¼‚å¸¸']
            return image, ['é”™è¯¯: é¢„å¤„ç†å¼‚å¸¸']
    def _optimize_image_size(self, image: np.ndarray) -> np.ndarray:
        """
        åŸºç¡€å°ºå¯¸ä¼˜åŒ–ï¼Œç¡®ä¿å›¾åƒåœ¨OCRå‹å¥½çš„å°ºå¯¸èŒƒå›´å†…ï¼ˆ1000-1600åƒç´ çš„æœ€é•¿è¾¹ï¼‰ã€‚
        è¿‡å¤§åˆ™ç¼©å°ï¼Œè¿‡å°åˆ™æ”¾å¤§ã€‚
        """
        try:
            h, w = image.shape[:2]
            
            # ç›®æ ‡OCRå‹å¥½çš„æœ€é•¿è¾¹èŒƒå›´
            target_ocr_long_side_min = 1000
            target_ocr_long_side_max = 1600
            
            long_side = max(h, w)
            
            # å¦‚æœå›¾åƒè¿‡å¤§ï¼Œç¼©å°åˆ°æœ€å¤§ç›®æ ‡å°ºå¯¸
            if long_side > target_ocr_long_side_max:
                scale = target_ocr_long_side_max / long_side
                new_w, new_h = int(w * scale), int(h * scale)
                image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4) # é«˜è´¨é‡ç¼©å°
                logger.debug(f"å›¾åƒå°ºå¯¸è¿‡å¤§è°ƒæ•´: {w}x{h} -> {new_w}x{new_h}")
                h, w = new_h, new_w # æ›´æ–°å°ºå¯¸
                long_side = max(h, w)

            # å¦‚æœå›¾åƒè¿‡å°ï¼Œæ”¾å¤§åˆ°æœ€å°ç›®æ ‡å°ºå¯¸
            if long_side < target_ocr_long_side_min:
                scale = target_ocr_long_side_min / long_side
                new_w, new_h = int(w * scale), int(h * scale)
                image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC) # åŒä¸‰æ¬¡æ’å€¼æ”¾å¤§
                logger.debug(f"å›¾åƒå°ºå¯¸è¿‡å°è°ƒæ•´: {w}x{h} -> {new_w}x{new_h}")
                h, w = new_h, new_w # æ›´æ–°å°ºå¯¸
                long_side = max(h, w)
            
            # å¼ºåˆ¶è½¬æ¢ä¸ºä¸‰é€šé“ (å¦‚æœä¸æ˜¯)ï¼ŒOpenCVå’ŒTesseracté€šå¸¸å–œæ¬¢BGRæ ¼å¼
            if len(image.shape) == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
                logger.debug("å›¾åƒè½¬æ¢ä¸ºBGRä¸‰é€šé“ã€‚")
                
            logger.debug(f"æœ€ç»ˆå›¾åƒå°ºå¯¸ä¼˜åŒ–å®Œæˆ: {image.shape[1]}x{image.shape[0]}")
            return image
            
        except Exception as e:
            logger.error(f"å›¾åƒå°ºå¯¸ä¼˜åŒ–å¤±è´¥: {e}\n{traceback.format_exc()}")
            return image
    
    # --- å›¾åƒå¤„ç†è¾…åŠ©æ–¹æ³• (å€Ÿé‰´ ocr_toolkit.py) ---
    def _deskew_image(self, image: np.ndarray, angle_threshold: float = 0.5) -> Tuple[np.ndarray, float]:
        """
        å€¾æ–œæ ¡æ­£ï¼Œé€šè¿‡Cannyè¾¹ç¼˜æ£€æµ‹å’ŒHoughå˜æ¢æ£€æµ‹æ–‡æœ¬å€¾æ–œè§’åº¦å¹¶è¿›è¡Œæ—‹è½¬æ ¡æ­£ã€‚
        """
        try:
            # ç¡®ä¿è¾“å…¥å›¾åƒæ˜¯ç°åº¦å›¾
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image
            
            # ä½¿ç”¨Cannyè¾¹ç¼˜æ£€æµ‹å’ŒHoughå˜æ¢æ£€æµ‹ç›´çº¿
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            # é˜ˆå€¼100ï¼ŒminLineLengthè‡³å°‘ä¸ºå›¾åƒå®½åº¦çš„1/4ï¼ŒmaxLineGapä¸º20åƒç´ 
            lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100,
                                   minLineLength=gray.shape[1] // 4, maxLineGap=20)
            
            if lines is not None and len(lines) > 0:
                angles = []
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    if x2 - x1 != 0:
                        angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
                        if abs(angle) < 45: # åªå…³æ³¨æ¥è¿‘æ°´å¹³çš„çº¿
                            angles.append(angle)
                
                if angles:
                    median_angle = np.median(angles)
                    if abs(median_angle) > angle_threshold: # åªæœ‰è§’åº¦è¶…è¿‡é˜ˆå€¼æ‰è¿›è¡Œæ—‹è½¬
                        center = (gray.shape[1] // 2, gray.shape[0] // 2)
                        rotation_matrix = cv2.getRotationMatrix2D(center, median_angle, 1.0)
                        rotated = cv2.warpAffine(gray, rotation_matrix,
                                               (gray.shape[1], gray.shape[0]),
                                               flags=cv2.INTER_CUBIC,
                                               borderMode=cv2.BORDER_REPLICATE) # å¡«å……è¾¹ç¼˜
                        logger.debug(f"å›¾åƒå€¾æ–œæ ¡æ­£ {median_angle:.2f}åº¦ã€‚")
                        return rotated, median_angle
            return image, 0.0 # æœªæ£€æµ‹åˆ°å€¾æ–œæˆ–å€¾æ–œè§’åº¦è¿‡å°
        except Exception as e:
            logger.warning(f"å€¾æ–œæ ¡æ­£å¤±è´¥: {e}")
            return image, 0.0

    def _remove_shadows(self, image: np.ndarray) -> np.ndarray:
        """
        ç§»é™¤å›¾åƒä¸­çš„é˜´å½±ï¼Œä½¿ç”¨å½¢æ€å­¦æ“ä½œå’ŒèƒŒæ™¯å‡æ³•æŠ€æœ¯ã€‚
        """
        try:
            # ç¡®ä¿è¾“å…¥å›¾åƒæ˜¯ç°åº¦å›¾
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            # ä½¿ç”¨å½¢æ€å­¦æ“ä½œè·å–å›¾åƒèƒŒæ™¯ï¼ˆæ¨¡æ‹Ÿé˜´å½±ï¼‰
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20)) # æ¤­åœ†æ ¸ï¼Œå°ºå¯¸å¯è°ƒ
            background = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel) # å¼€è¿ç®—å¹³æ»‘å›¾åƒï¼Œå»é™¤é«˜é¢‘ä¿¡æ¯ï¼ˆæ–‡æœ¬ï¼‰ï¼Œä¿ç•™ä½é¢‘ä¿¡æ¯ï¼ˆèƒŒæ™¯/é˜´å½±ï¼‰
            
            # ä»åŸå§‹å›¾åƒå‡å»èƒŒæ™¯ï¼Œå¾—åˆ°æ— é˜´å½±çš„å›¾åƒ
            diff = cv2.subtract(gray, background)
            
            # å¯¹ç»“æœè¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œå¢å¼ºå¯¹æ¯”åº¦
            norm_img = cv2.normalize(diff, None, 0, 255, cv2.NORM_MINMAX)
            
            # ä½¿ç”¨é™¤æ³•æ¥è¿›ä¸€æ­¥å‡å°‘é˜´å½± (å¯é€‰ï¼Œå¯èƒ½ä¼šå¼•å…¥å™ªå£°)
            # èƒŒæ™¯åƒç´ å€¼ä¸º0æ—¶ä¼šå¯¼è‡´é™¤é›¶ï¼Œå› æ­¤è¿›è¡Œä¿æŠ¤æ€§å¤„ç†
            background_float = background.astype(np.float32)
            image_float = gray.astype(np.float32)
            background_float = np.where(background_float == 0, 1, background_float) # é¿å…é™¤é›¶
            result = (image_float / background_float) * 255
            result = np.clip(result, 0, 255).astype(np.uint8) # ç¡®ä¿åƒç´ å€¼åœ¨0-255èŒƒå›´å†…

            logger.debug("å·²ç§»é™¤å›¾åƒé˜´å½±ã€‚")
            return result
        except Exception as e:
            logger.warning(f"é˜´å½±ç§»é™¤å¤±è´¥: {e}")
            return image

    def _process_borders(self, image: np.ndarray, remove_borders: bool, border_threshold: int, page_border_detection: bool) -> np.ndarray:
        """
        å¤„ç†å›¾åƒè¾¹æ¡†çš„é€šç”¨æ¥å£ã€‚
        æ ¹æ®é…ç½®é€‰æ‹©ç§»é™¤è¾¹æ¡†æˆ–è¿›è¡Œé¡µé¢è¾¹æ¡†æ£€æµ‹åŠé€è§†æ ¡æ­£ã€‚
        """
        if page_border_detection:
            return self._detect_and_crop_page(image)
        elif remove_borders:
            return self._remove_borders(image, border_threshold)
        return image

    def _remove_borders(self, image: np.ndarray, threshold: int) -> np.ndarray:
        """
        ç§»é™¤å›¾ç‰‡ä¸­çš„å‡åŒ€è¾¹æ¡†ï¼Œé€šè¿‡æ£€æŸ¥è¾¹ç¼˜åƒç´ çš„å¹³å‡å¼ºåº¦ã€‚
        """
        try:
            h, w = image.shape[:2]
            
            # æ£€æµ‹ä¸Šã€ä¸‹ã€å·¦ã€å³è¾¹æ¡†
            top, bottom, left, right = 0, h-1, 0, w-1
            
            # æ£€æŸ¥å‰1/4é«˜åº¦
            for i in range(h // 4): 
                if np.mean(image[i, :]) > threshold:
                    top = i
                    break
            
            # æ£€æŸ¥å1/4é«˜åº¦
            for i in range(h - 1, 3 * h // 4, -1): 
                if np.mean(image[i, :]) > threshold:
                    bottom = i
                    break
            
            # æ£€æŸ¥å‰1/4å®½åº¦
            for i in range(w // 4): 
                if np.mean(image[:, i]) > threshold:
                    left = i
                    break
            
            # æ£€æŸ¥å1/4å®½åº¦
            for i in range(w - 1, 3 * w // 4, -1): 
                if np.mean(image[:, i]) > threshold:
                    right = i
                    break
            
            # è£å‰ªå›¾åƒï¼Œç¡®ä¿è£å‰ªåæœ‰è¶³å¤Ÿå†…å®¹
            if top < bottom and left < right and (bottom - top > 50) and (right - left > 50): 
                logger.debug(f"ç§»é™¤è¾¹æ¡†: ä» {0},{0},{w},{h} è£å‰ªåˆ° {left},{top},{right+1},{bottom+1}")
                return image[top:bottom+1, left:right+1]
            logger.debug("æœªæ£€æµ‹åˆ°æ˜æ˜¾è¾¹æ¡†æˆ–è£å‰ªåŒºåŸŸè¿‡å°ï¼Œè·³è¿‡è¾¹æ¡†ç§»é™¤ã€‚")
            return image
        except Exception as e:
            logger.warning(f"ç§»é™¤è¾¹æ¡†å¤±è´¥: {e}")
            return image

    def _detect_and_crop_page(self, image: np.ndarray) -> np.ndarray:
        """
        æ£€æµ‹å¹¶è£å‰ªåˆ°æ–‡æ¡£é¡µé¢å†…å®¹ï¼Œæ”¯æŒé€è§†æ ¡æ­£ã€‚
        é€šè¿‡æŸ¥æ‰¾æœ€å¤§è½®å»“å¹¶è¿‘ä¼¼ä¸ºå››è¾¹å½¢æ¥è¯†åˆ«é¡µé¢ã€‚
        """
        try:
            # ç¡®ä¿è¾“å…¥å›¾åƒæ˜¯ç°åº¦å›¾
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image
            
            edges = cv2.Canny(gray, 50, 150) # è¾¹ç¼˜æ£€æµ‹
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # æŸ¥æ‰¾å¤–éƒ¨è½®å»“
            
            if contours:
                largest_contour = max(contours, key=cv2.contourArea) # æ‰¾åˆ°æœ€å¤§è½®å»“
                epsilon = 0.02 * cv2.arcLength(largest_contour, True) # è¿‘ä¼¼å¤šè¾¹å½¢çš„ç²¾åº¦
                approx = cv2.approxPolyDP(largest_contour, epsilon, True) # è¿‘ä¼¼å¤šè¾¹å½¢
                
                if len(approx) == 4: # å¦‚æœæ‰¾åˆ°å››ä¸ªè§’ç‚¹ï¼Œåˆ™è¿›è¡Œé€è§†æ ¡æ­£
                    points = approx.reshape(4, 2)
                    
                    # æ’åºè§’ç‚¹ï¼šå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹
                    rect = np.zeros((4, 2), dtype=np.float32)
                    s = points.sum(axis=1)
                    rect[0] = points[np.argmin(s)]  # å·¦ä¸Š (x+yæœ€å°)
                    rect[2] = points[np.argmax(s)]  # å³ä¸‹ (x+yæœ€å¤§)
                    
                    diff = np.diff(points, axis=1)
                    rect[1] = points[np.argmin(diff)]  # å³ä¸Š (y-xæœ€å°)
                    rect[3] = points[np.argmax(diff)]  # å·¦ä¸‹ (y-xæœ€å¤§)
                    
                    # è®¡ç®—æ–°å›¾åƒçš„å°ºå¯¸ (åŸºäºçŸ«æ­£åçš„å®½åº¦å’Œé«˜åº¦)
                    width_a = np.linalg.norm(rect[2] - rect[3])
                    width_b = np.linalg.norm(rect[1] - rect[0])
                    max_width = int(max(width_a, width_b))
                    
                    height_a = np.linalg.norm(rect[1] - rect[2])
                    height_b = np.linalg.norm(rect[0] - rect[3])
                    max_height = int(max(height_a, height_b))
                    
                    # ç›®æ ‡é€è§†å˜æ¢åçš„å››ä¸ªè§’ç‚¹
                    dst = np.array([
                        [0, 0],
                        [max_width - 1, 0],
                        [max_width - 1, max_height - 1],
                        [0, max_height - 1]
                    ], dtype=np.float32)
                    
                    matrix = cv2.getPerspectiveTransform(rect, dst) # è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
                    warped = cv2.warpPerspective(image, matrix, (max_width, max_height)) # åº”ç”¨é€è§†å˜æ¢
                    logger.debug("å·²æ‰§è¡Œé¡µé¢é€è§†æ ¡æ­£å’Œè£å‰ªã€‚")
                    return warped
                else: # æœªæ‰¾åˆ°å››ä¸ªè§’ç‚¹ï¼Œä½¿ç”¨æœ€å°å¤–æ¥çŸ©å½¢è¿›è¡Œè£å‰ª
                    x, y, w, h = cv2.boundingRect(largest_contour)
                    if w > 50 and h > 50: # ç¡®ä¿è£å‰ªåŒºåŸŸæœ‰æ•ˆ
                        logger.debug(f"å·²è£å‰ªåˆ°æœ€å¤§è½®å»“çŸ©å½¢åŒºåŸŸ: {x},{y},{w},{h}ã€‚")
                        return image[y:y+h, x:x+w]
            logger.debug("æœªæ£€æµ‹åˆ°æœ‰æ•ˆé¡µé¢è¾¹æ¡†ï¼Œè·³è¿‡é¡µé¢æ£€æµ‹è£å‰ªã€‚")
            return image
        except Exception as e:
            logger.warning(f"é¡µé¢æ£€æµ‹å’Œè£å‰ªå¤±è´¥: {e}")
            return image

    def _crop_to_content(self, image: np.ndarray) -> Tuple[np.ndarray, bool]:
        """
        è£å‰ªå›¾åƒçš„å®é™…å†…å®¹åŒºåŸŸï¼Œç§»é™¤ç©ºç™½è¾¹ç¼˜ã€‚
        é€šè¿‡æŸ¥æ‰¾éç™½è‰²ï¼ˆé255ï¼‰åƒç´ æ¥ç¡®å®šå†…å®¹è¾¹ç•Œã€‚
        """
        try:
            # ç¡®ä¿è¾“å…¥å›¾åƒæ˜¯ç°åº¦å›¾ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸éœ€è¦æ‰¾åˆ°éç™½è‰²åƒç´ 
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            # æ‰¾åˆ°æ‰€æœ‰éé›¶ï¼ˆéç™½è‰²ï¼‰åƒç´ çš„åæ ‡
            coords = cv2.findNonZero(gray)
            if coords is None: # å…¨ç™½å›¾åƒï¼Œæ²¡æœ‰å†…å®¹
                logger.debug("å›¾åƒå†…å®¹å…¨ç™½ï¼Œè·³è¿‡è£å‰ªåˆ°å†…å®¹ã€‚")
                return image, False
            x, y, w, h = cv2.boundingRect(coords) # è·å–å†…å®¹åŒºåŸŸçš„æœ€å°å¤–æ¥çŸ©å½¢
            
            # æ·»åŠ å°‘é‡è¾¹è·ï¼Œé˜²æ­¢è£å‰ªè¿‡ç´§
            margin = 5
            x = max(0, x - margin)
            y = max(0, y - margin)
            w = min(image.shape[1] - x, w + 2 * margin)
            h = min(image.shape[0] - y, h + 2 * margin)

            if w > 10 and h > 10: # ç¡®ä¿è£å‰ªåŒºåŸŸè¶³å¤Ÿå¤§ï¼Œé˜²æ­¢è£å‰ªæˆç©ºå›¾
                cropped = image[y:y+h, x:x+w]
                logger.debug(f"å·²è£å‰ªåˆ°å†…å®¹åŒºåŸŸ: {x},{y},{w},{h}ã€‚")
                return cropped, True
            logger.debug("å†…å®¹åŒºåŸŸè¿‡å°ï¼Œè·³è¿‡è£å‰ªåˆ°å†…å®¹ã€‚")
            return image, False
        except Exception as e:
            logger.warning(f"è£å‰ªåˆ°å†…å®¹å¤±è´¥: {e}")
            return image, False

    def _advanced_denoising(self, image: np.ndarray, strength: float, edge_preservation: float) -> np.ndarray:
        """
        é«˜çº§é™å™ªæ–¹æ³•ï¼Œä½¿ç”¨OpenCVçš„`fastNlMeansDenoising`ï¼ˆéå±€éƒ¨å‡å€¼é™å™ªï¼‰ã€‚
        æ”¯æŒé€šè¿‡`edge_preservation`å‚æ•°è°ƒæ•´é™å™ªæ—¶è¾¹ç¼˜çš„ä¿ç•™ç¨‹åº¦ã€‚
        """
        try:
            # ç¡®ä¿è¾“å…¥å›¾åƒæ˜¯ç°åº¦å›¾
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            h_param = int(strength * 30)  # å¼ºåº¦å‚æ•°ï¼Œå¯ä»¥è°ƒæ•´ï¼Œå½±å“å»å™ªæ•ˆæœ
            template_window_size = 7       # æ¨¡æ¿çª—å£å¤§å°
            search_window_size = 21        # æœç´¢çª—å£å¤§å°
            
            denoised = cv2.fastNlMeansDenoising(gray, None, h_param, template_window_size, search_window_size)
            
            # å¦‚æœè¾¹ç¼˜ä¿ç•™å› å­å°äº1.0ï¼Œåˆ™å°†åŸå§‹å›¾åƒä¸é™å™ªå›¾åƒåŠ æƒèåˆï¼Œä»¥ä¿ç•™æ›´å¤šè¾¹ç¼˜ç»†èŠ‚
            if edge_preservation < 1.0:
                denoised = cv2.addWeighted(gray, edge_preservation, 
                                         denoised, 1.0 - edge_preservation, 0)
            logger.debug(f"æ‰§è¡Œé«˜çº§é™å™ª (å¼ºåº¦: {strength}, è¾¹ç¼˜ä¿ç•™: {edge_preservation})ã€‚")
            return denoised
        except Exception as e:
            logger.warning(f"é«˜çº§é™å™ªå¤±è´¥: {e}ï¼Œå›é€€åˆ°é«˜æ–¯æ¨¡ç³Šã€‚")
            # å¤±è´¥æ—¶å›é€€åˆ°é«˜æ–¯æ¨¡ç³Š
            kernel_size = max(3, int(strength * 10))
            if kernel_size % 2 == 0:
                kernel_size += 1
            return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)

    def _unsharp_mask(self, image: np.ndarray, radius: float = 1.0, amount: float = 1.0) -> np.ndarray:
        """
        åé”åŒ–æ©æ¨¡ (Unsharp Masking) ç®—æ³•ï¼Œç”¨äºå¢å¼ºå›¾åƒç»†èŠ‚å’Œè¾¹ç¼˜ã€‚
        é€šè¿‡ä»åŸå§‹å›¾åƒä¸­å‡å»å…¶æ¨¡ç³Šç‰ˆæœ¬æ¥åˆ›å»ºé”åŒ–æ•ˆæœã€‚
        """
        try:
            # ç¡®ä¿è¾“å…¥å›¾åƒæ˜¯ç°åº¦å›¾
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            # å…ˆè¿›è¡Œé«˜æ–¯æ¨¡ç³Š
            # sigmaX å‚æ•°è®¾ç½®ä¸º radiusï¼Œkernel size è®¾ä¸º (0,0) è¡¨ç¤ºæ ¹æ® sigmaX è‡ªåŠ¨è®¡ç®—
            blurred = cv2.GaussianBlur(gray, (0, 0), radius)
            # è®¡ç®—æ©æ¨¡ï¼šåŸå§‹å›¾åƒ - æ¨¡ç³Šå›¾åƒ
            unsharp_mask_result = cv2.addWeighted(gray, 1.0 + amount, blurred, -amount, 0)
            unsharp_mask_result = np.clip(unsharp_mask_result, 0, 255).astype(np.uint8) # ç¡®ä¿åƒç´ å€¼èŒƒå›´
            logger.debug(f"æ‰§è¡Œåé”åŒ–æ©æ¨¡ (åŠå¾„: {radius}, å¼ºåº¦: {amount})ã€‚")
            return unsharp_mask_result
        except Exception as e:
            logger.warning(f"åé”åŒ–æ©æ¨¡å¤±è´¥: {e}")
            return image

    # --- ç¼“å­˜ç®¡ç†æ–¹æ³• ---
    def _generate_cache_key(self, image_path: str, options: Dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®ï¼ŒåŸºäºæ–‡ä»¶è·¯å¾„ã€ä¿®æ”¹æ—¶é—´åŠå¤„ç†é€‰é¡¹çš„MD5å“ˆå¸Œã€‚"""
        try:
            mtime = os.path.getmtime(image_path)
            options_str = json.dumps(options, sort_keys=True) # ç¡®ä¿é€‰é¡¹é¡ºåºä¸€è‡´
            key_data = f"{image_path}_{mtime}_{options_str}"
            return hashlib.md5(key_data.encode()).hexdigest()
        except Exception as e:
            logger.error(f"ç”Ÿæˆç¼“å­˜é”®å¤±è´¥: {e}")
            return f"error_{time.time()}"
    
    def _get_from_cache(self, cache_key: str) -> Optional[Dict]:
        """ä»ç¼“å­˜ä¸­è·å–ç»“æœï¼Œå¹¶æ£€æŸ¥æ˜¯å¦è¿‡æœŸã€‚"""
        try:
            if cache_key in self._processing_cache:
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                if cache_key in self._cache_expiry:
                    if datetime.now() > self._cache_expiry[cache_key]:
                        self._remove_from_cache(cache_key)
                        logger.debug(f"ç¼“å­˜æ¡ç›® {cache_key} å·²è¿‡æœŸå¹¶ç§»é™¤ã€‚")
                        return None
                
                logger.debug(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
                return self._processing_cache[cache_key]
            return None
        except Exception as e:
            logger.error(f"ä»ç¼“å­˜è·å–å¤±è´¥: {e}")
            return None
    
    def _add_to_cache(self, cache_key: str, result: Dict):
        """æ·»åŠ å¤„ç†ç»“æœåˆ°ç¼“å­˜ã€‚å½“ç¼“å­˜æ»¡æ—¶ï¼Œç§»é™¤æœ€æ—§çš„æ¡ç›®ã€‚"""
        try:
            # æ¸…ç†è¿‡æœŸç¼“å­˜
            self._cleanup_expired_cache()
            
            # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„æ¡ç›® (åŸºäºè¿‡æœŸæ—¶é—´)
            if len(self._processing_cache) >= self._cache_max_size:
                oldest_key = min(self._cache_expiry.keys(), 
                               key=lambda k: self._cache_expiry.get(k, datetime.now())) # å¦‚æœæ²¡æœ‰è¿‡æœŸæ—¶é—´ï¼Œåˆ™å‡å®šä¸ºå½“å‰æ—¶é—´
                self._remove_from_cache(oldest_key)
                logger.debug(f"ç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€æ—§æ¡ç›®: {oldest_key}")
            
            # æ·»åŠ æ–°çš„ç¼“å­˜æ¡ç›®
            self._processing_cache[cache_key] = result
            self._cache_expiry[cache_key] = datetime.now() + timedelta(hours=CVOCRConstants.CACHE_EXPIRE_HOURS)
            logger.debug(f"æ·»åŠ æ–°ç¼“å­˜æ¡ç›®: {cache_key}ï¼Œæœ‰æ•ˆæœŸè‡³: {self._cache_expiry[cache_key].strftime('%Y-%m-%d %H:%M:%S')}")
            
        except Exception as e:
            logger.error(f"æ·»åŠ åˆ°ç¼“å­˜å¤±è´¥: {e}")
    
    def _remove_from_cache(self, cache_key: str):
        """ä»ç¼“å­˜ä¸­åˆ é™¤æŒ‡å®šçš„æ¡ç›®ã€‚"""
        try:
            self._processing_cache.pop(cache_key, None)
            self._cache_expiry.pop(cache_key, None)
            logger.debug(f"å·²ä»ç¼“å­˜ä¸­åˆ é™¤æ¡ç›®: {cache_key}")
        except Exception as e:
            logger.error(f"ä»ç¼“å­˜åˆ é™¤å¤±è´¥: {e}")
    
    def _cleanup_expired_cache(self):
        """å®šæœŸæ¸…ç†æ‰€æœ‰å·²è¿‡æœŸçš„ç¼“å­˜æ¡ç›®ã€‚"""
        try:
            now = datetime.now()
            expired_keys = [k for k, v in self._cache_expiry.items() if now > v]
            for key in expired_keys:
                self._remove_from_cache(key)
            if expired_keys:
                logger.info(f"å·²æ¸…ç† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜æ¡ç›®ã€‚")
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸç¼“å­˜å¤±è´¥: {e}")
    
    def _update_processing_stats(self, processing_time: float):
        """æ›´æ–°å¤„ç†ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¹³å‡å¤„ç†æ—¶é—´ã€‚"""
        try:
            self._processing_stats['processing_times'].append(processing_time)
            self._processing_stats['average_processing_time'] = np.mean(list(self._processing_stats['processing_times']))
            logger.debug(f"æ›´æ–°å¤„ç†ç»Ÿè®¡ï¼šæœ¬æ¬¡è€—æ—¶ {processing_time:.2f}sï¼Œå¹³å‡è€—æ—¶ {self._processing_stats['average_processing_time']:.2f}sã€‚")
        except Exception as e:
            logger.error(f"æ›´æ–°å¤„ç†ç»Ÿè®¡å¤±è´¥: {e}")
    
    def get_processing_stats(self) -> Dict:
        """è·å–å½“å‰å¤„ç†ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        stats = self._processing_stats.copy()
        stats.update({
            'cache_size': len(self._processing_cache),
            'max_cache_size': self._cache_max_size,
            'cache_hit_rate': (stats['cache_hits'] / max(stats['cache_hits'] + stats['cache_misses'], 1)) * 100,
            'config': self.config.copy() # åŒ…å«å½“å‰çš„å¤„ç†å™¨é…ç½®
        })
        return stats
    
    def clear_cache(self):
        """æ¸…ç©ºæ‰€æœ‰å¤„ç†ç¼“å­˜ã€‚"""
        try:
            self._processing_cache.clear()
            self._cache_expiry.clear()
            # é‡ç½®ç¼“å­˜ç»Ÿè®¡
            self._processing_stats['cache_hits'] = 0
            self._processing_stats['cache_misses'] = 0
            logger.info("æ–‡æœ¬å›¾åƒå¤„ç†ç¼“å­˜å·²æ¸…ç†ã€‚")
        except Exception as e:
            logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
class EnhancedCVOCRManager:
    """
    å¢å¼ºç‰ˆCVOCRå¼•æ“ç®¡ç†å™¨ (V3.29 - ç»ˆææŠ€æœ¯æ ˆå‡çº§ç‰ˆ)
    - å½»åº•ç§»é™¤å·²è¢«æ·˜æ±°çš„FSRCNNæ¨¡å—ã€‚
    - é›†æˆDBNet++ä½œä¸ºé»˜è®¤çš„SOTAæ–‡æœ¬æ£€æµ‹å™¨ã€‚
    - èšç„¦äºDBNet++ + LayoutLMv2 + TrOCR + GPT-Neo + Tesseractçš„ç°ä»£æŠ€æœ¯æ ˆã€‚
    """

    def __init__(self, logger_func: Callable):
        """
        å¢å¼ºç‰ˆCVOCRå¼•æ“ç®¡ç†å™¨çš„æ„é€ å‡½æ•° (V3.32 - å»¶è¿Ÿåˆå§‹åŒ–ç‰ˆ)ã€‚
        - åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹å ä½ç¬¦ã€é…ç½®å’ŒçŠ¶æ€å˜é‡ã€‚
        - æ¥å—æ¥è‡ªGUIçš„æ—¥å¿—å‡½æ•°ã€‚
        - å°† UnifiedObjectDetector çš„å®ä¾‹åŒ–æ¨è¿Ÿåˆ° initialize æ–¹æ³•ä¸­ï¼Œä»¥ä¾¿ä½¿ç”¨ç”¨æˆ·é…ç½®ã€‚
        
        Args:
            logger_func (Callable): ä¸€ä¸ªç”¨äºè®°å½•æ—¥å¿—å¹¶æ˜¾ç¤ºåœ¨GUIä¸Šçš„å‡½æ•°ã€‚
        """
        # ======================================================================
        # 1. æ¨¡å‹å’Œå¤„ç†å™¨å ä½ç¬¦
        # ======================================================================
        self.layoutlm_processor = None
        self.layoutlm_model = None
        self.trocr_processor = None
        self.trocr_model = None
        self.gpt_neo_tokenizer = None
        self.gpt_neo_model = None
        self.fsrcnn_model = None # ä¿ç•™å ä½ç¬¦
        
        # ### ä¿®æ­£ï¼šå°†æ£€æµ‹å™¨åˆå§‹åŒ–ä¸º Noneï¼Œæ¨è¿Ÿå®ä¾‹åŒ– ###
        self.text_detector = None
        self.unified_detector = None
        
        # ======================================================================
        # 2. Tesseract ç›¸å…³è®¾ç½®
        # ======================================================================
        self.tesseract_config = None
        self.tesseract_path = None
        
        # ======================================================================
        # 3. çŠ¶æ€ä¸é…ç½®
        # ======================================================================
        self.is_initialized = False
        self.device = "cpu"
        self.version_info = {}
        self.language = OCRLanguage.AUTO
        
        self.logger_func = logger_func

        # å†…éƒ¨é»˜è®¤é…ç½®å­—å…¸ï¼Œå°†è¢«UIè®¾ç½®è¦†ç›–
        self.config = {
            'psm': 6, 'oem': 3,
            'confidence_threshold': CVOCRConstants.DEFAULT_CONFIDENCE_THRESHOLD,
            'lang': 'chi_sim+eng',
            'enable_layout_analysis': False,
            'enable_context_analysis': False,
            'enable_transformer_ocr': False,
            'dpi': CVOCRConstants.DEFAULT_DPI,
            'enable_preprocessing_optimization': True,
            'batch_size': 1,
            'use_gpu': False,
            'model_precision': 'fp32',
            'tesseract_process_timeout': 300,
            'force_intensive_preprocessing': False,
            'ppocr_model_name': 'text_detection_cn_ppocrv3_2023may.onnx',
            # æ–°å¢YOLOè·¯å¾„çš„é»˜è®¤å€¼
            'yolo_weights_path': 'yolov4-tiny.weights',
            'yolo_cfg_path': 'yolov4-tiny.cfg',
            'yolo_names_path': 'coco.names'
        }
        
        # ======================================================================
        # 4. æ€§èƒ½ç›‘æ§
        # ======================================================================
        self.performance_stats = {
            'total_recognitions': 0,
            'successful_recognitions': 0,
            'failed_recognitions': 0,
            'average_recognition_time': 0.0,
            'recognition_times': deque(maxlen=100),
            'component_usage': defaultdict(int)
        }
        
        logger.info("å¢å¼ºç‰ˆCVOCRå¼•æ“ç®¡ç†å™¨å·²åˆ›å»º (ç­‰å¾…åˆå§‹åŒ–...)")
    @staticmethod
    def _execute_tesseract_subprocess(image_pil: Image.Image, tesseract_cmd_path: Optional[str], config_str: str, timeout: int) -> Dict:
        """
        Tesseractå­è¿›ç¨‹æ‰§è¡Œå™¨ (V3.7 - é…ç½®æ–‡ä»¶æ¨¡å¼ä¿®æ­£ç‰ˆ)
        - ä½¿ç”¨ä¸´æ—¶é…ç½®æ–‡ä»¶ä¼ é€’å‚æ•°ï¼Œè§£å†³ä¸­æ–‡è¯†åˆ«å‚æ•°å¤±æ•ˆé—®é¢˜ã€‚
        """
        import subprocess
        import io
        import platform
        from collections import defaultdict
        import tempfile
        import os

        logger.debug(f"DEBUG: _execute_tesseract_subprocess å¼€å§‹æ‰§è¡Œã€‚")
        logger.debug(f"DEBUG: æ¥æ”¶åˆ° config_str: {config_str}")

        tesseract_executable = tesseract_cmd_path if (tesseract_cmd_path and os.path.exists(tesseract_cmd_path)) else "tesseract"
        logger.debug(f"DEBUG: ç¡®è®¤Tesseractå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„: {tesseract_executable}")
        
        if not shutil.which(tesseract_executable) and not os.path.exists(tesseract_executable):
            logger.error(f"ERROR: Tesseractå¯æ‰§è¡Œæ–‡ä»¶æœªæ‰¾åˆ°æˆ–ä¸å¯æ‰§è¡Œ: '{tesseract_executable}'ã€‚è¯·æ£€æŸ¥è·¯å¾„é…ç½®ã€‚", exc_info=True)
            return {"status": "error", "message": f"Tesseract å¯æ‰§è¡Œæ–‡ä»¶æœªæ‰¾åˆ°æˆ–ä¸å¯æ‰§è¡Œ: '{tesseract_executable}'ã€‚"}

        temp_image_path = None
        temp_output_base = None
        temp_config_path = None
        temp_output_txt = None
        temp_output_tsv = None

        try:
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_image_file:
                temp_image_path = temp_image_file.name
                if image_pil.mode not in ['RGB', 'L']:
                    image_pil = image_pil.convert('RGB')
                image_pil.save(temp_image_path, format='PNG')
            logger.debug(f"DEBUG: å›¾åƒå·²æˆåŠŸä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {temp_image_path} ç”¨äºTesseractè¾“å…¥ã€‚")

            temp_output_base = tempfile.NamedTemporaryFile(delete=False).name
            temp_output_txt = temp_output_base + '.txt'
            temp_output_tsv = temp_output_base + '.tsv'

            config_to_use = ""
            if isinstance(config_str, list) and len(config_str) > 0:
                config_to_use = config_str[0][0]
            elif isinstance(config_str, str):
                config_to_use = config_str
            
            # ã€æ ¸å¿ƒä¿®æ­£ã€‘: å°†é…ç½®å†™å…¥ä¸´æ—¶æ–‡ä»¶
            config_parts = config_to_use.split()
            
            # åˆ†ç¦»å‡º --psm, --oem, -l è¿™äº›ä¸»å‚æ•°
            command_args = []
            # å°† -c å‚æ•°çš„å†…å®¹å†™å…¥é…ç½®æ–‡ä»¶
            config_file_lines = []

            i = 0
            while i < len(config_parts):
                part = config_parts[i]
                if part in ['--psm', '--oem', '-l']:
                    command_args.append(part)
                    if i + 1 < len(config_parts):
                        command_args.append(config_parts[i+1])
                        i += 1
                elif part == '-c':
                    if i + 1 < len(config_parts):
                        # å°† key=value å†™å…¥é…ç½®æ–‡ä»¶, Tesseracté…ç½®æ–‡ä»¶æ ¼å¼æ˜¯ "key value"
                        config_file_lines.append(config_parts[i+1].replace('=', ' ', 1))
                        i += 1
                i += 1
            
            # æ„å»ºåŸºç¡€å‘½ä»¤
            command_base = [tesseract_executable, temp_image_path, temp_output_base] + command_args

            # å¦‚æœæœ‰éœ€è¦å†™å…¥é…ç½®æ–‡ä»¶çš„å‚æ•°
            if config_file_lines:
                with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.cfg', encoding='utf-8') as temp_config_file:
                    temp_config_path = temp_config_file.name
                    temp_config_file.write('\n'.join(config_file_lines))
                # å°†é…ç½®æ–‡ä»¶åä½œä¸ºæœ€åä¸€ä¸ªå‚æ•°æ·»åŠ åˆ°å‘½ä»¤ä¸­
                command_base.append(os.path.basename(temp_config_path).split('.')[0])
                logger.debug(f"DEBUG: Tesseract é…ç½®å·²å†™å…¥ä¸´æ—¶æ–‡ä»¶: {temp_config_path}")
            
            command_txt = command_base
            command_tsv = command_base + ['tsv']
            
            logger.debug(f"DEBUG: æœ€ç»ˆæ‰§è¡Œçš„ Txt å‘½ä»¤: {' '.join(command_txt)}")
            logger.debug(f"DEBUG: æœ€ç»ˆæ‰§è¡Œçš„ Tsv å‘½ä»¤: {' '.join(command_tsv)}")

            creation_flags = 0
            if platform.system() == "Windows":
                try:
                    creation_flags = subprocess.CREATE_NO_WINDOW
                except AttributeError:
                    creation_flags = 0x08000000

            try:
                actual_timeout = timeout 
                logger.debug(f"DEBUG: Tesseractè¿›ç¨‹è¶…æ—¶è®¾ç½®ä¸º: {actual_timeout} ç§’ã€‚")
                
                # åœ¨åŒ…å«é…ç½®æ–‡ä»¶çš„ç›®å½•ä¸­æ‰§è¡Œå‘½ä»¤ï¼Œä»¥ç¡®ä¿Tesseractèƒ½æ‰¾åˆ°å®ƒ
                process_cwd = os.path.dirname(temp_config_path) if temp_config_path else None

                process_text = subprocess.run(
                    command_txt, capture_output=True, timeout=actual_timeout,
                    creationflags=creation_flags, check=False, cwd=process_cwd
                )
                if process_text.returncode != 0:
                    stderr_msg = process_text.stderr.decode('utf-8', 'ignore').strip()
                    logger.error(f"ERROR: Tesseractçº¯æ–‡æœ¬å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process_text.returncode}, é”™è¯¯è¾“å‡º: {stderr_msg}", exc_info=True)
                    return {"status": "error", "message": f"Tesseractçº¯æ–‡æœ¬å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process_text.returncode}ï¼Œé”™è¯¯è¾“å‡º: {stderr_msg}"}

                process_data = subprocess.run(
                    command_tsv, capture_output=True, timeout=actual_timeout,
                    creationflags=creation_flags, check=False, cwd=process_cwd
                )
                if process_data.returncode != 0:
                    stderr_msg = process_data.stderr.decode('utf-8', 'ignore').strip()
                    logger.error(f"ERROR: Tesseract TSVå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process_data.returncode}, é”™è¯¯è¾“å‡º: {stderr_msg}", exc_info=True)
                    return {"status": "error", "message": f"Tesseract TSVå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process_data.returncode}ï¼Œé”™è¯¯è¾“å‡º: {stderr_msg}"}

            except subprocess.TimeoutExpired:
                logger.error(f"ERROR: Tesseract å­è¿›ç¨‹è¶…æ—¶ï¼ˆè¶…è¿‡ {timeout} ç§’ï¼‰ã€‚", exc_info=True)
                return {"status": "error", "message": f"Tesseract å­è¿›ç¨‹è¶…æ—¶ï¼ˆè¶…è¿‡ {timeout} ç§’ï¼‰ã€‚"}
            except FileNotFoundError:
                logger.error(f"ERROR: Tesseract å¯æ‰§è¡Œæ–‡ä»¶æœªæ‰¾åˆ°: '{tesseract_executable}'ã€‚", exc_info=True)
                return {"status": "error", "message": f"Tesseract å¯æ‰§è¡Œæ–‡ä»¶æœªæ‰¾åˆ°: '{tesseract_executable}'ã€‚è¯·æ£€æŸ¥è·¯å¾„é…ç½®ã€‚"}
            except Exception as e:
                logger.error(f"ERROR: æ‰§è¡ŒTesseractå‘½ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
                return {"status": "error", "message": f"æ‰§è¡ŒTesseractå‘½ä»¤æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"}

            full_text = ""
            data_lines = []
            try:
                if os.path.exists(temp_output_txt):
                    with open(temp_output_txt, 'r', encoding='utf-8') as f:
                        full_text = f.read()
                if os.path.exists(temp_output_tsv):
                    with open(temp_output_tsv, 'r', encoding='utf-8') as f:
                        data_lines = f.read().strip().split('\n')

                data_dict = defaultdict(list)
                if len(data_lines) > 1:
                    header = data_lines[0].split('\t')
                    for line in data_lines[1:]:
                        values = line.split('\t')
                        if len(values) == len(header):
                            for h, v in zip(header, values):
                                data_dict[h].append(v)
                
                for key in ['level', 'page_num', 'block_num', 'par_num', 'line_num', 'word_num', 'left', 'top', 'width', 'height']:
                    if key in data_dict:
                        data_dict[key] = [int(v) for v in data_dict[key] if v.isdigit()]
                if 'conf' in data_dict:
                    data_dict['conf'] = [float(v) for v in data_dict['conf'] if v != '-1']

                return {"status": "success", "data": dict(data_dict), "full_text": full_text}
                
            except Exception as e:
                logger.error(f"ERROR: è¯»å–æˆ–è§£æTesseractç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}", exc_info=True)
                return {"status": "error", "message": f"è¯»å–æˆ–è§£æTesseractç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}"}

        except Exception as e:
            logger.error(f"ERROR: _execute_tesseract_subprocess å¤–éƒ¨ä¸»å—å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}", exc_info=True)
            return {"status": "error", "message": f"Tesseractæ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°æ„å¤–é”™è¯¯: {str(e)}", "traceback": traceback.format_exc()}
        finally:
            for path in [temp_image_path, temp_output_txt, temp_output_tsv, temp_config_path]:
                if path and os.path.exists(path):
                    try:
                        os.remove(path)
                    except Exception as e:
                        logger.warning(f"WARNING: æ— æ³•æ¸…ç†ä¸´æ—¶æ–‡ä»¶ {path}: {e}")
    def set_tesseract_path(self, path: str):
        """è®¾ç½®Tesseractçš„å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„å¹¶éªŒè¯"""
        try:
            import pytesseract
            if path and os.path.exists(path) and shutil.which(path):
                self.tesseract_path = path
                pytesseract.pytesseract.tesseract_cmd = path
                logger.info(f"å·²æˆåŠŸè®¾ç½®Tesseractè·¯å¾„: {path}")
                return True, "Tesseractè·¯å¾„è®¾ç½®æˆåŠŸ"
            else:
                logger.warning(f"æä¾›çš„Tesseractè·¯å¾„æ— æ•ˆæˆ–ä¸å¯æ‰§è¡Œ: {path}")
                return False, "æä¾›çš„è·¯å¾„æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸å¯æ‰§è¡Œ"
        except Exception as e:
            logger.error(f"è®¾ç½®Tesseractè·¯å¾„æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False, f"è®¾ç½®è·¯å¾„æ—¶å‡ºé”™: {e}"

    def initialize(self, language: OCRLanguage = OCRLanguage.AUTO, 
               use_gpu: bool = False, **kwargs) -> Tuple[bool, str]:
        """
        åˆå§‹åŒ–CVOCRæ¨¡å‹ (V4.3 - æ£€æµ‹å™¨é€»è¾‘ä¿®æ­£ç‰ˆ)ã€‚
        - å®ä¾‹åŒ– EnhancedTextDetector ä½œä¸ºæ”¯æŒè‡ªå®šä¹‰ç®—æ³•ç»„åˆçš„ä¸»æ–‡æœ¬æ£€æµ‹å™¨ã€‚
        - PPOCRv3 æ¨¡å‹ä»ç„¶ä¼šæŒ‰éœ€åŠ è½½ï¼Œä½†ä¸»æ£€æµ‹é€»è¾‘ç”± EnhancedTextDetector é©±åŠ¨ã€‚
        """
        # ### å…³é”®ä¿®æ­£ï¼šåœ¨æ–¹æ³•æœ€å¼€å§‹å°±å¤„ç†Tesseractè·¯å¾„ ###
        tesseract_path_from_config = self.config.get('tesseract_path')
        if tesseract_path_from_config:
            success, msg = self.set_tesseract_path(tesseract_path_from_config)
            if not success:
                self.logger_func(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸­çš„Tesseractè·¯å¾„æ— æ•ˆ: {tesseract_path_from_config}. {msg}", "WARNING")
        
        try:
            import pytesseract
        except ImportError:
            return False, "pytesseractæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install pytesseract"
        
        if self.is_initialized:
            logger.info("CVOCRå¼•æ“å·²åˆå§‹åŒ–ï¼Œæ— éœ€é‡å¤ã€‚")
            return True, "CVOCRå¼•æ“å·²åˆå§‹åŒ–"

        # --- æ ¸å¿ƒé€»è¾‘ä¿®æ­£ï¼šå®ä¾‹åŒ– EnhancedTextDetector ä½œä¸ºä¸»æ£€æµ‹å™¨ ---
        # è¿™å°†ä½¿GUIä¸­çš„é«˜çº§åˆ†å‰²æŠ€æœ¯é€‰é¡¹èƒ½å¤Ÿæ­£å¸¸å·¥ä½œã€‚
        try:
            self.text_detector = EnhancedTextDetector()
            logger.info("âœ… æˆåŠŸåˆå§‹åŒ–æ”¯æŒè‡ªå®šä¹‰ç®—æ³•ç»„åˆçš„ EnhancedTextDetectorã€‚")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ– EnhancedTextDetector å¤±è´¥: {e}", exc_info=True)
            return False, f"åˆå§‹åŒ– EnhancedTextDetector å¤±è´¥: {e}"
        

        # æ ¹æ®é…ç½®åˆ›å»ºå…¨å…ƒç´ æ£€æµ‹å™¨ (YOLO)
        try:
            self.unified_detector = UnifiedObjectDetector(
                logger_func=self.logger_func,
                cfg_path=self.config.get('yolo_cfg_path', 'yolov4-tiny.cfg'),
                weights_path=self.config.get('yolo_weights_path', 'yolov4-tiny.weights'),
                names_path=self.config.get('yolo_names_path', 'coco.names')
            )
            if self.unified_detector.net is None:
                self.unified_detector = None
        except Exception as e:
            self.unified_detector = None
            self.logger_func(f"âŒ åˆå§‹åŒ–YOLOæ£€æµ‹å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}", "ERROR")

        # æ£€æŸ¥AIåº“ä¾èµ–
        try:
            import torch
            from transformers import (
                LayoutLMv2Processor, LayoutLMv2ForTokenClassification,
                TrOCRProcessor, VisionEncoderDecoderModel,
                GPT2Tokenizer, GPTNeoForCausalLM
            )
        except ImportError as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥ï¼šç¼ºå°‘å¿…è¦çš„AI/å›¾åƒå¤„ç†åº“: {e}ã€‚", exc_info=True)
            return False, f"åˆå§‹åŒ–å¤±è´¥ï¼šç¼ºå°‘å¿…è¦çš„AI/å›¾åƒå¤„ç†åº“: {e}ã€‚è¯·è¿è¡Œ 'pip install torch transformers sentencepiece'"
        
        start_init_time = time.time()
        
        if use_gpu and torch.cuda.is_available():
            self.device = "cuda"
            logger.info("âœ… æ£€æµ‹åˆ°å¯ç”¨GPUï¼Œå°†ä½¿ç”¨CUDAè¿›è¡ŒåŠ é€Ÿã€‚")
        else:
            self.device = "cpu"
            if use_gpu:
                logger.warning("âš ï¸ è¯·æ±‚ä½¿ç”¨GPUï¼Œä½†æœªæ£€æµ‹åˆ°å¯ç”¨çš„CUDAè®¾å¤‡ï¼Œå°†å›é€€åˆ°CPUã€‚")
            else:
                logger.info("â„¹ï¸ å°†ä½¿ç”¨CPUè¿›è¡Œè®¡ç®—ã€‚")

        self.language = language
        
        logger.info(f"å¼€å§‹åˆå§‹åŒ–CVOCRå¼•æ“ (è¯­è¨€: {language.value}, ç²¾åº¦: custom, è®¾å¤‡: {self.device})")
        
        success, message = self._initialize_tesseract()
        if not success:
            return False, message

        # åŠ è½½é«˜çº§AIæ¨¡å‹
        try:
            logger.info("â„¹ï¸ FSRCNNåŠŸèƒ½å·²è¢«ç§»é™¤ï¼Œè·³è¿‡åŠ è½½ã€‚")
            
            if self.config.get('enable_layout_analysis', False):
                try:
                    self.layoutlm_processor = LayoutLMv2Processor.from_pretrained("microsoft/layoutlmv2-base-uncased")
                    self.layoutlm_model = LayoutLMv2ForTokenClassification.from_pretrained("microsoft/layoutlmv2-base-uncased").to(self.device)
                    self.layoutlm_model.eval()
                    logger.info("âœ… LayoutLMv2æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
                except Exception as e:
                    self.layoutlm_model, self.layoutlm_processor = None, None
                    logger.error(f"âŒ LayoutLMv2æ¨¡å‹åŠ è½½å¤±è´¥: {e}", exc_info=True)
            else:
                logger.info("â„¹ï¸ LayoutLMv2æœªå¯ç”¨ï¼Œè·³è¿‡åŠ è½½ã€‚")

            if self.config.get('enable_transformer_ocr', False):
                try:
                    model_name = self.config.get('transformer_ocr_model', 'microsoft/trocr-base-printed')
                    logger.info(f"æ­£åœ¨åŠ è½½æŒ‡å®šçš„TrOCRæ¨¡å‹: {model_name}")
                    self.trocr_processor = TrOCRProcessor.from_pretrained(model_name, use_fast=True)
                    self.trocr_model = VisionEncoderDecoderModel.from_pretrained(model_name, ignore_mismatched_sizes=True).to(self.device)
                    self.trocr_model.eval()
                    logger.info(f"âœ… TrOCRæ¨¡å‹ ({model_name}) åŠ è½½æˆåŠŸã€‚")
                except Exception as e:
                    self.trocr_model, self.trocr_processor = None, None
                    logger.error(f"âŒ TrOCRæ¨¡å‹åŠ è½½å¤±è´¥: {e}", exc_info=True)
            else:
                logger.info("â„¹ï¸ TrOCRæœªå¯ç”¨ï¼Œè·³è¿‡åŠ è½½ã€‚")

            if self.config.get('enable_context_analysis', False):
                try:
                    self.gpt_neo_tokenizer = GPT2Tokenizer.from_pretrained("EleutherAI/gpt-neo-125M")
                    self.gpt_neo_model = GPTNeoForCausalLM.from_pretrained("EleutherAI/gpt-neo-125M").to(self.device)
                    self.gpt_neo_model.eval()
                    self.gpt_neo_tokenizer.pad_token = self.gpt_neo_tokenizer.eos_token
                    logger.info("âœ… GPT-Neoæ¨¡å‹åŠ è½½æˆåŠŸã€‚")
                except Exception as e:
                    self.gpt_neo_model, self.gpt_neo_tokenizer = None, None
                    logger.error(f"âŒ GPT-Neoæ¨¡å‹åŠ è½½å¤±è´¥: {e}", exc_info=True)
            else:
                logger.info("â„¹ï¸ GPT-Neoæœªå¯ç”¨ï¼Œè·³è¿‡åŠ è½½ã€‚")

        except Exception as e:
            logger.error(f"âŒ åŠ è½½é«˜çº§AIæ¨¡å‹æ—¶å‘ç”Ÿå¤–éƒ¨æ„å¤–é”™è¯¯: {e}", exc_info=True)
            return False, f"åŠ è½½é«˜çº§AIæ¨¡å‹æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç£ç›˜ç©ºé—´ã€‚"

        init_time = time.time() - start_init_time
        self.is_initialized = True

        self.version_info = {
            'cvocr_version': CVOCRConstants.VERSION,
            'python': sys.version.split()[0],
            'tesseract': CVOCRVersionManager.get_tesseract_version(self.tesseract_path),
            'transformers': CVOCRVersionManager.get_transformers_version(),
            'opencv': CVOCRVersionManager.get_opencv_version(),
            'torch': CVOCRVersionManager.get_torch_version(),
            'language': language.value,
            'use_gpu': self.device == "cuda",
            'device': self.device,
            'init_time': init_time,
            'config': self.config.copy(),
            'components': {
                'tesseract_enabled': True,
                'fsrcnn_enabled': False,
                'layoutlm_enabled': self.config.get('enable_layout_analysis', False) and (self.layoutlm_model is not None),
                'gpt_neo_enabled': self.config.get('enable_context_analysis', False) and (self.gpt_neo_model is not None),
                'transformer_ocr_enabled': self.config.get('enable_transformer_ocr', False) and (self.trocr_model is not None)
            },
            'system_info': CVOCRVersionManager.get_system_info(),
            'initialization_timestamp': datetime.now().isoformat()
        }
        
        test_success, test_msg = self._test_ocr_engine()
        if not test_success:
            self.is_initialized = False
            return False, f"CVOCRå¼•æ“åˆå§‹åŒ–æˆåŠŸï¼Œä½†TesseractåŸºç¡€æµ‹è¯•å¤±è´¥: {test_msg}"
        
        success_message = f"CVOCRå¼•æ“åˆå§‹åŒ–æˆåŠŸï¼šè¯­è¨€: {language.value}, ç²¾åº¦: custom, è€—æ—¶: {init_time:.2f}ç§’"
        logger.info(f"{success_message}, AIè®¾å¤‡: {self.device}")
        return True, success_message
    
    
    
    
    def _initialize_tesseract(self) -> Tuple[bool, str]:
        """åˆå§‹åŒ–Tesseract OCR (V3.4 è¯­è¨€åŒ…æ£€æŸ¥å¢å¼ºç‰ˆ)"""
        try:
            import pytesseract
            
            # --- å…³é”®ä¿®æ­£ï¼šåœ¨æ‰€æœ‰æ“ä½œå‰ï¼Œä¼˜å…ˆç¡®å®šå¹¶è®¾ç½®Tesseractå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ ---
            # æ£€æŸ¥ self.tesseract_path (è¯¥è·¯å¾„ç”± initialize æ–¹æ³•æˆ– set_tesseract_path æ–¹æ³•è®¾ç½®)ã€‚
            # å¦‚æœè¿™ä¸ªè·¯å¾„æœ‰æ•ˆå­˜åœ¨ï¼Œå°±å°†å…¶æ˜ç¡®åœ°åº”ç”¨åˆ° pytesseract åº“çš„å…¨å±€å‘½ä»¤å˜é‡ä¸­ã€‚
            # è¿™æ ·ï¼Œåç»­æ‰€æœ‰å¯¹ pytesseract çš„è°ƒç”¨ï¼ˆå¦‚ get_tesseract_versionï¼‰éƒ½ä¼šä½¿ç”¨è¿™ä¸ªæ­£ç¡®çš„è·¯å¾„ã€‚
            if self.tesseract_path and os.path.exists(self.tesseract_path):
                pytesseract.pytesseract.tesseract_cmd = self.tesseract_path
            
            # ç°åœ¨å¯ä»¥å®‰å…¨åœ°è°ƒç”¨ç‰ˆæœ¬æ£€æŸ¥ï¼Œå®ƒä¼šä¼˜å…ˆä½¿ç”¨ä¸Šé¢è®¾ç½®çš„è·¯å¾„
            try:
                version = pytesseract.get_tesseract_version()
                logger.info(f"Tesseract OCRå¼•æ“å¯ç”¨ï¼Œç‰ˆæœ¬: {version}")
            except Exception as e:
                logger.error(f"âŒ Tesseract å¯æ‰§è¡Œæ–‡ä»¶æ— æ³•è¿è¡Œæˆ–ç‰ˆæœ¬æ£€æµ‹å¤±è´¥: {e}", exc_info=True)
                return False, f"Tesseract å¯æ‰§è¡Œæ–‡ä»¶æ— æ³•è¿è¡Œæˆ–ç‰ˆæœ¬æ£€æµ‹å¤±è´¥: {e}"

            # --- ä¿®æ­£ï¼šç§»é™¤å¤šä½™çš„å‚æ•° ---
            # _get_tesseract_config æ–¹æ³•ç°åœ¨ä» self.config è¯»å–æ‰€æœ‰è®¾ç½®ï¼Œ
            # ä¸å†éœ€è¦ä»å¤–éƒ¨ä¼ å…¥å‚æ•°ã€‚
            tesseract_config_str = self._get_tesseract_config()
            self.tesseract_config = tesseract_config_str
            
            requested_langs = self.config['lang'].split('+')
            
            # ä½¿ç”¨ pytesseract.pytesseract.tesseract_cmd ä½œä¸ºå”¯ä¸€çš„çœŸç†æ¥æºï¼Œç®€åŒ–è·¯å¾„åˆ¤æ–­
            tesseract_executable_for_subprocess = pytesseract.pytesseract.tesseract_cmd

            try:
                available_langs_output = subprocess.run([tesseract_executable_for_subprocess, '--list-langs'], capture_output=True, text=True, check=True)
                available_langs = set(line.strip() for line in available_langs_output.stdout.splitlines() if line.strip() and not line.strip().startswith('tesseract'))
                
                missing_langs = [lang for lang in requested_langs if lang not in available_langs]
                
                message = f"Tesseractåˆå§‹åŒ–æˆåŠŸï¼Œç‰ˆæœ¬: {version}"
                if missing_langs:
                    logger.warning(f"âš ï¸ ç¼ºå°‘Tesseractè¯­è¨€åŒ…: {', '.join(missing_langs)}ã€‚è¯·å®‰è£…ã€‚")
                    if not any(lang in available_langs for lang in requested_langs):
                        return False, f"Tesseractç¼ºå°‘æ‰€æœ‰è¯·æ±‚çš„è¯­è¨€åŒ…: {', '.join(requested_langs)}ã€‚è¯·å®‰è£…ã€‚"
                    else:
                        message += f" (è­¦å‘Š: ç¼ºå°‘è¯­è¨€åŒ… {', '.join(missing_langs)})"
            except FileNotFoundError:
                logger.error(f"âŒ Tesseractå¯æ‰§è¡Œæ–‡ä»¶ '{tesseract_executable_for_subprocess}' æœªæ‰¾åˆ°ï¼Œæ— æ³•æ£€æŸ¥è¯­è¨€åŒ…ã€‚", exc_info=True)
                return False, f"Tesseractå¯æ‰§è¡Œæ–‡ä»¶ '{tesseract_executable_for_subprocess}' æœªæ‰¾åˆ°ï¼Œæ— æ³•æ£€æŸ¥è¯­è¨€åŒ…ã€‚"
            except subprocess.CalledProcessError as e:
                logger.error(f"âŒ Tesseract --list-langs å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e.stderr}", exc_info=True)
                return False, f"Tesseract --list-langs å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e.stderr}"
            except Exception as e:
                logger.error(f"âŒ æ£€æŸ¥Tesseractè¯­è¨€åŒ…æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)
                return False, f"æ£€æŸ¥Tesseractè¯­è¨€åŒ…æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
            
            return True, message
                
        except ImportError:
            logger.error("âŒ pytesseractæœªå®‰è£…ï¼Œè¯·å®‰è£…: pip install pytesseract", exc_info=True)
            return False, "pytesseractæœªå®‰è£…ï¼Œè¯·å®‰è£…: pip install pytesseract"
        except Exception as e:
            logger.error(f"âŒ Tesseractåˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            return False, f"Tesseractåˆå§‹åŒ–å¤±è´¥: {str(e)}"
    def _get_tesseract_config(self, lang_override: Optional[str] = None, psm_override: Optional[int] = None) -> List[Tuple[str, str]]:
        """
        æ ¹æ®UIè®¾ç½®æ„å»ºTesseracté…ç½®åˆ—è¡¨ (V4.8 - æ”¯æŒPSMè¦†ç›–ç‰ˆ)ã€‚
        è¿”å›ä¸€ä¸ªé…ç½®å…ƒç»„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç»„æ˜¯ (é…ç½®å­—ç¬¦ä¸², æè¿°)ã€‚
        """
        # --- PSM (é¡µé¢åˆ†å‰²æ¨¡å¼) ---
        if psm_override is not None:
            psm_val = str(psm_override)
        else:
            psm_value_from_config = self.config.get('psm', '6')
            if isinstance(psm_value_from_config, str):
                psm_val = psm_value_from_config.split(':')[0].strip()
            else:
                psm_val = str(psm_value_from_config)

        # --- OEM (å¼•æ“æ¨¡å¼) ---
        selected_oems = self.config.get('oem_options', {'3': True})
        enabled_oem_keys = [key for key, enabled in selected_oems.items() if enabled]
        
        oem_defs = {
            '0': "ç»å…¸å¼•æ“", '1': "ç¥ç»ç½‘ç»œ(LSTM)", 
            '2': "ç»å…¸+LSTM", '3': "é»˜è®¤(æ¨èLSTM)"
        }
        
        # è¯­è¨€
        lang_code = lang_override if lang_override else self.config.get('lang', 'chi_sim+eng')

        # ã€å…³é”®ã€‘åŸºç¡€é¢å¤–é…ç½®ï¼ˆåŒ…å«ä¸­æ–‡ä¼˜åŒ–ï¼‰
        extra_configs = []
        if 'chi_sim' in lang_code or 'chi_tra' in lang_code:
            extra_configs.extend([
                '-c textord_tabfind_find_tables=1',
                '-c chopper_enable=0',
                '-c preserve_interword_spaces=1',
                '-c language_model_penalty_non_freq_dict_word=0.1',
                '-c language_model_penalty_non_dict_word=0.15',
            ])
        extra_config_str = ' '.join(extra_configs)
        
        configs_to_run = []

        if not enabled_oem_keys:
            desc = f"è¿è¡Œ: PSM={psm_val}, OEM=Tesseracté»˜è®¤"
            config_str = f'--psm {psm_val} -l {lang_code} {extra_config_str}'
            configs_to_run.append((config_str.strip(), desc))
        else:
            for oem_key in enabled_oem_keys:
                desc = f"è¿è¡Œ: PSM={psm_val}, OEM={oem_key} ({oem_defs[oem_key]})"
                config_str = f'--psm {psm_val} --oem {oem_key} -l {lang_code} {extra_config_str}'
                configs_to_run.append((config_str.strip(), desc))
        
        # self.configçš„æ›´æ–°ä¿æŒä¸å˜
        self.config['psm_val'] = psm_val
        self.config['lang'] = lang_code
        
        return configs_to_run
    
    
    def _test_ocr_engine(self) -> Tuple[bool, str]:
        """æµ‹è¯•OCRå¼•æ“ (ä»…æµ‹è¯•TesseractåŸºç¡€åŠŸèƒ½)"""
        try:
            test_img = np.ones((100, 400, 3), dtype=np.uint8) * 255
            cv2.putText(test_img, 'CVOCR Test 2025', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
            test_pil_img = Image.fromarray(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))
            
            tesseract_result = self._execute_tesseract_subprocess(
                image_pil=test_pil_img, tesseract_cmd_path=self.tesseract_path,
                config_str=self.tesseract_config, timeout=self.config.get('tesseract_process_timeout', 300)
            )
            if tesseract_result['status'] == 'error':
                logger.error(f"OCRå¼•æ“æµ‹è¯•å¤±è´¥ (Tesseractå­è¿›ç¨‹é”™è¯¯): {tesseract_result['message']}")
                return False, f"OCRå¼•æ“æµ‹è¯•å¤±è´¥: {tesseract_result['message']}"

            result = tesseract_result['full_text']
            
            if any(word in result.upper() for word in ['CVOCR', 'TEST', '2025']):
                return True, f"OCRå¼•æ“æµ‹è¯•é€šè¿‡ï¼Œè¯†åˆ«ç»“æœ: {result.strip()}"
            else:
                return True, f"OCRå¼•æ“å¯ç”¨ï¼Œæµ‹è¯•ç»“æœ: {result.strip()}"
                
        except Exception as e:
            logger.error(f"OCRå¼•æ“æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
            return False, f"OCRå¼•æ“æµ‹è¯•å¼‚å¸¸: {str(e)}"
    
    def _run_segmentation_and_recognize(self, image_np: np.ndarray, scale_factors: Tuple[float, float], regions: List[np.ndarray]) -> Tuple[Dict, str]:
        """
        ã€å¢å¼ºç‰ˆã€‘å¯¹æ¯ä¸ªå·²æ£€æµ‹åŒºåŸŸè¿›è¡Œè¯†åˆ« (V4.9 - ä¸­æ–‡è¯†åˆ«ä¿®æ­£ç‰ˆ)
        - è°ƒç”¨å¢å¼ºçš„é…ç½®ç”Ÿæˆå‡½æ•°ï¼Œç¡®ä¿åœ¨ä½¿ç”¨é«˜çº§åˆ†å‰²æ—¶ï¼Œä¸ºTesseractä¼ å…¥æ­£ç¡®çš„PSMæ¨¡å¼å’Œæ‰€æœ‰å¿…éœ€çš„ä¸­æ–‡ä¼˜åŒ–å‚æ•°ã€‚
        - ä¿®å¤äº†åœ¨é«˜çº§åˆ†å‰²æµç¨‹ä¸­æ— æ³•æ­£ç¡®è¯†åˆ«ä¸­æ–‡çš„é—®é¢˜ã€‚
        - ä¿æŒäº†å¯¹TransformerOCRä½œä¸ºåŒºåŸŸè¯†åˆ«å¼•æ“çš„æ”¯æŒã€‚
        - ä¿æŒäº†å·²ä¿®å¤çš„ã€å®è§‚å‡†ç¡®çš„åæ ‡ç³»å…³è”é€»è¾‘ã€‚
        """
        if not regions: 
            logger.warning("è¯†åˆ«æµç¨‹ä¸­æ­¢ï¼šæ²¡æœ‰ä»ä¸Šæ¸¸æ£€æµ‹å™¨æ¥æ”¶åˆ°ä»»ä½•æ–‡æœ¬åŒºåŸŸã€‚")
            return {}, ""

        logger.info(f"ğŸš€ å¼€å§‹å¯¹ {len(regions)} ä¸ªå·²æ£€æµ‹åŒºåŸŸè¿›è¡Œè¯†åˆ«... ç¼©æ”¾æ¯”ä¾‹: x={scale_factors[0]:.2f}, y={scale_factors[1]:.2f}")
        
        recognizer_engine = self.config.get('segmentation_recognizer', 'Tesseract')
        logger.info(f"å°†ä½¿ç”¨ '{recognizer_engine}' å¼•æ“è¿›è¡Œè¯†åˆ«ã€‚")
        
        all_ocr_data = defaultdict(list)
        recognized_parts = []
        scale_x, scale_y = scale_factors

        if recognizer_engine == "TransformerOCR" and self.trocr_model:
            self.performance_stats['component_usage']['transformer_ocr'] += 1
            region_images_for_trocr = []
            valid_region_boxes = []

            for region_box in regions:
                try:
                    rect = cv2.minAreaRect(region_box)
                    center, (width, height), angle = rect

                    # --- æœ€ç»ˆç‰ˆæ™ºèƒ½æ—‹è½¬é€»è¾‘ ---
                    if width < height:
                        width, height = height, width
                        swapped = True
                    else:
                        swapped = False

                    aspect_ratio = width / height if height > 0 else 0
                    if swapped and aspect_ratio > 1.5:
                        angle += 90
                    # --- é€»è¾‘ç»“æŸ ---

                    if width <= 5 or height <= 5: continue
                    width, height = int(width), int(height)

                    M = cv2.getRotationMatrix2D(center, angle, 1.0)
                    warped_bgr = cv2.warpAffine(image_np, M, (image_np.shape[1], image_np.shape[0]), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
                    cropped_bgr = cv2.getRectSubPix(warped_bgr, (width, height), center)
                    if cropped_bgr is None or cropped_bgr.size == 0: continue
                    
                    region_images_for_trocr.append(cropped_bgr)
                    valid_region_boxes.append(region_box)
                except Exception as e:
                    logger.warning(f"å¤„ç†åŒºåŸŸä»¥å‡†å¤‡TrOCRè¾“å…¥æ—¶å‡ºé”™: {e}")

            if region_images_for_trocr:
                trocr_results = self._apply_transformer_ocr(region_images_for_trocr)
                for i, result in enumerate(trocr_results):
                    if result.get('error') or not result['text'].strip(): continue
                    
                    region_box = valid_region_boxes[i]
                    x_coords, y_coords = region_box[:, 0], region_box[:, 1]
                    x_start, y_start = int(np.min(x_coords)), int(np.min(y_coords))
                    width, height = int(np.max(x_coords) - x_start), int(np.max(y_coords) - y_start)
                    
                    all_ocr_data['left'].append(int(x_start * scale_x))
                    all_ocr_data['top'].append(int(y_start * scale_y))
                    all_ocr_data['width'].append(int(width * scale_x))
                    all_ocr_data['height'].append(int(height * scale_y))
                    all_ocr_data['text'].append(result['text'])
                    all_ocr_data['conf'].append(result['confidence'])
                    all_ocr_data['word_num'].append(len(result['text'].split()))
                    all_ocr_data['line_num'].append(1)
                    all_ocr_data['par_num'].append(1)
                    all_ocr_data['block_num'].append(i + 1)
                    
                    recognized_parts.append({'text': result['text'], 'y_coord': int(y_start * scale_y), 'x_coord': int(x_start * scale_x)})
        else:
            if recognizer_engine == "TransformerOCR":
                logger.warning("TrOCRè¢«é€‰ä¸ºè¯†åˆ«å¼•æ“ï¼Œä½†æ¨¡å‹æœªåŠ è½½ã€‚å°†è‡ªåŠ¨å›é€€åˆ°Tesseractã€‚")
            self.performance_stats['component_usage']['tesseract'] += 1
            tesseract_timeout = self.config.get('tesseract_process_timeout', 300)
            
            use_fine_tuning = self.config.get('enable_tesseract_fine_tuning', True)
            if use_fine_tuning:
                logger.info("Tesseractç²¾ç»†åŒ–é¢„å¤„ç†å·²å¯ç”¨ã€‚")
            else:
                logger.info("Tesseractç²¾ç»†åŒ–é¢„å¤„ç†å·²ç¦ç”¨ã€‚")
            
            # ã€æ ¸å¿ƒä¿®æ­£ã€‘: è°ƒç”¨å¢å¼ºçš„é…ç½®ç”Ÿæˆå‡½æ•°ï¼Œå¹¶ä¼ å…¥ä»GUIè§£æçš„PSMå€¼
            psm_str_from_gui = self.settings['psm_mode'].get()
            psm_val = int(psm_str_from_gui.split(':')[0].strip())

            # è°ƒç”¨ä¸­å¤®é…ç½®å‡½æ•°ï¼Œå¹¶è¦†ç›–PSMå€¼ï¼Œä»¥è·å¾—åŒ…å«æ‰€æœ‰ä¼˜åŒ–ï¼ˆåŒ…æ‹¬ä¸­æ–‡ï¼‰çš„å®Œæ•´é…ç½®
            configs_list = self._get_tesseract_config(psm_override=psm_val)
            tesseract_config_for_regions = configs_list[0][0] if configs_list else ""
            
            # æ›´æ–°æ—¥å¿—ï¼Œä½¿å…¶å‡†ç¡®åæ˜ æ­£åœ¨ä½¿ç”¨çš„é…ç½®
            logger.info(f"æ‰€æœ‰åŒºåŸŸå°†ä½¿ç”¨é…ç½®: '{tesseract_config_for_regions}'")
            logger.warning(f"å½“å‰ä½¿ç”¨çš„PSMæ¨¡å¼ä¸º '{psm_str_from_gui}'ã€‚å¦‚æœè¯†åˆ«æ•ˆæœä¸ä½³ï¼Œ"
                           f"è¯·ç¡®ä¿æ­¤æ¨¡å¼é€‚åˆå¤„ç†å·²åˆ†å‰²çš„ç‹¬ç«‹æ–‡æœ¬å—ï¼ˆæ¨èä½¿ç”¨PSM 6, 7, 8, 13ç­‰ï¼‰ã€‚")

            for i, region_box in enumerate(regions):
                try:
                    rect = cv2.minAreaRect(region_box)
                    center, (width, height), angle = rect

                    # æ™ºèƒ½æ—‹è½¬é€»è¾‘
                    if width < height:
                        width, height = height, width
                        swapped = True
                    else:
                        swapped = False
                    aspect_ratio = width / height if height > 0 else 0
                    if swapped and aspect_ratio > 1.5: angle += 90
                    
                    if width <= 5 or height <= 5: continue
                    width, height = int(width), int(height)

                    # åˆ‡å‰²å¹¶æ ¡æ­£åŒºåŸŸ
                    M = cv2.getRotationMatrix2D(center, angle, 1.0)
                    warped_bgr = cv2.warpAffine(image_np, M, (image_np.shape[1], image_np.shape[0]), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
                    cropped_bgr = cv2.getRectSubPix(warped_bgr, (width, height), center)
                    if cropped_bgr is None or cropped_bgr.size == 0: continue
                    
                    # åº”ç”¨ç²¾ç»†åŒ–é¢„å¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    processed_for_ocr = cropped_bgr
                    if use_fine_tuning:
                        gray_cropped = cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2GRAY)
                        h_proc, _ = gray_cropped.shape
                        if h_proc > 0 and (h_proc < 24 or h_proc > 64):
                            scale = 40.0 / h_proc
                            gray_cropped = cv2.resize(gray_cropped, (0,0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
                        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
                        enhanced = clahe.apply(gray_cropped)
                        _, binarized = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                        bordered = cv2.copyMakeBorder(binarized, 8, 8, 8, 8, cv2.BORDER_CONSTANT, value=[255])
                        processed_for_ocr = cv2.cvtColor(bordered, cv2.COLOR_GRAY2BGR)
                    
                    cropped_pil = Image.fromarray(cv2.cvtColor(processed_for_ocr, cv2.COLOR_BGR2RGB))
                    
                    # è°ƒç”¨Tesseract
                    region_result = self._execute_tesseract_subprocess(
                        image_pil=cropped_pil, tesseract_cmd_path=self.tesseract_path,
                        config_str=tesseract_config_for_regions, timeout=tesseract_timeout
                    )
                    
                    if region_result["status"] == "success" and region_result.get("full_text", "").strip():
                        full_text_from_region = region_result.get("full_text", "").strip()
                        
                        x, y, w, h = cv2.boundingRect(region_box.astype(np.int32))
                        
                        confidences = region_result.get("data", {}).get("conf", [])
                        avg_conf = sum(confidences) / len(confidences) if confidences else 95.0

                        all_ocr_data['left'].append(int(x * scale_x))
                        all_ocr_data['top'].append(int(y * scale_y))
                        all_ocr_data['width'].append(int(w * scale_x))
                        all_ocr_data['height'].append(int(h * scale_y))
                        all_ocr_data['text'].append(full_text_from_region)
                        all_ocr_data['conf'].append(avg_conf)
                        
                        all_ocr_data['word_num'].append(len(full_text_from_region.split()))
                        all_ocr_data['line_num'].append(i + 1)
                        all_ocr_data['par_num'].append(i + 1)
                        all_ocr_data['block_num'].append(i + 1)
                        
                        recognized_parts.append({
                            'text': full_text_from_region, 
                            'y_coord': int(y * scale_y), 
                            'x_coord': int(x * scale_x)
                        })

                except Exception as e:
                    logger.warning(f"å¤„ç†åŒºåŸŸ {i} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue

        # æŒ‰é˜…è¯»é¡ºåºå¯¹æ‰€æœ‰è¯†åˆ«å‡ºçš„æ–‡æœ¬ç‰‡æ®µè¿›è¡Œæ’åº
        recognized_parts.sort(key=lambda item: (item['y_coord'], item['x_coord']))
        final_full_text = "\n".join([part['text'] for part in recognized_parts])

        return dict(all_ocr_data), final_full_text
    
    
    
    def _calculate_bbox_iou_for_polygons(self, poly1, poly2) -> float:
        """è®¡ç®—ä¸¤ä¸ªå¤šè¾¹å½¢åŒºåŸŸçš„äº¤å¹¶æ¯”(IoU)"""
        try:
            r1 = cv2.boundingRect(poly1.astype(int))
            r2 = cv2.boundingRect(poly2.astype(int))
            
            max_x = max(r1[0]+r1[2], r2[0]+r2[2])
            max_y = max(r1[1]+r1[3], r2[1]+r2[3])
            
            img1 = np.zeros((max_y, max_x), dtype=np.uint8)
            img2 = np.zeros((max_y, max_x), dtype=np.uint8)

            cv2.fillPoly(img1, [poly1.astype(int)], 255)
            cv2.fillPoly(img2, [poly2.astype(int)], 255)
            
            intersection = np.sum(cv2.bitwise_and(img1, img2) > 0)
            union = np.sum(cv2.bitwise_or(img1, img2) > 0)
            
            return intersection / union if union > 0 else 0.0
        except Exception:
            return 0.0
    def _merge_blocks_by_layoutlm(self, ocr_data: Dict, layout_info: Dict) -> Dict:
        """
        ä½¿ç”¨LayoutLMv2çš„åˆ†æç»“æœï¼Œå¯¹OCRæ–‡æœ¬å—è¿›è¡Œè¯­ä¹‰åˆå¹¶ã€‚
        
        Args:
            ocr_data (Dict): åŒ…å«å¤šä¸ª'text_blocks'çš„åŸå§‹OCRç»“æœã€‚
            layout_info (Dict): æ¥è‡ªLayoutLMv2çš„å¸ƒå±€åˆ†æç»“æœã€‚

        Returns:
            Dict: åˆå¹¶åçš„æ–°çš„OCRç»“æœå­—å…¸ã€‚
        """
        self.logger_func("ğŸ§  å¼€å§‹æ‰§è¡ŒåŸºäºLayoutLMv2çš„è¯­ä¹‰åˆå¹¶...", "INFO")
        if not ocr_data.get('text_blocks') or not layout_info.get('text_regions'):
            self.logger_func("âš ï¸ è¯­ä¹‰åˆå¹¶ä¸­æ­¢ï¼šç¼ºå°‘OCRæ–‡æœ¬å—æˆ–LayoutLMv2åˆ†æç»“æœã€‚", "WARNING")
            return ocr_data

        # 1. ä¸ºæ¯ä¸ªåŸå§‹OCRå—åŒ¹é…ä¸€ä¸ªLayoutLMv2çš„è¯­ä¹‰æ ‡ç­¾
        ocr_blocks = ocr_data['text_blocks']
        for block in ocr_blocks:
            # _match_text_to_layout ä¼šè¿”å› {'region_type': 'Paragraph', ...}
            block['layout_info'] = self._match_text_to_layout(block, layout_info)

        # 2. æŒ‰è¯­ä¹‰æ ‡ç­¾å’Œç©ºé—´ä½ç½®è¿›è¡Œåˆ†ç»„
        # æˆ‘ä»¬åªåˆå¹¶è¢«æ ‡è®°ä¸º 'Paragraph', 'List', 'Table' çš„å—
        mergeable_tags = {'Paragraph', 'List', 'Table', 'Section-header'}
        
        merged_blocks = []
        processed_indices = set()
        
        # æŒ‰é˜…è¯»é¡ºåºæ’åº
        ocr_blocks.sort(key=lambda b: (b['bbox'][1], b['bbox'][0]))

        for i in range(len(ocr_blocks)):
            if i in processed_indices:
                continue

            current_block = ocr_blocks[i]
            current_tag = current_block.get('layout_info', {}).get('region_type', 'unknown')

            # å¦‚æœå½“å‰å—ä¸å¯åˆå¹¶ï¼Œæˆ–æ²¡æœ‰æ ‡ç­¾ï¼Œåˆ™ç›´æ¥ä¿ç•™
            if current_tag not in mergeable_tags:
                merged_blocks.append(current_block)
                processed_indices.add(i)
                continue

            # åˆ›å»ºä¸€ä¸ªæ–°çš„åˆå¹¶ç»„
            merge_group = [current_block]
            processed_indices.add(i)

            # å‘åæŸ¥æ‰¾å¯ä»¥åˆå¹¶åˆ°æ­¤ç»„çš„å…¶ä»–å—
            for j in range(i + 1, len(ocr_blocks)):
                if j in processed_indices:
                    continue
                
                next_block = ocr_blocks[j]
                next_tag = next_block.get('layout_info', {}).get('region_type', 'unknown')

                # åˆå¹¶æ¡ä»¶ï¼šè¯­ä¹‰æ ‡ç­¾ç›¸åŒï¼Œä¸”åœ¨ç©ºé—´ä¸Šæ˜¯è¿ç»­çš„
                if next_tag == current_tag:
                    # ç®€å•çš„ç©ºé—´è¿ç»­æ€§åˆ¤æ–­ï¼šä¸‹ä¸€ä¸ªå—çš„å·¦ä¸Šè§’Yåæ ‡ä¸å½“å‰ç»„çš„
                    # æœ€åä¸€ä¸ªå—çš„å·¦ä¸‹è§’Yåæ ‡ç›¸å·®ä¸å¤§ï¼ˆåœ¨ä¸€ä¸ªè¡Œé«˜å†…ï¼‰
                    last_block_in_group = merge_group[-1]
                    y_gap = next_block['bbox'][1] - last_block_in_group['bbox'][3]
                    line_height = last_block_in_group['bbox'][3] - last_block_in_group['bbox'][1]
                    
                    if y_gap < line_height: # å‚ç›´é—´éš™å°äºä¸€ä¸ªè¡Œé«˜
                        merge_group.append(next_block)
                        processed_indices.add(j)

            # 3. å°†åˆå¹¶ç»„ä¸­çš„æ‰€æœ‰å—èšåˆæˆä¸€ä¸ªå¤§å—
            if len(merge_group) > 1:
                # åˆå¹¶æ–‡æœ¬
                full_text = "\n".join([b['text'] for b in merge_group])
                # åˆå¹¶è¾¹ç•Œæ¡†
                min_x = min(b['bbox'][0] for b in merge_group)
                min_y = min(b['bbox'][1] for b in merge_group)
                max_x = max(b['bbox'][2] for b in merge_group)
                max_y = max(b['bbox'][3] for b in merge_group)
                
                # è®¡ç®—åˆå¹¶åçš„å¹³å‡ç½®ä¿¡åº¦
                avg_conf = np.mean([b['confidence'] for b in merge_group])

                merged_block = {
                    'text': full_text,
                    'confidence': int(avg_conf),
                    'bbox': [min_x, min_y, max_x, max_y],
                    'word_num': len(full_text.split()),
                    'line_num': len(full_text.split('\n')),
                    'par_num': 1, # æ•´ä¸ªç»„åˆå¹¶æˆä¸€ä¸ªæ®µè½
                    'block_num': merge_group[0]['block_num'],
                    'layout_info': {'region_type': f"Merged-{current_tag}"}
                }
                merged_blocks.append(merged_block)
                self.logger_func(f"  -> æˆåŠŸå°† {len(merge_group)} ä¸ª '{current_tag}' å—åˆå¹¶ã€‚", "DEBUG")
            else:
                # å¦‚æœç»„é‡Œåªæœ‰ä¸€ä¸ªå—ï¼Œç›´æ¥ä¿ç•™
                merged_blocks.append(current_block)

        # 4. æ„å»ºæ–°çš„ ocr_data
        new_ocr_data = ocr_data.copy()
        new_ocr_data['text_blocks'] = merged_blocks
        new_ocr_data['full_text'] = "\n\n".join([b['text'] for b in merged_blocks])
        new_ocr_data['total_blocks'] = len(merged_blocks)
        
        self.logger_func(f"ğŸ§  è¯­ä¹‰åˆå¹¶å®Œæˆï¼Œæ–‡æœ¬å—ä» {len(ocr_blocks)} ä¸ªå‡å°‘åˆ° {len(merged_blocks)} ä¸ªã€‚", "SUCCESS")
        return new_ocr_data        
    def recognize_text_enhanced(self, image_path: str, enable_preprocessing: bool = True) -> Tuple[Optional[Dict], str]:
        """
        CVOCRå¢å¼ºæ–‡æœ¬è¯†åˆ«çš„æ ¸å¿ƒå®ç° (V4.9 - LayoutLMv2è¯­ä¹‰åˆå¹¶é›†æˆç‰ˆ)
        - æ–°å¢ä¸€ä¸ªåŸºäºLayoutLMv2çš„è¯­ä¹‰åˆå¹¶åˆ†æ”¯ï¼Œåœ¨æ‰€æœ‰è¯†åˆ«å’Œåˆ†æå®Œæˆåæ‰§è¡Œã€‚
        - æ ¹æ®ç”¨æˆ·çš„GUIé€‰æ‹©ï¼Œåœ¨çº¯å‡ ä½•åˆå¹¶å’Œé«˜çº§è¯­ä¹‰åˆå¹¶ä¹‹é—´è¿›è¡Œåˆ‡æ¢ã€‚
        - ç¡®ä¿åœ¨è°ƒç”¨è¯­ä¹‰åˆå¹¶å‰ï¼Œæ‰€æœ‰å¿…è¦çš„æ•°æ®ï¼ˆåˆæ­¥OCRç»“æœã€LayoutLMv2åˆ†æï¼‰éƒ½å·²å‡†å¤‡å°±ç»ªã€‚
        """
        recognition_start_time = time.time()
        
        try:
            # --- æ­¥éª¤ 1: åˆå§‹åŒ–ç»Ÿè®¡å’Œé…ç½® ---
            self.performance_stats['total_recognitions'] += 1
            
            # --- æ­¥éª¤ 2: å›¾åƒé¢„å¤„ç† (ç»Ÿä¸€å…¥å£) ---
            self.logger_func("å·¥ä½œæµæ­¥éª¤1: æ­£åœ¨åº”ç”¨ç»Ÿä¸€çš„å›¾åƒé¢„å¤„ç†...", "INFO")
            image_processor = AdvancedTextImageProcessor()
            processed_image_np, preprocess_msg, metadata = image_processor.intelligent_preprocess_image(
                image_path, **self.config
            )
            if processed_image_np is None:
                self._update_failed_stats()
                return None, f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {preprocess_msg}"
            
            # è®¡ç®—åæ ‡è½¬æ¢æ¯”ä¾‹
            try:
                with Image.open(image_path) as img:
                    original_width, original_height = img.size
            except Exception as e:
                self._update_failed_stats()
                return None, f"æ— æ³•è¯»å–åŸå§‹å›¾åƒå°ºå¯¸: {e}"

            processed_height, processed_width = processed_image_np.shape[:2]
            scale_x = original_width / processed_width if processed_width > 0 else 1.0
            scale_y = original_height / processed_height if processed_height > 0 else 1.0

            # --- æ­¥éª¤ 3: æ–‡æœ¬ä¸å…ƒç´ æ£€æµ‹ (æ ¹æ®æ¨¡å¼é€‰æ‹©) ---
            text_regions = []
            shape_blocks = []

            # ã€æ ¸å¿ƒä¿®æ­£ã€‘: æ£€æŸ¥æ˜¯å¦ä¸ºå¿«é€Ÿæ¨¡å¼
            is_quick_mode = self.config.get('quick_mode', False)
            
            if is_quick_mode:
                # å·¥ä½œæµ C: å¿«é€Ÿæ¨¡å¼
                self.logger_func("å·¥ä½œæµæ­¥éª¤2: æ¨¡å¼[å¿«é€ŸOCR] -> è·³è¿‡æ–‡æœ¬æ£€æµ‹ï¼Œç›´æ¥è¿›è¡Œæ•´é¡µè¯†åˆ«...", "INFO")
                # åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ£€æµ‹åŒºåŸŸï¼Œæ‰€ä»¥ text_regions ä¿æŒä¸ºç©ºåˆ—è¡¨
                # åç»­çš„è¯†åˆ«é€»è¾‘å°†ç›´æ¥å¤„ç†æ•´å¼ å›¾ç‰‡
            
            else:
                is_full_element_mode = self.config.get('enable_advanced_segmentation', False)

                if is_full_element_mode:
                    # å·¥ä½œæµ A: å…¨å…ƒç´ æ£€æµ‹æ¨¡å¼
                    self.logger_func("å·¥ä½œæµæ­¥éª¤2: æ¨¡å¼[å…¨å…ƒç´ æ£€æµ‹] -> æ­£åœ¨ä½¿ç”¨YOLOè¿›è¡Œæ£€æµ‹...", "INFO")
                    if self.unified_detector and self.unified_detector.net:
                        self.performance_stats['component_usage']['unified_detector'] += 1
                        all_detected_objects = self.unified_detector.detect_all_objects(processed_image_np)
                        
                        for obj in all_detected_objects:
                            x1, y1, x2, y2 = obj['bbox']
                            if obj['label'] in ['text', 'table']:
                                points = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], dtype=np.float32)
                                text_regions.append(points)
                            else:
                                shape_blocks.append({
                                    'text': f"[{obj['label'].upper()}]", 'confidence': int(obj['confidence'] * 100),
                                    'bbox': obj['bbox'], 'is_shape': True,
                                    'word_num': 1, 'line_num': 1, 'par_num': 1, 'block_num': 999 
                                })
                        self.logger_func(f"YOLOæ£€æµ‹åˆ° {len(text_regions)} ä¸ªæ–‡æœ¬/è¡¨æ ¼åŒºåŸŸå’Œ {len(shape_blocks)} ä¸ªå›¾å½¢ã€‚", "INFO")
                    else:
                        self.logger_func("âš ï¸ å…¨å…ƒç´ æ£€æµ‹æ¨¡å¼å·²å¯ç”¨ï¼Œä½†YOLOæ£€æµ‹å™¨æœªåŠ è½½ã€‚", "WARNING")
                else:
                    # å·¥ä½œæµ B: çº¯æ–‡æœ¬OCRæ¨¡å¼
                    self.logger_func("å·¥ä½œæµæ­¥éª¤2: æ¨¡å¼[çº¯æ–‡æœ¬OCR] -> æ­£åœ¨ä½¿ç”¨é«˜çº§åˆ†å‰²æŠ€æœ¯è¿›è¡Œæ£€æµ‹...", "INFO")
                    self.performance_stats['component_usage']['advanced_segmentation'] += 1
                    enabled_algorithms = self.config.get('enabled_segmentation_algorithms', [])
                    self.text_detector.config.update(self.config)
                    
                    text_regions, _ = self.text_detector.detect_text_regions_advanced(
                        processed_image_np, enabled_algorithms
                    )
                    self.logger_func(f"é«˜çº§åˆ†å‰²æŠ€æœ¯æ£€æµ‹åˆ° {len(text_regions)} ä¸ªæ–‡æœ¬åŒºåŸŸã€‚", "INFO")

            # --- æ­¥éª¤ 4: åŒºåŸŸçš„åˆæ­¥è¯†åˆ« (æˆ–æ•´é¡µè¯†åˆ«) ---
            # ã€æ ¸å¿ƒä¿®æ­£ã€‘: æ ¹æ®æ˜¯å¦ä¸ºå¿«é€Ÿæ¨¡å¼ï¼Œé€‰æ‹©ä¸åŒçš„è¯†åˆ«ç­–ç•¥
            if is_quick_mode:
                self.logger_func("å·¥ä½œæµæ­¥éª¤3: å°†æ•´å¼ é¢„å¤„ç†åçš„å›¾ç‰‡é€å…¥Tesseractè¿›è¡Œç«¯åˆ°ç«¯è¯†åˆ«...", "INFO")
                
                # ç›´æ¥è°ƒç”¨ Tesseract å¤„ç†æ•´å¼ å›¾ç‰‡
                full_image_pil = Image.fromarray(cv2.cvtColor(processed_image_np, cv2.COLOR_BGR2RGB))
                tesseract_configs = self._get_tesseract_config() # è·å–ä¸ºå¿«é€Ÿæ¨¡å¼é…ç½®çš„ --psm 3 ç­‰å‚æ•°
                
                # ç›´æ¥æ‰§è¡Œ Tesseract å¹¶è·å–ç»“æœ
                tesseract_result = self._execute_tesseract_subprocess(
                    image_pil=full_image_pil,
                    tesseract_cmd_path=self.tesseract_path,
                    config_str=tesseract_configs,
                    timeout=self.config.get('tesseract_process_timeout', 300)
                )

                if tesseract_result['status'] == 'success':
                    ocr_data = tesseract_result['data']
                    full_text = tesseract_result['full_text']
                    # å°† Tesseract è¿”å›çš„å—çº§åæ ‡åº”ç”¨ç¼©æ”¾
                    for key in ['left', 'top', 'width', 'height']:
                        if key in ocr_data:
                            ocr_data[key] = [int(v * (scale_x if key in ['left', 'width'] else scale_y)) for v in ocr_data[key]]
                else:
                    raise CVOCRException(f"Tesseractåœ¨å¿«é€Ÿæ¨¡å¼ä¸‹æ‰§è¡Œå¤±è´¥: {tesseract_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            else:
                # åŸå§‹é€»è¾‘ï¼šå¯¹åˆ†å‰²å‡ºçš„åŒºåŸŸè¿›è¡Œè¯†åˆ«
                self.logger_func(f"å·¥ä½œæµæ­¥éª¤3: å°† {len(text_regions)} ä¸ªåŒºåŸŸé€å…¥è¯†åˆ«å¼•æ“è¿›è¡Œåˆæ­¥è¯†åˆ«...", "INFO")
                ocr_data, full_text = self._run_segmentation_and_recognize(
                    processed_image_np, (scale_x, scale_y), text_regions
                )

            # --- æ­¥éª¤ 5: AIåˆ†æ (ä¸ºè¯­ä¹‰åˆå¹¶å’Œæœ€ç»ˆç»“æœåšå‡†å¤‡) ---
            self.logger_func("å·¥ä½œæµæ­¥éª¤4: æ­£åœ¨æ‰§è¡ŒAIåˆ†æ...", "INFO")
            layout_info, context_info, transformer_results = None, None, None
            
            # LayoutLMv2 å¿…é¡»åœ¨è¯­ä¹‰åˆå¹¶å‰è¿è¡Œ
            if (self.config.get('enable_layout_analysis', False) or self.config.get('enable_layoutlm_merge', False)) and self.layoutlm_model:
                layout_info = self._analyze_layout_with_layoutlmv2(processed_image_np)
                self.performance_stats['component_usage']['layoutlmv2'] += 1

            if self.config.get('enable_context_analysis', False) and full_text and self.gpt_neo_model:
                full_text, context_info = self._analyze_context_with_gpt_neo(full_text, ocr_data or {})
                self.performance_stats['component_usage']['gpt_neo'] += 1

            
            
            # --- æ­¥éª¤ 6: æœ€ç»ˆç»“æœæ•´åˆ (åŒ…å«è¯­ä¹‰åˆå¹¶åˆ†æ”¯) ---
            self.logger_func("å·¥ä½œæµæ­¥éª¤5: æ­£åœ¨æ•´åˆæœ€ç»ˆç»“æœ...", "INFO")
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œé«˜çº§è¯­ä¹‰åˆå¹¶
            if (self.config.get('enable_smart_line_merge') and 
                self.config.get('enable_layoutlm_merge') and 
                layout_info and not layout_info.get('error')):
                
                # 6a. å…ˆè¿›è¡Œä¸€æ¬¡å¸¸è§„çš„åå¤„ç†ï¼Œå¾—åˆ°å¾…åˆå¹¶çš„æ–‡æœ¬å—
                initial_results = self._post_process_cvocr_results(
                    ocr_data, full_text, 
                    layout_info, context_info, transformer_results, metadata,
                    shape_blocks=shape_blocks
                )
                
                # 6b. è°ƒç”¨æ–°çš„è¯­ä¹‰åˆå¹¶æ–¹æ³•
                final_results_dict = self._merge_blocks_by_layoutlm(initial_results, layout_info)

                # æ›´æ–° full_text ä»¥åæ˜ åˆå¹¶åçš„ç»“æœ
                full_text = final_results_dict['full_text']
            else:
                # 6c. å¦‚æœä¸ä½¿ç”¨è¯­ä¹‰åˆå¹¶ï¼Œåˆ™èµ°åŸæ¥çš„å¸¸è§„åå¤„ç†æµç¨‹
                if self.config.get('enable_layoutlm_merge'):
                    self.log_message("âš ï¸ è¯·æ±‚äº†è¯­ä¹‰åˆå¹¶ï¼Œä½†LayoutLMv2æœªå¯ç”¨æˆ–åˆ†æå¤±è´¥ï¼Œå›é€€åˆ°å‡ ä½•åˆå¹¶ã€‚", "WARNING")
                
                final_results_dict = self._post_process_cvocr_results(
                    ocr_data, full_text, 
                    layout_info, context_info, transformer_results, metadata,
                    shape_blocks=shape_blocks
                )

            # --- æ­¥éª¤ 7: ç”Ÿæˆæ‘˜è¦å¹¶è¿”å› ---
            processing_time = time.time() - recognition_start_time
            self._update_success_stats(processing_time)
            summary_msg = self._generate_cvocr_result_summary(final_results_dict, processing_time, preprocess_msg)
            final_results_dict['processing_metadata']['total_processing_time'] = processing_time
            
            return final_results_dict, summary_msg

        except Exception as e:
            self._update_failed_stats()
            error_message = f"åœ¨recognize_text_enhancedä¸»æµç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}"
            self.logger_func(f"âŒ {error_message}\n{traceback.format_exc()}", "ERROR")
            return None, error_message
        finally:
            self.logger_func("è¯†åˆ«æµç¨‹ç»“æŸã€‚", "DEBUG")
    def _apply_fsrcnn_enhancement(self, image: np.ndarray) -> np.ndarray:
        """
        åº”ç”¨çœŸæ­£çš„FSRCNNè¶…åˆ†è¾¨ç‡å¢å¼º (V3.29 DBNetå…¼å®¹ä¿®æ­£ç‰ˆ)
        """
        # FSRCNNåŠŸèƒ½å·²è¢«ç§»é™¤ï¼Œæ­¤å‡½æ•°ä»…ä¸ºä¿ç•™ç»“æ„ï¼Œç›´æ¥è¿”å›åŸå›¾
        if self.config.get('enable_super_resolution', False):
             logger.warning("FSRCNNåŠŸèƒ½å·²è¢«ç§»é™¤ï¼Œè¶…åˆ†è¾¨ç‡å¢å¼ºå°†ä¸ä¼šæ‰§è¡Œã€‚")
        return image
    
    def _analyze_layout_with_layoutlmv2(self, image: np.ndarray) -> Dict:
        """ä½¿ç”¨çœŸæ­£çš„LayoutLMv2è¿›è¡Œæ–‡æ¡£å¸ƒå±€åˆ†æã€‚"""
        import torch
        from transformers import LayoutLMv2Processor, LayoutLMv2ForTokenClassification

        if not self.layoutlm_model or not self.layoutlm_processor:
            logger.warning("LayoutLMv2æ¨¡å‹æˆ–å¤„ç†å™¨æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œå¸ƒå±€åˆ†æã€‚")
            return {'error': 'LayoutLMv2æ¨¡å‹æœªåŠ è½½', 'text_regions': []}

        try:
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            
            # å‡†å¤‡æ¨¡å‹è¾“å…¥
            encoding = self.layoutlm_processor(pil_image, return_tensors="pt").to(self.device)
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = self.layoutlm_model(**encoding)
            
            # è§£æé¢„æµ‹ç»“æœ
            predictions = outputs.logits.argmax(-1).squeeze().tolist()
            token_boxes = encoding.bbox.squeeze().tolist()
            tokens = self.layoutlm_processor.tokenizer.convert_ids_to_tokens(encoding.input_ids.squeeze().tolist())
            
            text_regions = []
            for i, pred in enumerate(predictions):
                if pred == 0 or tokens[i] in ['[CLS]', '[SEP]', '[PAD]']:
                    continue

                box = token_boxes[i]
                text_regions.append({
                    'text': tokens[i],
                    'bbox': [box[0], box[1], box[2], box[3]], # x_min, y_min, x_max, y_max
                    'type_id': pred,
                    'type_name': self.layoutlm_model.config.id2label.get(pred, 'UNKNOWN'),
                    'confidence': float(torch.softmax(outputs.logits, dim=-1).squeeze()[i][pred].item())
                })
            
            aggregated_regions = self._aggregate_layoutlmv2_regions(text_regions, image.shape[1], image.shape[0])

            layout_analysis = {
                'text_regions': aggregated_regions,
                'document_structure': {
                    'estimated_language': 'mixed',
                    'text_density': 'medium'
                },
                'confidence_score': float(torch.softmax(outputs.logits, dim=-1).max().item()),
            }
            
            logger.info(f"LayoutLMv2å¸ƒå±€åˆ†æå®Œæˆï¼Œæ£€æµ‹åˆ° {len(aggregated_regions)} ä¸ªèšåˆæ–‡æœ¬åŒºåŸŸã€‚")
            return layout_analysis
        except Exception as e:
            logger.error(f"LayoutLMv2å¸ƒå±€åˆ†æå¤±è´¥: {e}\n{traceback.format_exc()}")
            return {'error': str(e), 'text_regions': []}
    
    def _aggregate_layoutlmv2_regions(self, regions: List[Dict], image_width: int, image_height: int) -> List[Dict]:
        """
        èšåˆLayoutLMv2è¾“å‡ºçš„tokençº§åŒºåŸŸï¼Œå½¢æˆæ›´ç²—ç²’åº¦çš„æ–‡æœ¬å—ã€‚
        """
        aggregated_output = []
        
        def scale_box(box):
            return [
                int(box[0] / 1000 * image_width),
                int(box[1] / 1000 * image_height),
                int(box[2] / 1000 * image_width),
                int(box[3] / 1000 * image_height)
            ]

        regions.sort(key=lambda r: (r['bbox'][1], r['bbox'][0], r['type_id']))

        current_block = None
        for region in regions:
            scaled_bbox = scale_box(region['bbox'])
            if current_block is None:
                current_block = {
                    'text': region['text'], 'bbox': scaled_bbox, 'type_name': region['type_name'],
                    'type_id': region['type_id'], 'confidence': region['confidence'], 'count': 1
                }
            else:
                overlap_threshold = 20
                if region['type_id'] == current_block['type_id'] and \
                   abs(scaled_bbox[1] - current_block['bbox'][1]) < overlap_threshold:
                    
                    current_block['text'] += " " + region['text']
                    current_block['bbox'][0] = min(current_block['bbox'][0], scaled_bbox[0])
                    current_block['bbox'][1] = min(current_block['bbox'][1], scaled_bbox[1])
                    current_block['bbox'][2] = max(current_block['bbox'][2], scaled_bbox[2])
                    current_block['bbox'][3] = max(current_block['bbox'][3], scaled_bbox[3])
                    current_block['confidence'] = (current_block['confidence'] * current_block['count'] + region['confidence']) / (current_block['count'] + 1)
                    current_block['count'] += 1
                else:
                    aggregated_output.append(current_block)
                    current_block = {
                        'text': region['text'], 'bbox': scaled_bbox, 'type_name': region['type_name'],
                        'type_id': region['type_id'], 'confidence': region['confidence'], 'count': 1
                    }
        if current_block:
            aggregated_output.append(current_block)
            
        final_regions = []
        for block in aggregated_output:
            final_regions.append({
                'bbox': [int(coord) for coord in block['bbox']],
                'text': block['text'].strip().replace(' ##', ''),
                'type': block['type_name'],
                'confidence': block['confidence']
            })
        
        return final_regions

    def _apply_transformer_ocr(self, images: Union[np.ndarray, List[np.ndarray]]) -> Union[Dict, List[Dict]]:
        """
        ã€ä¿®æ­£å’Œå¢å¼ºç‰ˆã€‘ä½¿ç”¨çœŸæ­£çš„TrOCRæ¨¡å‹è¿›è¡Œç«¯åˆ°ç«¯OCRè¯†åˆ«ã€‚
        """
        import torch
        from transformers import TrOCRProcessor, VisionEncoderDecoderModel

        if not self.trocr_model or not self.trocr_processor:
            logger.warning("TrOCRæ¨¡å‹æˆ–å¤„ç†å™¨æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡ŒTrOCRè¯†åˆ«ã€‚")
            if isinstance(images, list):
                return [{'error': 'TrOCRæ¨¡å‹æœªåŠ è½½', 'text': '', 'confidence': 0.0} for _ in images]
            else:
                return {'error': 'TrOCRæ¨¡å‹æœªåŠ è½½', 'text': '', 'confidence': 0.0}

        is_single_image = False
        if isinstance(images, np.ndarray):
            is_single_image = True
            images_list = [images]
        elif isinstance(images, list):
            images_list = images
        else:
            error_msg = f"æ— æ•ˆçš„è¾“å…¥ç±»å‹: {type(images)}"
            logger.error(error_msg)
            return {'error': error_msg, 'text': '', 'confidence': 0.0}

        if not images_list:
            return [] if not is_single_image else {'error': 'è¾“å…¥å›¾åƒä¸ºç©º', 'text': '', 'confidence': 0.0}
            
        try:
            pil_images = [Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) for img in images_list]

            pixel_values = self.trocr_processor(images=pil_images, return_tensors="pt").pixel_values.to(self.device)
            
            with torch.no_grad():
                generated_output = self.trocr_model.generate(
                    pixel_values, output_scores=True, return_dict_in_generate=True
                )
            
            generated_text_list = self.trocr_processor.batch_decode(generated_output.sequences, skip_special_tokens=True)
            
            sequence_confidences = []
            log_probs = torch.nn.functional.log_softmax(torch.stack(generated_output.scores, dim=1), dim=-1)
            
            for i in range(generated_output.sequences.shape[0]):
                sequence = generated_output.sequences[i, 1:]
                seq_len = (sequence != self.trocr_processor.tokenizer.pad_token_id).sum().item()
                if seq_len > 0:
                    token_log_probs = log_probs[i, torch.arange(seq_len), sequence[:seq_len]].sum()
                    avg_log_prob = token_log_probs / seq_len
                    confidence = torch.exp(avg_log_prob).item()
                else:
                    confidence = 0.0
                sequence_confidences.append(confidence)

            results_list = []
            model_name = self.config.get('transformer_ocr_model', 'unknown')
            for i, text in enumerate(generated_text_list):
                results_list.append({
                    'method': 'transformer_ocr',
                    'model_name': model_name,
                    'text': text,
                    'confidence': sequence_confidences[i] * 100
                })
            
            logger.info(f"TrOCRæ‰¹é‡è¯†åˆ«å®Œæˆ {len(images_list)} ä¸ªå›¾åƒã€‚")
            
            return results_list[0] if is_single_image else results_list
            
        except Exception as e:
            logger.error(f"TrOCRå¤„ç†å¤±è´¥: {e}\n{traceback.format_exc()}")
            error_result = {'error': str(e), 'text': '', 'confidence': 0.0}
            if isinstance(images, list):
                return [error_result for _ in images]
            else:
                return error_result
    
    def _analyze_context_with_gpt_neo(self, text: str, ocr_data: Dict) -> Tuple[str, Dict]:
        """ä½¿ç”¨çœŸæ­£çš„GPT-Neoè¿›è¡Œä¸Šä¸‹æ–‡åˆ†æå’Œæ–‡æœ¬ä¼˜åŒ–ã€‚"""
        import torch
        from transformers import GPT2Tokenizer, GPTNeoForCausalLM

        if not self.gpt_neo_model or not self.gpt_neo_tokenizer:
            logger.warning("GPT-Neoæ¨¡å‹æˆ–åˆ†è¯å™¨æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œä¸Šä¸‹æ–‡åˆ†æã€‚")
            return text, {'error': 'GPT-Neoæ¨¡å‹æœªåŠ è½½'}

        try:
            max_input_length = 512 - 50
            if len(text.split()) > max_input_length:
                text = " ".join(text.split()[:max_input_length])
                logger.warning(f"GPT-Neoè¾“å…¥æ–‡æœ¬è¿‡é•¿ï¼Œå·²æˆªæ–­è‡³ {max_input_length} tokenã€‚")

            prompt = (
                "The following text was extracted from an image using OCR and may contain errors. "
                "Please correct any mistakes, typos, and improve the formatting or grammar. "
                "Focus on readability and correctness. Do not add or remove significant information. "
                "Only fix the existing text.\n\n"
                f"Original OCR Text:\n---\n{text}\n---\n\n"
                "Corrected Text:"
            )

            input_ids = self.gpt_neo_tokenizer(prompt, return_tensors="pt").input_ids.to(self.device)
            
            max_new_tokens = min(200, int(len(input_ids[0]) * 0.5) + 20)
            
            with torch.no_grad():
                gen_tokens = self.gpt_neo_model.generate(
                    input_ids, do_sample=True, temperature=0.7, top_p=0.9,
                    max_new_tokens=max_new_tokens, pad_token_id=self.gpt_neo_tokenizer.eos_token_id
                )
            
            corrected_text_full = self.gpt_neo_tokenizer.decode(gen_tokens[0], skip_special_tokens=True)
            
            if "Corrected Text:" in corrected_text_full:
                optimized_text = corrected_text_full.split("Corrected Text:", 1)[1].strip()
            else:
                optimized_text = corrected_text_full.replace(prompt.split('---')[0].strip(), '').strip()
                optimized_text = optimized_text.replace(text, '').strip()
                if not optimized_text:
                    optimized_text = text
                
            corrections_applied = abs(len(text) - len(optimized_text))
            
            context_analysis = {
                'original_length': len(text),
                'optimized_length': len(optimized_text),
                'corrections_applied': corrections_applied,
                'semantic_coherence': 0.95,
                'processing_method': 'gpt-neo-125m',
                'model_confidence': 0.90
            }
            
            logger.info(f"GPT-Neoä¸Šä¸‹æ–‡åˆ†æå®Œæˆï¼Œæ–‡æœ¬é•¿åº¦ä» {len(text)} å˜ä¸º {len(optimized_text)}ï¼Œåº”ç”¨äº†çº¦ {corrections_applied} å¤„ä¿®æ­£ã€‚")
            self.performance_stats['component_usage']['gpt_neo'] += 1
            return optimized_text, context_analysis
            
        except Exception as e:
            logger.error(f"GPT-Neoä¸Šä¸‹æ–‡åˆ†æå¤±è´¥: {e}\n{traceback.format_exc()}")
            return text, {'error': str(e)}
    
    def _post_process_cvocr_results(self, data: Optional[Dict], full_text: str,
                                    layout_info: Dict = None, context_info: Dict = None, 
                                    transformer_results: Dict = None, preprocess_metadata: Dict = None,
                                    shape_blocks: List[Dict] = None) -> Dict:
        """
        CVOCRç»“æœåå¤„ç†å’Œæ•´åˆ (V3.30 å…¨å…ƒç´ æ£€æµ‹å‡çº§ç‰ˆ)ã€‚
        æ­¤æ–¹æ³•æ˜¯ç»“æœå¤„ç†çš„æ ¸å¿ƒï¼Œå®ƒå°†æ¥è‡ªä¸åŒæ¨¡å—çš„åŸå§‹æ•°æ®æ•´åˆæˆä¸€ä¸ªç»“æ„åŒ–çš„ã€
        å†…å®¹ä¸°å¯Œçš„æœ€ç»ˆç»“æœå­—å…¸ã€‚
        - æ•´åˆæ¥è‡ªTesseractæˆ–TransformerOCRçš„æ–‡æœ¬è¯†åˆ«ç»“æœã€‚
        - åˆå¹¶æ¥è‡ªUnifiedObjectDetectorçš„å›¾å½¢æ£€æµ‹ç»“æœã€‚
        - æ ¹æ®é¡µé¢ä½ç½®å¯¹æ‰€æœ‰å…ƒç´ ï¼ˆæ–‡æœ¬å’Œå›¾å½¢ï¼‰è¿›è¡Œæ’åºã€‚
        - é‡æ–°ç”ŸæˆåŒ…å«æ‰€æœ‰å…ƒç´ æ ‡ç­¾çš„å®Œæ•´æ–‡æœ¬æŠ¥å‘Šã€‚
        - è®¡ç®—æœ€ç»ˆçš„ç»Ÿè®¡æ•°æ®ï¼ˆæ€»å—æ•°ã€å­—ç¬¦æ•°ã€å¹³å‡ç½®ä¿¡åº¦ï¼‰ã€‚
        - é™„åŠ æ‰€æœ‰ç›¸å…³çš„å…ƒæ•°æ®ï¼Œå¦‚ä½¿ç”¨çš„ç»„ä»¶ã€é…ç½®å’Œé¢„å¤„ç†ä¿¡æ¯ã€‚

        Args:
            data (Optional[Dict]): æ¥è‡ªTesseractçš„åŸå§‹OCRæ•°æ®ã€‚
            full_text (str): æ¥è‡ªä¸»è¦OCRå¼•æ“çš„çº¯æ–‡æœ¬ç»“æœã€‚
            layout_info (Dict, optional): æ¥è‡ªLayoutLMv2çš„å¸ƒå±€åˆ†æç»“æœã€‚
            context_info (Dict, optional): æ¥è‡ªGPT-Neoçš„ä¸Šä¸‹æ–‡åˆ†æç»“æœã€‚
            transformer_results (Dict, optional): æ¥è‡ªTransformerOCRçš„æ•´é¡µè¯†åˆ«ç»“æœã€‚
            preprocess_metadata (Dict, optional): å›¾åƒé¢„å¤„ç†è¿‡ç¨‹çš„å…ƒæ•°æ®ã€‚
            shape_blocks (List[Dict], optional): æ£€æµ‹åˆ°çš„å›¾å½¢å…ƒç´ åˆ—è¡¨ã€‚

        Returns:
            Dict: ä¸€ä¸ªç»“æ„åŒ–çš„å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰æ•´åˆåçš„è¯†åˆ«ç»“æœå’Œå…ƒæ•°æ®ã€‚
        """
        try:
            # åˆå§‹åŒ–ä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨æ‰€æœ‰å¤„ç†è¿‡çš„æ–‡æœ¬å—
            text_blocks = []
            
            # è·å–å›¾åƒå°ºå¯¸ï¼Œç”¨äºå½“TrOCRç»“æœä½œä¸ºå”¯ä¸€ç»“æœæ—¶å¡«å……è¾¹ç•Œæ¡†
            image_w, image_h = 1000, 800 # é»˜è®¤å€¼
            if preprocess_metadata and 'final_shape' in preprocess_metadata:
                image_h, image_w = preprocess_metadata['final_shape'][:2]

            # æ£€æŸ¥TrOCRç»“æœæ˜¯å¦æœ‰æ•ˆå¹¶åº”ä½œä¸ºä¸»è¦ç»“æœ
            is_trocr_result_valid = False
            if self.config.get('enable_transformer_ocr', False) and transformer_results and 'text' in transformer_results and transformer_results['text'].strip():
                trocr_text = transformer_results['text'].strip()
                # æ£€æŸ¥ç»“æœæ˜¯å¦åŒ…å«æœ‰æ•ˆå­—ç¬¦ä¸”é•¿åº¦åˆç†
                if len(trocr_text) > 2 and re.search(r'[a-zA-Z\u4e00-\u9fa5]', trocr_text):
                    is_trocr_result_valid = True

            if is_trocr_result_valid:
                # å¦‚æœTrOCRç»“æœæœ‰æ•ˆï¼Œåˆ™å°†å…¶æ„é€ æˆä¸€ä¸ªè¦†ç›–æ•´ä¸ªå›¾åƒçš„æ–‡æœ¬å—
                self.logger_func("TrOCRç»“æœæœ‰æ•ˆï¼Œå°†å…¶æ•´åˆä¸ºå”¯ä¸€çš„è¯†åˆ«æ–‡æœ¬å—ã€‚", "INFO")
                text_blocks.append({
                    'text': transformer_results['text'], 
                    'confidence': int(transformer_results.get('confidence', 99.0)),
                    'bbox': [0, 0, image_w, image_h], 
                    'word_num': len(transformer_results['text'].split()),
                    'line_num': 1, 'par_num': 1, 'block_num': 1, 
                    'transformer_enhanced': True
                })
            
            elif data and 'text' in data and isinstance(data.get('text'), list):
                # å¦‚æœä½¿ç”¨Tesseractç­‰ä¼ ç»ŸOCRï¼Œåˆ™é€ä¸ªå¤„ç†å…¶è¿”å›çš„æ–‡æœ¬å—
                for i in range(len(data['text'])):
                    conf_str = data['conf'][i] if i < len(data['conf']) else '-1'
                    conf = int(float(conf_str)) if conf_str != '-1' else 0
                    text = data['text'][i].strip()
                    
                    # æ ¹æ®ç½®ä¿¡åº¦é˜ˆå€¼å’Œæ–‡æœ¬å†…å®¹è¿‡æ»¤æ— æ•ˆå—
                    if conf < self.config.get('confidence_threshold', 60) or not text:
                        continue
                    
                    # ç¡®ä¿è¾¹ç•Œæ¡†æ•°æ®å®Œæ•´
                    if all(k in data and i < len(data[k]) for k in ['left', 'top', 'width', 'height']):
                        bbox_coords = [
                            int(data['left'][i]), int(data['top'][i]),
                            int(data['left'][i] + data['width'][i]), int(data['top'][i] + data['height'][i])
                        ]
                    else:
                        self.logger_func(f"æ–‡æœ¬å— '{text[:20]}...' çš„è¾¹ç•Œæ¡†æ•°æ®ä¸å®Œæ•´ï¼Œå·²è·³è¿‡ã€‚", "WARNING")
                        continue

                    # æ„å»ºç»“æ„åŒ–çš„æ–‡æœ¬å—å­—å…¸
                    text_block = {
                        'text': text, 
                        'confidence': conf, 
                        'bbox': bbox_coords,
                        'word_num': int(data['word_num'][i]) if i < len(data['word_num']) else len(text.split()),
                        'line_num': int(data['line_num'][i]) if i < len(data['line_num']) else 0,
                        'par_num': int(data['par_num'][i]) if i < len(data['par_num']) else 0,
                        'block_num': int(data['block_num'][i]) if i < len(data['block_num']) else 0
                    }

                    # é™„åŠ AIå¢å¼ºä¿¡æ¯
                    if context_info: text_block['context_enhanced'] = True
                    if layout_info: text_block['layout_info'] = self._match_text_to_layout(text_block, layout_info)
                    
                    text_blocks.append(text_block)
            
            # åˆå¹¶æ£€æµ‹åˆ°çš„å›¾å½¢å—åˆ°ç»“æœåˆ—è¡¨ä¸­
            if shape_blocks:
                text_blocks.extend(shape_blocks)
            
            # æŒ‰ç…§é¡µé¢é˜…è¯»é¡ºåºï¼ˆä»ä¸Šåˆ°ä¸‹ï¼Œä»å·¦åˆ°å³ï¼‰å¯¹æ‰€æœ‰å…ƒç´ ï¼ˆæ–‡æœ¬å’Œå›¾å½¢ï¼‰è¿›è¡Œæ’åº
            text_blocks.sort(key=lambda x: (x.get('bbox', [0,0,0,0])[1], x.get('bbox', [0,0,0,0])[0]))
            
            # é‡æ–°ç”Ÿæˆå®Œæ•´çš„æ–‡æœ¬æŠ¥å‘Šï¼Œç°åœ¨å®ƒå°†åŒ…å«å›¾å½¢çš„æ ‡ç­¾
            full_text_sorted = "\n".join([block['text'] for block in text_blocks])
            
            # è®¡ç®—æœ€ç»ˆçš„ç»Ÿè®¡æ•°æ®
            total_chars = sum(len(block['text']) for block in text_blocks if not block.get('is_shape', False)) # åªç»Ÿè®¡æ–‡æœ¬å­—ç¬¦
            # åªå¯¹æ–‡æœ¬å—è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            text_only_blocks = [block for block in text_blocks if not block.get('is_shape', False)]
            avg_confidence = sum(block['confidence'] for block in text_only_blocks) / len(text_only_blocks) if text_only_blocks else 0
            
            # æ„å»ºæœ€ç»ˆçš„è¿”å›å­—å…¸
            cvocr_results = {
                'full_text': full_text_sorted.strip(), 
                'text_blocks': text_blocks,
                'total_blocks': len(text_blocks), 
                'total_characters': total_chars,
                'average_confidence': avg_confidence, 
                'language': self.language.value,
                'cvocr_components': {
                    'tesseract_used': bool(data and data.get('text')), 
                    'fsrcnn_used': False, # FSRCNNå·²ç§»é™¤
                    'layoutlmv2_used': self.config.get('enable_layout_analysis', False),
                    'gpt_neo_used': self.config.get('enable_context_analysis', False),
                    'transformer_ocr_used': is_trocr_result_valid,
                    'unified_detector_used': bool(shape_blocks) # ã€æ ¸å¿ƒä¿®æ­£ã€‘: æ­£ç¡®æ£€æŸ¥åˆ—è¡¨æ˜¯å¦ä¸ºç©º
                },
                'layout_analysis': layout_info, 
                'context_analysis': context_info,
                'transformer_results': transformer_results,
                'processing_metadata': {
                    'timestamp': datetime.now().isoformat(), 
                    'version': CVOCRConstants.VERSION,
                    'config': self.config.copy(), 
                    'preprocess_info': preprocess_metadata
                }
            }
            return cvocr_results
            
        except Exception as e:
            logger.error(f"CVOCRç»“æœåå¤„ç†å¤±è´¥: {e}", exc_info=True)
            # è¿”å›ä¸€ä¸ªåŒ…å«é”™è¯¯ä¿¡æ¯çš„ç»“æ„åŒ–å­—å…¸ï¼Œä»¥é¿å…ç¨‹åºå´©æºƒ
            return {
                'error': f"ç»“æœåå¤„ç†å¤±è´¥: {str(e)}", 
                'full_text': full_text or '',
                'text_blocks': [], 
                'total_blocks': 0, 
                'total_characters': 0,
                'average_confidence': 0,
                'processing_metadata': {
                    'timestamp': datetime.now().isoformat(), 
                    'version': CVOCRConstants.VERSION,
                    'error': True, 
                    'preprocess_info': preprocess_metadata
                }
            }
    
    def _match_text_to_layout(self, text_block: Dict, layout_info: Dict) -> Dict:
        """å°†æ–‡æœ¬å—åŒ¹é…åˆ°å¸ƒå±€ä¿¡æ¯"""
        try:
            text_bbox = text_block['bbox']
            text_regions = layout_info.get('text_regions', [])
            
            max_overlap = 0
            best_match = None
            
            for region in text_regions:
                overlap = self._calculate_bbox_overlap(text_bbox, region['bbox'])
                if overlap > max_overlap:
                    max_overlap = overlap
                    best_match = region
            
            if best_match and max_overlap > 0.3:
                return {
                    'region_type': best_match.get('type', best_match.get('type_name', 'unknown')),
                    'layout_confidence': best_match.get('confidence', 0),
                    'overlap_ratio': max_overlap
                }
            
            return {'region_type': 'unmatched', 'layout_confidence': 0, 'overlap_ratio': 0}
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬å¸ƒå±€åŒ¹é…å¤±è´¥: {e}")
            return {'region_type': 'error', 'layout_confidence': 0, 'overlap_ratio': 0}
    
    def _calculate_bbox_overlap(self, bbox1: List[int], bbox2: List[int]) -> float:
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„é‡å ç‡"""
        try:
            x1, y1, x2, y2 = bbox1
            x3, y3, x4, y4 = bbox2
            
            ix1, iy1 = max(x1, x3), max(y1, y3)
            ix2, iy2 = min(x2, x4), min(y2, y4)
            
            if ix2 <= ix1 or iy2 <= iy1: return 0.0
            
            intersection = (ix2 - ix1) * (iy2 - iy1)
            area1 = (x2 - x1) * (y2 - y1)
            area2 = (x4 - x3) * (y4 - y3)
            union = area1 + area2 - intersection
            
            return intersection / union if union > 0 else 0.0
            
        except Exception:
            return 0.0
    
    def _generate_cvocr_result_summary(self, results: Dict, processing_time: float, preprocessing_info: str) -> str:
        """ç”ŸæˆCVOCRç»“æœæ‘˜è¦"""
        if not results or not results.get('text_blocks'):
            return f"CVOCRæ–‡æœ¬è¯†åˆ«å®Œæˆä½†æœªæ‰¾åˆ°æ–‡æœ¬ (è€—æ—¶: {processing_time:.2f}ç§’)"
        
        total_blocks, total_chars, avg_confidence = results.get('total_blocks', 0), results.get('total_characters', 0), results.get('average_confidence', 0)
        
        components = results.get('cvocr_components', {})
        used_components = [comp.replace('_used', '').upper() for comp, used in components.items() if used and comp != 'fsrcnn_used']
        
        components_str = '+'.join(used_components) if used_components else 'Basic'
        
        summary = f"CVOCRè¯†åˆ«å®Œæˆ [{components_str}] (è€—æ—¶: {processing_time:.2f}s, {total_blocks}ä¸ªå—, {total_chars}ä¸ªå­—ç¬¦, å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.1f}%)"
        
        if preprocessing_info:
            summary += f", é¢„å¤„ç†: {preprocessing_info.rstrip('; ')}"
        
        return summary
    
    def _update_success_stats(self, processing_time: float):
        """æ›´æ–°æˆåŠŸç»Ÿè®¡"""
        self.performance_stats['successful_recognitions'] += 1
        self.performance_stats['recognition_times'].append(processing_time)
        self.performance_stats['average_recognition_time'] = np.mean(self.performance_stats['recognition_times'])
    
    def _update_failed_stats(self):
        """æ›´æ–°å¤±è´¥ç»Ÿè®¡"""
        self.performance_stats['failed_recognitions'] += 1
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return self.performance_stats.copy()
    
    def clear_performance_stats(self):
        """æ¸…é™¤æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats = {
            'total_recognitions': 0, 'successful_recognitions': 0, 'failed_recognitions': 0,
            'average_recognition_time': 0.0, 'recognition_times': deque(maxlen=100),
            'component_usage': defaultdict(int)
        }


class AsyncOCRProcessor:
    def __init__(self, cvocr_manager: 'EnhancedCVOCRManager', max_workers: int = 4):
        self.cvocr_manager = cvocr_manager
        # åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„çº¿ç¨‹æ± ç”¨äºæ‰§è¡Œé˜»å¡çš„ OCR ä»»åŠ¡
        # è¿™ä¸ªçº¿ç¨‹æ± ä¸ asyncio äº‹ä»¶å¾ªç¯ä¸€èµ·å·¥ä½œï¼Œè€Œä¸æ˜¯ç›´æ¥ä½œä¸º asyncio çš„executor
        self.executor = ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="AsyncOCR")
        logger.info(f"AsyncOCRProcessor initialized with ThreadPoolExecutor (max_workers={max_workers})")

    async def run_blocking_ocr_task(self, image_path: str, enable_preprocessing: bool) -> Tuple[Optional[Dict], str]:
        """
        åœ¨åå°çº¿ç¨‹æ± ä¸­å¼‚æ­¥æ‰§è¡Œé˜»å¡çš„OCRè¯†åˆ«ä»»åŠ¡ã€‚
        
        æ­¤æ–¹æ³•è¢«ä¿®æ­£ä»¥è§£å†³ 'NameError: name 'loop' is not defined' çš„é—®é¢˜ã€‚
        """
        # --- å…³é”®ä¿®æ­£ï¼šè·å–å½“å‰æ­£åœ¨è¿è¡Œçš„ asyncio äº‹ä»¶å¾ªç¯ ---
        # åŸå§‹ä»£ç ä¸­ç¼ºå°‘è¿™ä¸€è¡Œï¼Œå¯¼è‡´äº† NameErrorã€‚
        loop = asyncio.get_running_loop()
        # --- ä¿®æ­£ç»“æŸ ---

        # ç°åœ¨ 'loop' å˜é‡å·²å®šä¹‰ï¼Œå¯ä»¥å®‰å…¨åœ°ä½¿ç”¨å®ƒæ¥è°ƒåº¦ä»»åŠ¡
        return await loop.run_in_executor(
            self.executor,
            self.cvocr_manager.recognize_text_enhanced,
            image_path,
            enable_preprocessing
        )
    
    def shutdown(self):
        """å…³é—­å†…éƒ¨çš„çº¿ç¨‹æ± """
        if self.executor:
            self.executor.shutdown(wait=True)
            logger.info("AsyncOCRProcessor's ThreadPoolExecutor has been shut down.")

class TextTestImageGenerator:
    """æ–‡æœ¬æµ‹è¯•å›¾åƒç”Ÿæˆå™¨"""
    
    @staticmethod
    def create_text_test_image(filename: str = "cvocr_test_2025.jpg", 
                              include_complex_text: bool = True) -> Tuple[bool, str]:
        """åˆ›å»ºæ–‡æœ¬è¯†åˆ«æµ‹è¯•å›¾åƒ"""
        try:
            width, height = 1000, 800
            img = Image.new('RGB', (width, height), 'white')
            draw = ImageDraw.Draw(img)
            
            # åŠ è½½å­—ä½“
            font_paths = [
                "C:/Windows/Fonts/msyh.ttc",
                "C:/Windows/Fonts/simsun.ttc",
                "/System/Library/Fonts/PingFang.ttc",
                "/System/Library/Fonts/Hiragino Sans GB.ttc",
                "/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc",
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
                "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf" # Fallback for Linux
            ]
            
            fonts = {}
            for size in [14, 16, 18, 20, 24, 32]:
                fonts[size] = ImageFont.load_default() # Fallback
                for font_path in font_paths:
                    try:
                        if os.path.exists(font_path):
                            fonts[size] = ImageFont.truetype(font_path, size)
                            break
                    except (IOError, OSError):
                        continue
            
            y_pos = 50
            
            # æ ‡é¢˜
            draw.text((50, y_pos), "CVOCR å¢å¼ºç‰ˆ v3.0 æµ‹è¯•å›¾åƒ (2025)", 
                     font=fonts[32], fill='black')
            y_pos += 60
            
            # ### ä¿®æ­£ï¼šä»æŠ€æœ¯æ¶æ„æè¿°ä¸­ç§»é™¤å·²è¢«æ·˜æ±°çš„ FSRCNN ###
            draw.text((50, y_pos), "æŠ€æœ¯æ¶æ„: PP-OCRv3 + LayoutLMv2 + Tesseract + GPT-Neo + TransformerOCR", 
                     font=fonts[20], fill='darkblue')
            y_pos += 40
            
            # ä¸­æ–‡æ–‡æœ¬
            draw.text((50, y_pos), "ä¸­æ–‡æµ‹è¯•ï¼šäººå·¥æ™ºèƒ½ä¸è®¡ç®—æœºè§†è§‰æŠ€æœ¯å‘å±•è¿…é€Ÿ", 
                     font=fonts[24], fill='black')
            y_pos += 40
            
            # è‹±æ–‡æ–‡æœ¬
            draw.text((50, y_pos), "English Test: Advanced OCR with Deep Learning Integration", 
                     font=fonts[24], fill='black')
            y_pos += 40
            
            # æ•°å­—æ–‡æœ¬
            draw.text((50, y_pos), "æ•°å­—æµ‹è¯•ï¼š1234567890 (Phone: +86-138-0013-8000)", 
                     font=fonts[20], fill='black')
            y_pos += 35
            
            # æ··åˆæ–‡æœ¬
            draw.text((50, y_pos), "æ··åˆæ–‡æœ¬ï¼šCVOCR 2025å¹´ Version 3.0.0 Release", 
                     font=fonts[20], fill='black')
            y_pos += 35
            
            # å°å­—å·æ–‡æœ¬
            draw.text((50, y_pos), "å°å­—å·æ–‡æœ¬æµ‹è¯•ï¼šè¿™æ˜¯ä¸€æ®µæ¯”è¾ƒå°çš„æ–‡å­—ç”¨äºæµ‹è¯•OCRçš„è¯†åˆ«èƒ½åŠ›å’Œç²¾åº¦è¡¨ç°", 
                     font=fonts[14], fill='gray')
            y_pos += 30
            
            if include_complex_text:
                # å¤æ‚åœºæ™¯æµ‹è¯•
                y_pos += 20
                
                # ä¸åŒèƒŒæ™¯çš„æ–‡æœ¬
                # æ·±è‰²èƒŒæ™¯
                draw.rectangle([50, y_pos, 700, y_pos + 40], fill='darkblue')
                draw.text((60, y_pos + 8), "æ·±è‰²èƒŒæ™¯ç™½å­—æµ‹è¯•ï¼šCVOCRæŠ€æœ¯æ¶æ„é›†æˆ", 
                         font=fonts[20], fill='white')
                y_pos += 55
                
                # æµ…è‰²èƒŒæ™¯
                draw.rectangle([50, y_pos, 700, y_pos + 35], fill='lightgray')
                draw.text((60, y_pos + 5), "æµ…è‰²èƒŒæ™¯é»‘å­—æµ‹è¯•ï¼šå¤šæ¨¡æ€OCRèåˆ", 
                         font=fonts[20], fill='black')
                y_pos += 50
                
                # è¡¨æ ¼æ ¼å¼çš„æ–‡æœ¬
                draw.text((50, y_pos), "è¡¨æ ¼æµ‹è¯•ï¼š", font=fonts[20], fill='black')
                y_pos += 35
                
                # ä¿®æ­£å
                table_data = [
                    ["ç»„ä»¶åç§°", "ç‰ˆæœ¬", "åŠŸèƒ½", "çŠ¶æ€"],
                    ["Tesseract", "5.3+", "åŸºç¡€OCR", "âœ“"],
                    ["LayoutLMv2", "Base", "å¸ƒå±€åˆ†æ", "âœ“"],
                    ["GPT-Neo", "125M", "ä¸Šä¸‹æ–‡åˆ†æ", "âœ“"],
                    ["TransformerOCR", "Base", "ç«¯åˆ°ç«¯OCR", "âœ“"],
                    ["PP-OCRv3", "v3.0", "æ–‡æœ¬æ£€æµ‹", "âœ“"] # å¯é€‰æ·»åŠ 
                ]
                                
                cell_width = 120
                cell_height = 25
                
                for row_idx, row in enumerate(table_data):
                    for col_idx, cell in enumerate(row):
                        x = 50 + col_idx * cell_width
                        y = y_pos + row_idx * cell_height
                        
                        # ç»˜åˆ¶è¡¨æ ¼è¾¹æ¡†
                        draw.rectangle([x, y, x + cell_width - 1, y + cell_height - 1], 
                                     outline='black', width=1)
                        
                        # è¡¨å¤´èƒŒæ™¯
                        if row_idx == 0:
                            draw.rectangle([x+1, y+1, x + cell_width - 2, y + cell_height - 2], 
                                         fill='lightblue')
                        
                        # ç»˜åˆ¶æ–‡å­—
                        font_size = 16 if len(cell) <= 10 else 14
                        text_font = fonts.get(font_size, fonts[16])
                        draw.text((x + 5, y + 3), cell, font=text_font, fill='black')
                
                y_pos += len(table_data) * cell_height + 30
                
                # å¤šç§å­—ä½“æ ·å¼æµ‹è¯•
                draw.text((50, y_pos), "å­—ä½“æ ·å¼æµ‹è¯•ï¼š", font=fonts[20], fill='black')
                y_pos += 30
                
                styles = [
                    ("æ­£å¸¸æ–‡æœ¬", 'black'),
                    ("ç²—ä½“æ•ˆæœ", 'black'),
                    ("å€¾æ–œæ•ˆæœ", 'darkgreen'),
                    ("ä¸‹åˆ’çº¿æ–‡æœ¬", 'darkred')
                ]
                
                x_offset = 50
                for style_text, color in styles:
                    draw.text((x_offset, y_pos), style_text, font=fonts[18], fill=color)
                    x_offset += 150
                
                y_pos += 40
            
            # æ·»åŠ ä¸€äº›å‡ ä½•å›¾å½¢å¹²æ‰°
            draw.ellipse([750, 100, 900, 200], outline='red', width=2)
            draw.rectangle([750, 220, 900, 320], outline='green', width=2)
            draw.line([750, 340, 900, 440], fill='blue', width=3)
            
            # æ·»åŠ äºŒç»´ç æ¨¡æ‹ŸåŒºåŸŸ
            qr_size = 80
            qr_x, qr_y = 800, 500
            draw.rectangle([qr_x, qr_y, qr_x + qr_size, qr_y + qr_size], 
                         outline='black', width=2)
            for i in range(8):
                for j in range(8):
                    if (i + j) % 2 == 0:
                        cell_size = qr_size // 8
                        x1 = qr_x + i * cell_size
                        y1 = qr_y + j * cell_size
                        draw.rectangle([x1, y1, x1 + cell_size, y1 + cell_size], 
                                     fill='black')
            
            # æ·»åŠ æ—¶é—´æˆ³å’Œç‰ˆæœ¬ä¿¡æ¯
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            draw.text((50, height - 80), f"ç”Ÿæˆæ—¶é—´: {timestamp}", 
                     font=fonts[14], fill='gray')
            draw.text((50, height - 60), f"CVOCRç‰ˆæœ¬: {CVOCRConstants.VERSION}", 
                     font=fonts[14], fill='gray')
            draw.text((50, height - 40), f"ç³»ç»Ÿ: {platform.system()} {platform.release()}", 
                     font=fonts[14], fill='gray')
            draw.text((50, height - 20), "å»ºè®®ä½¿ç”¨CVOCRå¢å¼ºæ¨¡å¼è·å¾—æœ€ä½³è¯†åˆ«æ•ˆæœ", 
                     font=fonts[14], fill='darkblue')
            
            # ä¿å­˜å›¾åƒ
            img.save(filename, 'JPEG', quality=95)
            return True, f"CVOCRæµ‹è¯•å›¾åƒå·²ç”Ÿæˆ: {filename}"
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•å›¾åƒå¤±è´¥: {traceback.format_exc()}")
            return False, f"ç”Ÿæˆæµ‹è¯•å›¾åƒå¤±è´¥: {str(e)}"
class TextResultManager:
    """æ–‡æœ¬ç»“æœç®¡ç†å™¨
    è´Ÿè´£å­˜å‚¨ã€æ£€ç´¢ã€ç®¡ç†å’Œå¯¼å‡ºOCRè¯†åˆ«çš„å†å²ç»“æœã€‚
    åŒæ—¶ç»´æŠ¤ç›¸å…³çš„æ€§èƒ½å’Œä½¿ç”¨ç»Ÿè®¡æ•°æ®ã€‚
    """
    
    def __init__(self, max_history: int = 200):
        """
        åˆå§‹åŒ–TextResultManagerã€‚
        
        Args:
            max_history (int): å†å²è®°å½•æœ€å¤§ä¿å­˜æ¡æ•°ï¼Œè¶…å‡ºæ­¤æ•°é‡ä¼šç§»é™¤æœ€æ—§çš„è®°å½•ã€‚
        """
        self.max_history = max_history # æœ€å¤§å†å²è®°å½•æ¡æ•°
        self.history = [] # å­˜å‚¨å†å²è®°å½•çš„åˆ—è¡¨ï¼Œæœ€æ–°è®°å½•åœ¨åˆ—è¡¨å¤´éƒ¨
        self.current_results = None # å¯¹æœ€è¿‘ä¸€æ¬¡è¯†åˆ«ç»“æœçš„å¼•ç”¨
        self._results_cache = {} # ç”¨äºæŒ‰IDå¿«é€ŸæŸ¥æ‰¾ç»“æœçš„ç¼“å­˜å­—å…¸
        
        # ç»Ÿè®¡ä¿¡æ¯ï¼Œç”¨äºè·Ÿè¸ªOCRå¼•æ“çš„ä½¿ç”¨æƒ…å†µå’Œæ€§èƒ½
        self.stats = {
            'total_recognitions': 0, # æ€»è¯†åˆ«ä»»åŠ¡æ•°
            'total_characters_recognized': 0, # æ€»è¯†åˆ«å­—ç¬¦æ•°
            'total_processing_time': 0.0, # æ€»å¤„ç†æ—¶é—´ (ç§’)
            'average_confidence': 0.0, # å¹³å‡è¯†åˆ«ç½®ä¿¡åº¦
            'language_distribution': defaultdict(int), # è¯†åˆ«è¯­è¨€çš„åˆ†å¸ƒç»Ÿè®¡
            'component_usage_stats': defaultdict(int) # CVOCRå†…éƒ¨ç»„ä»¶ï¼ˆå¦‚Tesseract, LayoutLMv2ç­‰ï¼‰çš„ä½¿ç”¨ç»Ÿè®¡
        }
        
        logger.info(f"æ–‡æœ¬ç»“æœç®¡ç†å™¨åˆå§‹åŒ–ï¼Œæœ€å¤§å†å²è®°å½•: {max_history} æ¡ã€‚")
    
    def add_result(self, image_path: str, results: Dict, metadata: Optional[Dict] = None) -> Optional[Dict]:
        """
        æ·»åŠ æ–‡æœ¬è¯†åˆ«ç»“æœåˆ°å†å²è®°å½•ã€‚
        """
        try:
            serializable_results = self._make_results_json_serializable(results)
            
            result_entry = {
                'id': self._generate_result_id(),
                'timestamp': datetime.now().isoformat(),
                'image_path': image_path,
                'image_name': os.path.basename(image_path),
                'results': serializable_results,
                'metadata': metadata or {},
                'total_blocks': serializable_results.get('total_blocks', 0),
                'total_characters': serializable_results.get('total_characters', 0),
                'avg_confidence': serializable_results.get('average_confidence', 0),
                'full_text': serializable_results.get('full_text', ''),
                'language': serializable_results.get('language', 'unknown'),
                'cvocr_components': serializable_results.get('cvocr_components', {}),
                'processing_time': metadata.get('total_processing_time', 0) if metadata else 0
            }
            
            self.history.insert(0, result_entry)
            
            if len(self.history) > self.max_history:
                removed_entries = self.history[self.max_history:]
                self.history = self.history[:self.max_history]
                
                for entry_to_remove in removed_entries:
                    self._results_cache.pop(entry_to_remove['id'], None)
                logger.debug(f"å†å²è®°å½•è¶…å‡º {self.max_history} æ¡ï¼Œå·²ç§»é™¤ {len(removed_entries)} æ¡æœ€æ—§è®°å½•ã€‚")
            
            self.current_results = serializable_results
            
            self._update_stats(result_entry)
            
            self._results_cache[result_entry['id']] = result_entry
            
            logger.info(f"æˆåŠŸæ·»åŠ è¯†åˆ«ç»“æœåˆ°å†å²è®°å½•: {result_entry['image_name']}ã€‚")
            
            return result_entry
            
        except Exception as e:
            logger.error(f"æ·»åŠ ç»“æœåˆ°å†å²è®°å½•å¤±è´¥: {e}\n{traceback.format_exc()}")
            return None
    def _make_results_json_serializable(self, data: Union[Dict, List, Any]) -> Union[Dict, List, Any]:
        """
        é€’å½’åœ°å°†å­—å…¸ã€åˆ—è¡¨æˆ–ç›´æ¥çš„æšä¸¾å¯¹è±¡è½¬æ¢ä¸ºå¯JSONåºåˆ—åŒ–çš„å½¢å¼ã€‚
        æšä¸¾å¯¹è±¡ä¼šè¢«è½¬æ¢ä¸ºå…¶ `.value` å±æ€§ã€‚
        
        Args:
            data (Union[Dict, List, Any]): å¾…è½¬æ¢çš„æ•°æ®ã€‚
            
        Returns:
            Union[Dict, List, Any]: è½¬æ¢åçš„æ•°æ®ã€‚
        """
        if isinstance(data, Enum):
            return data.value
        elif isinstance(data, dict):
            serializable_dict = {}
            for key, value in data.items():
                serializable_dict[key] = self._make_results_json_serializable(value)
            return serializable_dict
        elif isinstance(data, list):
            serializable_list = []
            for item in data:
                serializable_list.append(self._make_results_json_serializable(item))
            return serializable_list
        else:
            return data
    
    def _generate_result_id(self) -> str:
        """
        ç”Ÿæˆä¸€ä¸ªåŸºäºå½“å‰æ—¶é—´æˆ³çš„å”¯ä¸€ç»“æœIDã€‚
        
        Returns:
            str: å”¯ä¸€çš„ç»“æœIDå­—ç¬¦ä¸²ã€‚
        """
        return f"result_{int(time.time() * 1000000)}"
    
    def _update_stats(self, result_entry: Dict):
        """
        æ ¹æ®æ–°çš„ç»“æœæ¡ç›®æ›´æ–°å†…éƒ¨çš„ç»Ÿè®¡æ•°æ®ã€‚
        
        Args:
            result_entry (Dict): æ–°æ·»åŠ çš„å†å²è®°å½•æ¡ç›®ã€‚
        """
        try:
            self.stats['total_recognitions'] += 1
            self.stats['total_characters_recognized'] += result_entry.get('total_characters', 0)
            self.stats['total_processing_time'] += result_entry.get('processing_time', 0)
            
            # é‡æ–°è®¡ç®—æ‰€æœ‰å†å²è®°å½•çš„å¹³å‡ç½®ä¿¡åº¦
            if self.stats['total_recognitions'] > 0:
                total_confidence = sum(entry.get('avg_confidence', 0) for entry in self.history)
                self.stats['average_confidence'] = total_confidence / len(self.history)
            
            # æ›´æ–°è¯­è¨€åˆ†å¸ƒç»Ÿè®¡
            language = result_entry.get('language', 'unknown')
            self.stats['language_distribution'][language] += 1
            
            # æ›´æ–°CVOCRç»„ä»¶ä½¿ç”¨ç»Ÿè®¡
            components = result_entry.get('cvocr_components', {})
            for component, used in components.items():
                if used:
                    self.stats['component_usage_stats'][component] += 1
                    
        except Exception as e:
            logger.error(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    def get_history(self, limit: Optional[int] = None, 
                   filter_func: Optional[Callable[[Dict], bool]] = None) -> List[Dict]:
        """
        è·å–å†å²è®°å½•åˆ—è¡¨ã€‚
        
        Args:
            limit (Optional[int]): å¦‚æœæä¾›ï¼Œé™åˆ¶è¿”å›çš„å†å²è®°å½•æ•°é‡ã€‚
            filter_func (Optional[Callable[[Dict], bool]]): ä¸€ä¸ªå¯é€‰çš„è¿‡æ»¤å‡½æ•°ï¼Œ
                                                               æ¥å—ä¸€ä¸ªå†å²è®°å½•æ¡ç›®å­—å…¸å¹¶è¿”å›Trueæˆ–Falseã€‚
                                                               åªæœ‰è¿”å›Trueçš„æ¡ç›®æ‰ä¼šè¢«åŒ…å«åœ¨ç»“æœä¸­ã€‚
        Returns:
            List[Dict]: ç­›é€‰å’Œé™åˆ¶åçš„å†å²è®°å½•åˆ—è¡¨ã€‚
        """
        try:
            history = self.history.copy() # è¿”å›å‰¯æœ¬ï¼Œé˜²æ­¢å¤–éƒ¨ä¿®æ”¹
            
            if filter_func:
                history = [entry for entry in history if filter_func(entry)]
            
            if limit:
                history = history[:limit]
            
            return history
            
        except Exception as e:
            logger.error(f"è·å–å†å²è®°å½•å¤±è´¥: {e}")
            return []
    
    def get_result_by_id(self, result_id: str) -> Optional[Dict]:
        """
        æ ¹æ®ç»“æœIDä»å†…éƒ¨ç¼“å­˜ä¸­è·å–å•ä¸ªå†å²è®°å½•æ¡ç›®ã€‚
        
        Args:
            result_id (str): å¾…æ£€ç´¢ç»“æœçš„å”¯ä¸€IDã€‚
            
        Returns:
            Optional[Dict]: å¯¹åº”çš„å†å²è®°å½•æ¡ç›®å­—å…¸ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›Noneã€‚
        """
        return self._results_cache.get(result_id)
    
    def search_results(self, query: str, search_in_text: bool = True, 
                      search_in_filename: bool = True) -> List[Dict]:
        """
        åœ¨å†å²è®°å½•ä¸­æœç´¢åŒ…å«ç‰¹å®šæŸ¥è¯¢å­—ç¬¦ä¸²çš„ç»“æœã€‚
        
        Args:
            query (str): æœç´¢å…³é”®è¯ã€‚
            search_in_text (bool): æ˜¯å¦åœ¨è¯†åˆ«æ–‡æœ¬å†…å®¹ä¸­æœç´¢ã€‚
            search_in_filename (bool): æ˜¯å¦åœ¨å›¾ç‰‡åç§°ä¸­æœç´¢ã€‚
            
        Returns:
            List[Dict]: åŒ¹é…æœç´¢æ¡ä»¶çš„å†å²è®°å½•åˆ—è¡¨ã€‚
        """
        try:
            results = []
            query_lower = query.lower()
            
            for entry in self.history:
                match = False
                
                if search_in_text and query_lower in entry.get('full_text', '').lower():
                    match = True
                
                if search_in_filename and query_lower in entry.get('image_name', '').lower():
                    match = True
                
                if match:
                    results.append(entry)
            
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢ç»“æœå¤±è´¥: {e}")
            return []
    
    def get_stats(self) -> Dict:
        """
        è·å–å½“å‰çš„ç»¼åˆç»Ÿè®¡ä¿¡æ¯ã€‚
        åŒ…æ‹¬æ€»è¯†åˆ«æ•°ã€æˆåŠŸç‡ã€å¹³å‡å¤„ç†æ—¶é—´ç­‰åŠ¨æ€è®¡ç®—çš„æŒ‡æ ‡ã€‚
        
        Returns:
            Dict: åŒ…å«å„ç§ç»Ÿè®¡æ•°æ®çš„å­—å…¸ã€‚
        """
        stats = self.stats.copy()
        
        if self.history:
            # è®¡ç®—æˆåŠŸç‡ï¼šæœ‰æ–‡æœ¬å—æˆ–æ²¡æœ‰é”™è¯¯ä¿¡æ¯çš„æ¡ç›®è§†ä¸ºæˆåŠŸ
            stats['success_rate'] = len([e for e in self.history if e.get('total_blocks', 0) > 0 or not e.get('results', {}).get('error')]) / len(self.history) * 100
            
            # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
            stats['average_processing_time'] = (stats['total_processing_time'] / 
                                              max(stats['total_recognitions'], 1)) # é¿å…é™¤ä»¥é›¶
            
            # ç¡®å®šæœ€å¸¸ç”¨çš„è¯†åˆ«è¯­è¨€
            if stats['language_distribution']:
                stats['most_used_language'] = max(stats['language_distribution'].items(), 
                                                key=lambda x: x[1])[0] 
            else:
                stats['most_used_language'] = 'unknown'
        else:
            # å¦‚æœæ²¡æœ‰å†å²è®°å½•ï¼Œåˆ™æ‰€æœ‰åŠ¨æ€æŒ‡æ ‡éƒ½ä¸º0æˆ–unknown
            stats['success_rate'] = 0
            stats['average_processing_time'] = 0
            stats['most_used_language'] = 'unknown'
        
        return stats
    
    def clear_history(self, confirm: bool = True) -> bool:
        """
        æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•ã€å†…éƒ¨ç¼“å­˜å’Œé‡ç½®æ‰€æœ‰ç»Ÿè®¡æ•°æ®ã€‚
        
        Args:
            confirm (bool): æ˜¯å¦åœ¨æ‰§è¡Œæ¸…ç©ºæ“ä½œå‰è¯·æ±‚ç”¨æˆ·ç¡®è®¤ (åœ¨GUIä¸­é€šå¸¸ä¼šä½¿ç”¨å¯¹è¯æ¡†)ã€‚
                            æ­¤æ–¹æ³•å†…éƒ¨çš„`confirm`å‚æ•°æ˜¯ä¸ºäº†ç»Ÿä¸€æ¥å£ï¼Œå®é™…åœ¨GUIè°ƒç”¨æ—¶ç”±GUIè´Ÿè´£è¯¢é—®ã€‚
                            è¿™é‡Œæ€»æ˜¯æ‰§è¡Œæ¸…ç©ºæ“ä½œã€‚
            
        Returns:
            bool: æ¸…ç©ºæ“ä½œæ˜¯å¦æˆåŠŸã€‚
        """
        try:
            if confirm:
                # åœ¨GUIä¸­ä¼šæ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†ï¼Œè¿™é‡Œå‡è®¾å·²ç¡®è®¤
                pass
            
            self.history.clear() # æ¸…ç©ºå†å²è®°å½•åˆ—è¡¨
            self._results_cache.clear() # æ¸…ç©ºIDç¼“å­˜
            self.current_results = None # é‡ç½®å½“å‰ç»“æœ
            
            # é‡ç½®æ‰€æœ‰ç»Ÿè®¡æ•°æ®
            self.stats = {
                'total_recognitions': 0,
                'total_characters_recognized': 0,
                'total_processing_time': 0.0,
                'average_confidence': 0.0,
                'language_distribution': defaultdict(int),
                'component_usage_stats': defaultdict(int)
            }
            
            logger.info("æ‰€æœ‰å†å²è®°å½•ã€ç¼“å­˜å’Œç»Ÿè®¡æ•°æ®å·²æ¸…ç©ºã€‚")
            return True
            
        except Exception as e:
            logger.error(f"æ¸…ç©ºå†å²è®°å½•å¤±è´¥: {e}")
            return False
    
    def export_history(self, filename: str, export_format: str = 'json') -> Tuple[bool, str]:
        """
        å¯¼å‡ºæ‰€æœ‰å†å²è®°å½•åˆ°æŒ‡å®šæ–‡ä»¶ã€‚
        
        Args:
            filename (str): å¯¼å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„å’Œåç§°ã€‚
            export_format (str): å¯¼å‡ºæ ¼å¼ï¼Œæ”¯æŒ 'json' å’Œ 'csv'ã€‚
            
        Returns:
            Tuple[bool, str]: ä¸€ä¸ªå…ƒç»„ï¼ŒæŒ‡ç¤ºå¯¼å‡ºæ˜¯å¦æˆåŠŸï¼Œä»¥åŠç›¸å…³çš„æ¶ˆæ¯ã€‚
        """
        try:
            # å‡†å¤‡å¯¼å‡ºæ•°æ®ï¼ŒåŒ…å«å¯¼å‡ºä¿¡æ¯ã€ç»Ÿè®¡å’Œå†å²è®°å½•
            export_data = {
                'export_info': {
                    'timestamp': datetime.now().isoformat(),
                    'version': CVOCRConstants.VERSION,
                    'total_records': len(self.history),
                    'export_format': export_format
                },
                'statistics': self.get_stats(),
                'history': self.history # å†å²è®°å½•ä¸­çš„æšä¸¾å€¼å·²è¢«è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¯ç›´æ¥åºåˆ—åŒ–
            }
            
            if export_format.lower() == 'json':
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
                    
            elif export_format.lower() == 'csv':
                import csv
                with open(filename, 'w', newline='', encoding='utf-8-sig') as f: # ä½¿ç”¨utf-8-sigæ”¯æŒExcel
                    writer = csv.writer(f)
                    
                    # ã€æ ¸å¿ƒä¿®æ­£1ã€‘: ä»CSVè¡¨å¤´ä¸­ç§»é™¤â€œç²¾åº¦ç­‰çº§â€
                    writer.writerow([
                        'æ—¶é—´', 'å›¾ç‰‡åç§°', 'æ–‡æœ¬å—æ•°', 'å­—ç¬¦æ•°', 'å¹³å‡ç½®ä¿¡åº¦', 
                        'è¯­è¨€', 'ä½¿ç”¨ç»„ä»¶', 'å¤„ç†æ—¶é—´', 'é”™è¯¯ä¿¡æ¯'
                    ])
                    
                    # é€è¡Œå†™å…¥å†å²è®°å½•æ•°æ®
                    for entry in self.history:
                        components = entry.get('cvocr_components', {})
                        used_components = [k for k, v in components.items() if v] # è·å–å·²ä½¿ç”¨çš„ç»„ä»¶åˆ—è¡¨
                        
                        
                        writer.writerow([
                            entry.get('timestamp', ''),
                            entry.get('image_name', ''),
                            entry.get('total_blocks', 0),
                            entry.get('total_characters', 0),
                            f"{entry.get('avg_confidence', 0):.1f}", # æ ¼å¼åŒ–ç½®ä¿¡åº¦
                            entry.get('language', ''),
                            '+'.join(used_components), # å°†ç»„ä»¶åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                            f"{entry.get('processing_time', 0):.2f}s", # æ ¼å¼åŒ–å¤„ç†æ—¶é—´
                            entry.get('results', {}).get('error', '') # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯
                        ])
                        
            else:
                return False, f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}"
            
            logger.info(f"å†å²è®°å½•å·²æˆåŠŸå¯¼å‡ºåˆ°: {filename} (æ ¼å¼: {export_format})ã€‚")
            return True, f"å†å²è®°å½•å·²å¯¼å‡º: {filename}"
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºå†å²è®°å½•å¤±è´¥: {traceback.format_exc()}")
            return False, f"å¯¼å‡ºå¤±è´¥: {str(e)}"
class Tooltip:
    """
    åˆ›å»ºä¸€ä¸ªå¯ä»¥é™„åŠ åˆ°ä»»ä½•Tkinteræ§ä»¶çš„å·¥å…·æç¤ºã€‚
    """
    def __init__(self, widget, text):
        self.widget = widget
        self.text = text
        self.tooltip_window = None
        self.widget.bind("<Enter>", self.show_tooltip)
        self.widget.bind("<Leave>", self.hide_tooltip)

    def show_tooltip(self, event=None):
        x, y, _, _ = self.widget.bbox("insert")
        x += self.widget.winfo_rootx() + 25
        y += self.widget.winfo_rooty() + 25

        self.tooltip_window = tk.Toplevel(self.widget)
        self.tooltip_window.wm_overrideredirect(True)
        self.tooltip_window.wm_geometry(f"+{x}+{y}")

        label = tk.Label(self.tooltip_window, text=self.text, justify='left',
                         background="#ffffe0", relief='solid', borderwidth=1,
                         wraplength=300,  # æç¤ºæ¡†æœ€å¤§å®½åº¦
                         font=("Arial", 10, "normal"))
        label.pack(ipadx=5, ipady=5)

    def hide_tooltip(self, event=None):
        if self.tooltip_window:
            self.tooltip_window.destroy()
        self.tooltip_window = None
class EnhancedCVOCRGUI:
    """å¢å¼ºç‰ˆCVOCR GUIä¸»ç•Œé¢"""
    
    def __init__(self, master: Optional[tk.Tk] = None):
        """
        å¢å¼ºç‰ˆCVOCR GUIä¸»ç•Œé¢çš„æ„é€ å‡½æ•° (V4.8 - æœ€ç»ˆé…ç½®ä¸çŠ¶æ€ç‰ˆ)ã€‚
        è´Ÿè´£åˆå§‹åŒ–çª—å£ã€æ‰€æœ‰åç«¯ç®¡ç†å™¨ã€GUIçŠ¶æ€å˜é‡ï¼Œå¹¶å®šä¹‰äº†æ‰€æœ‰ä¸UIæ§ä»¶ç»‘å®šçš„Tkinterå˜é‡ã€‚
        è¿™æ˜¯æ•´ä¸ªåº”ç”¨ç¨‹åºæ‰€æœ‰ç”¨æˆ·å¯é…ç½®çŠ¶æ€çš„â€œå•ä¸€äº‹å®æ¥æºâ€ã€‚
        """
        # ======================================================================
        # 1. çª—å£å’ŒåŸºç¡€è®¾ç½®
        # ======================================================================
        if master is None:
            self.root = tk.Tk()
            self._is_standalone = True
        else:
            self.root = master
            self._is_standalone = False

        self.setup_window()
        
        # ======================================================================
        # 2. åˆå§‹åŒ–åç«¯æ ¸å¿ƒç»„ä»¶
        # ======================================================================
        # ä½¿ç”¨å¢å¼ºç‰ˆç»„ä»¶ï¼Œå¹¶ä¼ å…¥self.log_messageä½œä¸ºæ—¥å¿—å›è°ƒå‡½æ•°
        self.cvocr_manager = EnhancedCVOCRManager(logger_func=self.log_message)
        self.image_processor = AdvancedTextImageProcessor()
        self.result_manager = TextResultManager()
        
        # å¼•å…¥å¼‚æ­¥ OCR å¤„ç†å™¨
        self.async_ocr_processor = AsyncOCRProcessor(self.cvocr_manager)

        # ======================================================================
        # 3. åˆå§‹åŒ–GUIçŠ¶æ€å˜é‡
        # ======================================================================
        self.current_image_path: Optional[str] = None
        self.processing = False
        self.photo = None
        self.current_image_display_id = None
        self.current_bboxes = []
        self._last_original_image_size: Optional[Tuple[int, int]] = None
        self._last_display_scale_ratio_x: float = 1.0
        self._last_display_scale_ratio_y: float = 1.0
        self._last_display_x_offset: int = 0
        self._last_display_y_offset: int = 0
        self._is_closing = False
        self._cached_preprocessed_image: Optional[np.ndarray] = None

        # ======================================================================
        # 4. è®¾ç½®çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—å’Œå¼‚æ­¥äº‹ä»¶å¾ªç¯
        # ======================================================================
        self.log_queue = queue.Queue()
        self.loop = None
        self._loop_ready_event = threading.Event()

        # ======================================================================
        # 5. å®šä¹‰æ‰€æœ‰Tkinterå˜é‡ä»¥ç»‘å®šGUIæ§ä»¶
        # ======================================================================
        self.settings = {
            # --- OCRä¸æ£€æµ‹æ ¸å¿ƒé…ç½® ---
            
            'language': tk.StringVar(value='auto'),
            'tesseract_path': tk.StringVar(value=''),
            'confidence_threshold': tk.DoubleVar(value=CVOCRConstants.DEFAULT_CONFIDENCE_THRESHOLD),
            'psm_mode': tk.StringVar(value='6: å‡è®¾ä¸ºå•ä¸ªç»Ÿä¸€çš„æ–‡æœ¬å—'),
            'enable_advanced_segmentation': tk.BooleanVar(value=False),
            'ppocr_model': tk.StringVar(value='text_detection_cn_ppocrv3_2023may.onnx'),
            'yolo_weights_path': tk.StringVar(value='yolov4-tiny.weights'),
            'yolo_cfg_path': tk.StringVar(value='yolov4-tiny.cfg'),
            'yolo_names_path': tk.StringVar(value='coco.names'),
            
            # --- AIç»„ä»¶é…ç½® ---
            'enable_layout_analysis': tk.BooleanVar(value=False),
            'layoutlm_model': tk.StringVar(value='microsoft/layoutlmv2-base-uncased'),
            'enable_context_analysis': tk.BooleanVar(value=False),
            'gpt_neo_model': tk.StringVar(value='EleutherAI/gpt-neo-125M'),
            'enable_transformer_ocr': tk.BooleanVar(value=False),
            'transformer_ocr_model': tk.StringVar(value='microsoft/trocr-base-printed'),
            
            # --- æ–‡æœ¬å—è¯†åˆ«å¼•æ“ ---
            'segmentation_recognizer': tk.StringVar(value='Tesseract'),
            'enable_tesseract_fine_tuning': tk.BooleanVar(value=True),
            
            # --- é«˜çº§æ–‡æœ¬åˆ†å‰²æŠ€æœ¯ ---
            'seg_simple_high_contrast': tk.BooleanVar(value=True),
            'seg_improved_mser': tk.BooleanVar(value=True),
            'seg_multiscale_contour': tk.BooleanVar(value=True),
            'seg_gradient_based': tk.BooleanVar(value=False),
            'seg_multilevel_mser': tk.BooleanVar(value=False),
            'seg_stroke_width_transform': tk.BooleanVar(value=False),
            'seg_connected_components': tk.BooleanVar(value=False),
            'seg_character_level': tk.BooleanVar(value=False),
            'enable_smart_line_merge': tk.BooleanVar(value=True),
            'enable_layoutlm_merge': tk.BooleanVar(value=False),
            
            # --- å›¾åƒé¢„å¤„ç†æ€»å¼€å…³ ---
            'enable_preprocessing': tk.BooleanVar(value=True),
            
            # --- æ ¸å¿ƒè½¬æ¢æ­¥éª¤ ---
            'enable_grayscale': tk.BooleanVar(value=True),
            'enable_binarization': tk.BooleanVar(value=True),
            'adaptive_block_size': tk.IntVar(value=11), 
            'adaptive_c_constant': tk.IntVar(value=2), 
            
            # --- å‡ ä½•æ ¡æ­£ ---
            'enable_deskew': tk.BooleanVar(value=True),
            'deskew_angle_threshold': tk.DoubleVar(value=0.5),
            'remove_borders': tk.BooleanVar(value=True),
            'border_threshold': tk.IntVar(value=10),
            'crop_to_content': tk.BooleanVar(value=True),
            'page_border_detection': tk.BooleanVar(value=True),
            
            # --- å›¾åƒå¢å¼ºä¸é™å™ª ---
            'shadow_removal': tk.BooleanVar(value=True),
            'bilateral_filter': tk.BooleanVar(value=True), 
            'bilateral_d': tk.IntVar(value=9),
            'bilateral_sigma_color': tk.DoubleVar(value=75.0),
            'bilateral_sigma_space': tk.DoubleVar(value=75.0),
            'histogram_equalization': tk.BooleanVar(value=True),
            'apply_clahe': tk.BooleanVar(value=True), 
            'clahe_clip_limit': tk.DoubleVar(value=2.0),
            'clahe_tile_grid_size_x': tk.IntVar(value=8), 
            'clahe_tile_grid_size_y': tk.IntVar(value=8), 
            'unsharp_mask': tk.BooleanVar(value=True),
            'unsharp_radius': tk.DoubleVar(value=1.0),
            'unsharp_amount': tk.DoubleVar(value=1.0),
            
            # --- æ˜¾ç¤ºä¸ä¿å­˜ ---
            'save_results': tk.BooleanVar(value=True),
            'show_confidence': tk.BooleanVar(value=True),
            'auto_save_results': tk.BooleanVar(value=True),
            
            # --- æ€§èƒ½ ---
            'use_gpu': tk.BooleanVar(value=False),
            'batch_processing': tk.BooleanVar(value=False)
        }
        
        # ======================================================================
        # 6. åˆ›å»ºGUIç•Œé¢
        # ======================================================================
        self.create_widgets()
        self.create_status_bar()
        
        # ======================================================================
        # 7. å¯åŠ¨å’Œåˆå§‹åŒ–æµç¨‹
        # ======================================================================
        self.log_message("ğŸš€ CVOCRå¢å¼ºç‰ˆv3.0å¯åŠ¨æˆåŠŸ", 'INFO')
        self.log_message("âœ¨ æ–°åŠŸèƒ½ï¼šå¤šè¯­è¨€è¯†åˆ«ã€é«˜çº§é¢„å¤„ç†ã€æ™ºèƒ½æ–‡æœ¬åˆ†æ", 'INFO')
        self.log_message("ğŸ”§ CVOCRæŠ€æœ¯æ¶æ„ï¼šPP-OCRv3 + LayoutLMv2 + Tesseract + GPT-Neo + Transformer OCR", 'INFO')
        
        self._load_settings()

        self._start_async_loop_in_thread()
        
        self._loop_ready_event.wait()

        self.loop.call_soon_threadsafe(self.loop.create_task, self._process_queues())
        self.loop.call_soon_threadsafe(self.loop.create_task, self._trigger_initial_system_check_async())

        for key, var in self.settings.items():
            if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar)):
                logger.debug(f"DEBUG: Setting '{key}' initial value: {var.get()}")
        
        try:
            self.add_debug_monitoring()
        except Exception as e:
            logger.warning(f"å¯åŠ¨è°ƒè¯•ç›‘æ§å¤±è´¥: {e}")
    def _start_async_loop_in_thread(self):
        """åœ¨ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹ä¸­å¯åŠ¨ asyncio äº‹ä»¶å¾ªç¯"""
        def run_loop():
            # ä¸ºè¿™ä¸ªæ–°çº¿ç¨‹åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ asyncio äº‹ä»¶å¾ªç¯
            self.loop = asyncio.new_event_loop()
            # å°†è¿™ä¸ªæ–°åˆ›å»ºçš„å¾ªç¯è®¾ç½®ä¸ºå½“å‰çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯
            asyncio.set_event_loop(self.loop)
            
            # --- ä¿®æ­£: å¾ªç¯åˆ›å»ºåè®¾ç½®äº‹ä»¶ï¼Œé€šçŸ¥ä¸»çº¿ç¨‹ loop å·²å°±ç»ª ---
            # è¿™æ˜¯å…³é”®çš„åŒæ­¥æ­¥éª¤ã€‚ä¸€æ—¦ self.loop è¢«èµ‹å€¼ï¼Œå°±ç«‹å³è®¾ç½®äº‹ä»¶ã€‚
            # è¿™å°†é‡Šæ”¾ä¸»çº¿ç¨‹ä¸­æ­£åœ¨ç­‰å¾…çš„ .wait() è°ƒç”¨ï¼Œä½¿å…¶å¯ä»¥å®‰å…¨åœ°ä½¿ç”¨ self.loopã€‚
            self._loop_ready_event.set()
            
            # å¯åŠ¨äº‹ä»¶å¾ªç¯ï¼Œå®ƒå°†ä¸€ç›´è¿è¡Œï¼Œç›´åˆ°è¢«æ˜¾å¼åœæ­¢ï¼ˆä¾‹å¦‚åœ¨ on_closing æ–¹æ³•ä¸­ï¼‰
            try:
                self.loop.run_forever()
            finally:
                # å½“å¾ªç¯ç»“æŸæ—¶ï¼ˆé€šå¸¸åœ¨ç¨‹åºé€€å‡ºæ—¶ï¼‰ï¼Œç¡®ä¿å®ƒè¢«æ­£ç¡®å…³é—­
                # è·å–æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å¹¶å–æ¶ˆå®ƒä»¬
                tasks = asyncio.all_tasks(loop=self.loop)
                for task in tasks:
                    task.cancel()
                
                # æ”¶é›†æ‰€æœ‰ä»»åŠ¡çš„å–æ¶ˆç»“æœ
                async def gather_tasks():
                    await asyncio.gather(*tasks, return_exceptions=True)

                # åœ¨å¾ªç¯ä¸­è¿è¡Œä»»åŠ¡æ”¶é›†ï¼Œç›´åˆ°å®Œæˆ
                self.loop.run_until_complete(gather_tasks())
                self.loop.close()
                logger.info("Asyncio event loop has been properly shut down.")

        # åˆ›å»ºä¸€ä¸ªæ–°çš„å®ˆæŠ¤çº¿ç¨‹æ¥è¿è¡Œ run_loop å‡½æ•°ã€‚
        # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹ (daemon=True) æ„å‘³ç€å¦‚æœä¸»ç¨‹åºé€€å‡ºï¼Œè¿™ä¸ªçº¿ç¨‹ä¹Ÿä¼šè¢«å¼ºåˆ¶ç»ˆæ­¢ã€‚
        self.async_loop_thread = threading.Thread(target=run_loop, daemon=True, name="AsyncioEventLoopThread")
        
        # å¯åŠ¨åå°çº¿ç¨‹
        self.async_loop_thread.start()
        
        # è®°å½•æ—¥å¿—ï¼Œè¡¨ç¤ºåå°å¾ªç¯çº¿ç¨‹å·²å¯åŠ¨
        logger.info("Asyncio event loop started in a separate thread.")

    
    def setup_window(self):
        """è®¾ç½®çª—å£"""
        # ### ä¿®æ­£ï¼šä»çª—å£æ ‡é¢˜ä¸­ç§»é™¤å·²è¢«æ·˜æ±°çš„ FSRCNN ###
        self.root.title(f"CVOCRå¢å¼ºç‰ˆv{CVOCRConstants.VERSION} - é«˜ç²¾åº¦æ–‡æœ¬è¯†åˆ« (PP-OCRv3+LayoutLMv2+Tesseract+GPT-Neo+TransformerOCR)  ä½œè€…ï¼šè·³èˆçš„ç«å…¬å­")
        self.root.geometry("1800x1200")
        self.root.minsize(1600, 1000)
        
        # è®¾ç½®æ ·å¼
        self.style_manager = ttk.Style()
        design.configure_ttk_styles(self.style_manager)
        
        self.root.configure(bg=design.get_color('neutral', '50'))

        if self._is_standalone:
            self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        
        # è®¾ç½®å›¾æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            if os.path.exists('cvocr_icon.ico'):
                self.root.iconbitmap('cvocr_icon.ico')
        except Exception:
            pass
    
    def create_widgets(self):
        """åˆ›å»ºä¸»è¦æ§ä»¶"""
        main_frame = tk.Frame(self.root, bg=design.get_color('neutral', '50'))
        main_frame.pack(fill='both', expand=True, 
                        padx=design.get_spacing('4'), 
                        pady=design.get_spacing('3'))
        
        # å·¦ä¾§æ§åˆ¶é¢æ¿
        self.create_enhanced_control_panel(main_frame)
        
        # å³ä¾§æ˜¾ç¤ºåŒºåŸŸ
        self.create_display_area(main_frame)
    def _create_segmentation_techniques_section(self):
        """
        åˆ›å»ºé«˜çº§æ–‡æœ¬åˆ†å‰²æŠ€æœ¯é€‰æ‹©åŒº (V2 - LayoutLMv2é›†æˆç‰ˆ)
        - åœ¨â€œæ™ºèƒ½è¡Œåˆå¹¶â€ä¸‹å¢åŠ â€œä½¿ç”¨LayoutLMv2è¿›è¡Œè¯­ä¹‰åˆå¹¶â€çš„å­é€‰é¡¹ï¼Œ
          ä¸ºç”¨æˆ·æä¾›å‡ ä½•åˆå¹¶ä¸è¯­ä¹‰åˆå¹¶ä¸¤ç§æ¨¡å¼çš„é€‰æ‹©ã€‚
        - å¢å¼ºäº†Tooltipæç¤ºï¼Œä»¥æ¸…æ™°åœ°è§£é‡Šæ¯ä¸ªé€‰é¡¹çš„åŠŸèƒ½å’Œé€‚ç”¨åœºæ™¯ã€‚
        """
        # --- ä¸»å®¹å™¨ ---
        seg_frame = ttk.LabelFrame(self.inner_control_frame, text="é«˜çº§æ–‡æœ¬åˆ†å‰²æŠ€æœ¯", padding=design.get_spacing('3'))
        seg_frame.pack(fill='x', pady=(0, design.get_spacing('4')))
        
        # --- åŠŸèƒ½æè¿°æ ‡ç­¾ ---
        desc_label = ttk.Label(seg_frame, text="è‡ªç”±ç»„åˆæ£€æµ‹ç®—æ³•ä»¥é€‚åº”ä¸åŒå›¾åƒã€‚é€‰æ‹©å¼•æ“ç²¾åº¦é¢„è®¾å¯è‡ªåŠ¨é…ç½®ã€‚", 
                               font=design.get_font('xs'), foreground='gray', wraplength=380, justify='left')
        desc_label.pack(anchor='w', pady=(0, design.get_spacing('2')))

        # --- å®šä¹‰æ‰€æœ‰å¯ç”¨çš„åˆ†å‰²æŠ€æœ¯åŠå…¶æè¿° ---
        techniques = [
            ('seg_simple_high_contrast', 'é«˜å¯¹æ¯”åº¦è½®å»“ (å¿«, é€‚ç”¨äºæ¸…æ™°æ–‡æ¡£)'),
            ('seg_improved_mser', 'æ”¹è¿›MSER (é€šç”¨, é²æ£’)'),
            ('seg_multiscale_contour', 'å¤šå°ºåº¦è½®å»“ (é€‚åˆå¤šå°ºå¯¸æ–‡æœ¬)'),
            ('seg_gradient_based', 'æ¢¯åº¦æ£€æµ‹ (é€‚åˆè¾¹ç¼˜æ¨¡ç³Šæ–‡æœ¬)'),
            ('seg_multilevel_mser', 'å¤šçº§MSER (æç²¾ç¡®, è€—æ—¶)'),
            ('seg_stroke_width_transform', 'ç¬”ç”»å®½åº¦å˜æ¢ (SWT, å¤æ‚åœºæ™¯)'),
            ('seg_connected_components', 'è¿é€šåˆ†é‡åˆ†æ (å­—ç¬¦çº§, ç²¾ç»†)'),
            ('seg_character_level', 'å­—ç¬¦çº§åˆ†å‰² (å®éªŒæ€§, è€—æ—¶)')
        ]

        # --- å¾ªç¯åˆ›å»ºæŠ€æœ¯é€‰æ‹©çš„å¤é€‰æ¡† ---
        for var_name, text in techniques:
            ttk.Checkbutton(seg_frame, text=text,
                            variable=self.settings[var_name], style='TCheckbutton').pack(anchor='w')

        # --- åˆ†éš”çº¿ ---
        ttk.Separator(seg_frame, orient='horizontal').pack(fill='x', pady=design.get_spacing('2'), padx=design.get_spacing('1'))
        
        # --- æ™ºèƒ½è¡Œåˆå¹¶æ§åˆ¶åŒºåŸŸ ---
        merge_control_frame = ttk.Frame(seg_frame)
        merge_control_frame.pack(fill='x', pady=(design.get_spacing('1'), 0))

        # â€œå¯ç”¨æ™ºèƒ½è¡Œåˆå¹¶â€ ä¸»å¼€å…³
        merge_check = ttk.Checkbutton(merge_control_frame, text="å¯ç”¨æ™ºèƒ½è¡Œåˆå¹¶",
                                      variable=self.settings['enable_smart_line_merge'])
        merge_check.pack(side='left', anchor='w')
        Tooltip(merge_check, "å°†æ£€æµ‹åˆ°çš„ç›¸é‚»å°æ–‡æœ¬å—åˆå¹¶æˆæ›´å®Œæ•´çš„é€»è¾‘å•å…ƒï¼ˆè¡Œã€æ®µè½ç­‰ï¼‰ã€‚\nè¿™æ˜¯æ‰€æœ‰åˆå¹¶åŠŸèƒ½çš„ä¸»å¼€å…³ã€‚")
        
        # â€œé¢„è§ˆåˆå¹¶æ•ˆæœâ€ æŒ‰é’®
        btn_preview_merge = tk.Button(merge_control_frame, text="ğŸ”¬ é¢„è§ˆåˆå¹¶æ•ˆæœ", command=self.preview_merge_effect)
        design.apply_button_style(btn_preview_merge, 'secondary')
        btn_preview_merge.pack(side='left', padx=(design.get_spacing('2'), 0))
        Tooltip(btn_preview_merge, "é¢„è§ˆå¯ç”¨æ­¤åŠŸèƒ½å‰åçš„åˆ†å‰²æ¡†å¯¹æ¯”æ•ˆæœã€‚")

        # --- æ–°å¢ï¼šLayoutLMv2 è¯­ä¹‰åˆå¹¶é€‰é¡¹ ---
        # ä½¿ç”¨ä¸€ä¸ªæ–°çš„æ¡†æ¶å¹¶è¿›è¡Œç¼©è¿›ï¼Œä»¥åœ¨è§†è§‰ä¸Šè¡¨ç¤ºå±‚çº§å…³ç³»
        layoutlm_merge_frame = ttk.Frame(seg_frame)
        layoutlm_merge_frame.pack(fill='x', padx=(20, 0))

        # â€œä½¿ç”¨LayoutLMv2è¿›è¡Œè¯­ä¹‰åˆå¹¶â€ å­é€‰é¡¹
        layoutlm_merge_check = ttk.Checkbutton(layoutlm_merge_frame, text="ğŸ§  ä½¿ç”¨LayoutLMv2è¿›è¡Œè¯­ä¹‰åˆå¹¶ (ç²¾åº¦æœ€é«˜)",
                                               variable=self.settings['enable_layoutlm_merge'])
        layoutlm_merge_check.pack(anchor='w')
        Tooltip(layoutlm_merge_check, ("éœ€è¦å·²åˆå§‹åŒ–LayoutLMv2æ¨¡å‹ã€‚\n"
                                       "å¯ç”¨åï¼Œå°†ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹åˆ†ææ–‡æ¡£ç»“æ„ï¼ˆæ®µè½ã€åˆ—è¡¨ã€è¡¨æ ¼ï¼‰ï¼Œ"
                                       "å®ç°æœ€æ™ºèƒ½çš„åˆå¹¶ï¼Œèƒ½å¤„ç†å¤šæ ã€å›¾æ–‡æ··æ’ç­‰å¤æ‚å¸ƒå±€ã€‚\n"
                                       "ã€æ³¨æ„ã€‘ä¼šæ˜¾è‘—å¢åŠ å¤„ç†æ—¶é—´ï¼"))
    def create_enhanced_control_panel(self, parent):
        """åˆ›å»ºå¢å¼ºæ§åˆ¶é¢æ¿"""
        # åˆ›å»ºå¤–å±‚å®¹å™¨
        outer_control_frame = ttk.LabelFrame(parent, text="CVOCRå¢å¼ºæ§åˆ¶é¢æ¿", 
                                                padding=design.get_spacing('1'))
        outer_control_frame.pack(side='left', fill='y', padx=(0, design.get_spacing('4')))

        # åˆ›å»ºæ»šåŠ¨ç”»å¸ƒ
        self.control_canvas = tk.Canvas(outer_control_frame, 
                                        bg=design.get_color('neutral', '50'), 
                                        highlightthickness=0,
                                        width=400)  # è®¾ç½®å›ºå®šå®½åº¦
        self.control_canvas.pack(side='left', fill='both', expand=True)

        # åˆ›å»ºæ»šåŠ¨æ¡
        control_scrollbar = ttk.Scrollbar(outer_control_frame, 
                                            orient='vertical', 
                                            command=self.control_canvas.yview)
        control_scrollbar.pack(side='right', fill='y')

        self.control_canvas.configure(yscrollcommand=control_scrollbar.set)
        self.control_canvas.bind_all("<MouseWheel>", self._on_mousewheel)

        # åˆ›å»ºå†…éƒ¨æ¡†æ¶
        self.inner_control_frame = ttk.Frame(self.control_canvas, 
                                                padding=design.get_spacing('3'))
        
        self.control_canvas_window = self.control_canvas.create_window(
            (0, 0), window=self.inner_control_frame, anchor="nw", tags="inner_frame")

        self.inner_control_frame.bind("<Configure>", self._on_inner_control_frame_configure)
        self.control_canvas.bind("<Configure>", self._on_control_canvas_configure)

        # ç³»ç»ŸçŠ¶æ€åŒº
        self._create_system_status_section()
        
        # CVOCRç»„ä»¶é…ç½®åŒº
        self._create_cvocr_components_section()
        
        # OCRé…ç½®åŒº
        self._create_ocr_configuration_section()

        # --- æ–°å¢è°ƒç”¨ ---
        self._create_segmentation_techniques_section()
        
        # å›¾åƒæ“ä½œåŒº
        self._create_image_operations_section()
        
        # æ–‡æœ¬è¯†åˆ«æ“ä½œåŒº
        self._create_recognition_operations_section()
        
        # é«˜çº§è®¾ç½®åŒº
        self._create_advanced_settings_section()
        
        # ç»“æœæ“ä½œåŒº
        self._create_result_operations_section()
        
        # æ—¥å¿—åŒºåŸŸ
        self._create_log_section()
    
    def _create_system_status_section(self):
        """åˆ›å»ºç³»ç»ŸçŠ¶æ€åŒº"""
        status_frame = ttk.LabelFrame(self.inner_control_frame, text="ç³»ç»ŸçŠ¶æ€", padding=design.get_spacing('3'))
        status_frame.pack(fill='x', pady=(0, design.get_spacing('4')))
        
        self.status_label = ttk.Label(status_frame, text="ç³»ç»Ÿæœªåˆå§‹åŒ–", style='Warning.TLabel')
        self.status_label.pack(pady=design.get_spacing('1'))
        
        # ç³»ç»Ÿæ£€æŸ¥æŒ‰é’®
        btn_system_check = tk.Button(status_frame, text="ğŸ” ç³»ç»Ÿæ£€æŸ¥", command=self.check_system)
        design.apply_button_style(btn_system_check, 'secondary')
        btn_system_check.pack(fill='x', pady=design.get_spacing('1'))

        # åˆå§‹åŒ–CVOCRæŒ‰é’®
        btn_init_cvocr = tk.Button(status_frame, text="ğŸš€ åˆå§‹åŒ–CVOCR", command=self.initialize_cvocr)
        design.apply_button_style(btn_init_cvocr, 'primary')
        btn_init_cvocr.pack(fill='x', pady=design.get_spacing('1'))
        
        # ç‰ˆæœ¬ä¿¡æ¯æ˜¾ç¤º
        version_label = ttk.Label(status_frame, text=f"CVOCR v{CVOCRConstants.VERSION}", 
                                 style='TLabel')
        version_label.pack(pady=design.get_spacing('1'))
    
    def _create_cvocr_components_section(self):
        """
        åˆ›å»ºCVOCRç»„ä»¶é…ç½®åŒº (V3.30 - ç»Ÿä¸€æ¨¡å‹é€‰æ‹©ä¸çŠ¶æ€åé¦ˆç‰ˆ)
        - ä¸ºæ‰€æœ‰ä¸»è¦çš„AIç»„ä»¶ï¼ˆLayoutLMv2, GPT-Neo, Transformer OCRï¼‰æä¾›ç»Ÿä¸€çš„é…ç½®UIã€‚
        - æ¯ä¸ªç»„ä»¶éƒ½åŒ…å«ï¼šå¯ç”¨å¼€å…³ã€åŠŸèƒ½æè¿°ã€æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†å’ŒçŠ¶æ€åé¦ˆæ ‡ç­¾ã€‚
        - æ¨¡å‹åˆ—è¡¨å¯ä»¥ä»å¤–éƒ¨é…ç½®æ–‡ä»¶åŠ è½½ï¼Œå¢åŠ äº†çµæ´»æ€§ï¼ˆæ­¤å¤„ä¸ºç®€åŒ–ï¼Œä»ç¡¬ç¼–ç ï¼‰ã€‚
        """
        components_frame = ttk.LabelFrame(self.inner_control_frame, text="CVOCRç»„ä»¶é…ç½®", padding=design.get_spacing('3'))
        components_frame.pack(fill='x', pady=(0, design.get_spacing('4')))

        # --- ç»Ÿä¸€çš„ç»„ä»¶åˆ›å»ºå‡½æ•°ï¼Œä»¥å‡å°‘ä»£ç é‡å¤ ---
        def create_component_widget(parent, check_var_name, check_text, desc_text,
                                    model_var_name, model_list, tooltip_text):
            
            # ä¸»æ¡†æ¶
            frame = ttk.Frame(parent)
            frame.pack(fill='x', pady=design.get_spacing('2'))

            # å¯ç”¨å¤é€‰æ¡†å’Œæè¿°
            check_frame = ttk.Frame(frame)
            check_frame.pack(fill='x')
            checkbutton = ttk.Checkbutton(check_frame, text=check_text,
                                          variable=self.settings[check_var_name],
                                          style='TCheckbutton')
            checkbutton.pack(anchor='w')
            Tooltip(checkbutton, tooltip_text) # ä¸ºå¤é€‰æ¡†æ·»åŠ æç¤º

            desc_label = ttk.Label(check_frame, text=desc_text,
                                   font=design.get_font('xs'), foreground='gray')
            desc_label.pack(anchor='w', padx=(20, 0)) # ç¼©è¿›

            # æ¨¡å‹é€‰æ‹©å’ŒçŠ¶æ€åé¦ˆ
            model_frame = ttk.Frame(frame)
            model_frame.pack(fill='x', pady=(design.get_spacing('1'), 0), padx=(20, 0)) # ç¼©è¿›

            tk.Label(model_frame, text="æ¨¡å‹é€‰æ‹©:", bg=design.get_color('neutral', '50')).pack(side='left', padx=(0, design.get_spacing('2')))
            
            model_combo = ttk.Combobox(model_frame,
                                       textvariable=self.settings[model_var_name],
                                       values=model_list,
                                       width=30,
                                       state='readonly')
            model_combo.pack(side='left', fill='x', expand=True)

            # åˆ›å»ºå¹¶å­˜å‚¨çŠ¶æ€æ ‡ç­¾ï¼Œä»¥ä¾¿åç»­æ›´æ–°
            status_label = ttk.Label(model_frame, text="(æœªåˆå§‹åŒ–)", foreground="gray", font=design.get_font('xs'))
            status_label.pack(side='left', padx=(design.get_spacing('2'), 0))
            
            return status_label # è¿”å›çŠ¶æ€æ ‡ç­¾çš„å¼•ç”¨

        # --- 1. LayoutLMv2 å¸ƒå±€åˆ†æ ---
        layoutlm_models = [
            'microsoft/layoutlmv2-base-uncased',
            'microsoft/layoutlmv2-large-uncased' # æä¾›å¤§æ¨¡å‹é€‰é¡¹
        ]
        self.layoutlm_status_label = create_component_widget(
            components_frame,
            check_var_name='enable_layout_analysis',
            check_text="ğŸ“„ å¯ç”¨LayoutLMv2å¸ƒå±€åˆ†æ",
            desc_text="ç†è§£æ–‡æ¡£ç»“æ„ï¼Œæå‡è¡¨æ ¼ã€åˆ—è¡¨ç­‰å¤æ‚ç‰ˆé¢è¯†åˆ«",
            model_var_name='layoutlm_model', # æ–°å¢ä¸€ä¸ªè®¾ç½®å˜é‡
            model_list=layoutlm_models,
            tooltip_text="åˆ†æé¡µé¢å…ƒç´ çš„ç±»å‹ï¼ˆå¦‚æ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ï¼‰ï¼Œä¸ºç»“æ„åŒ–è¾“å‡ºæä¾›ä¾æ®ã€‚"
        )
        # ä¸ºæ–°çš„è®¾ç½®å˜é‡åˆå§‹åŒ–
        if 'layoutlm_model' not in self.settings:
            self.settings['layoutlm_model'] = tk.StringVar(value=layoutlm_models[0])

        # --- 2. GPT-Neo ä¸Šä¸‹æ–‡åˆ†æ ---
        gpt_neo_models = [
            'EleutherAI/gpt-neo-125M',
            'EleutherAI/gpt-neo-1.3B' # æä¾›æ›´å¤§ã€æ›´å¼ºçš„æ¨¡å‹é€‰é¡¹
        ]
        self.gpt_neo_status_label = create_component_widget(
            components_frame,
            check_var_name='enable_context_analysis',
            check_text="ğŸ§  å¯ç”¨GPT-Neoä¸Šä¸‹æ–‡åˆ†æ",
            desc_text="æ™ºèƒ½æ–‡æœ¬çº é”™ï¼Œä¼˜åŒ–è¯­æ³•å’Œæ ¼å¼ï¼Œæå‡è¯†åˆ«å‡†ç¡®åº¦",
            model_var_name='gpt_neo_model', # æ–°å¢ä¸€ä¸ªè®¾ç½®å˜é‡
            model_list=gpt_neo_models,
            tooltip_text="åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å¯¹OCRåˆæ­¥ç»“æœè¿›è¡Œåå¤„ç†ï¼Œä¿®æ­£å¸¸è§çš„è¯†åˆ«é”™è¯¯ã€‚"
        )
        # ä¸ºæ–°çš„è®¾ç½®å˜é‡åˆå§‹åŒ–
        if 'gpt_neo_model' not in self.settings:
            self.settings['gpt_neo_model'] = tk.StringVar(value=gpt_neo_models[0])

        # --- 3. Transformer OCR (æ•´é¡µæ¨¡å¼) ---
        trocr_models = [
            'microsoft/trocr-base-printed',
            'microsoft/trocr-base-handwritten',
            'microsoft/trocr-small-printed',
            'microsoft/trocr-large-printed', # æä¾›å¤§æ¨¡å‹é€‰é¡¹
            'google/trocr-base-zh-printed'
        ]
        self.trocr_status_label = create_component_widget(
            components_frame,
            check_var_name='enable_transformer_ocr',
            check_text="ğŸ¤– å¯ç”¨Transformer OCR (æ•´é¡µæ¨¡å¼)",
            desc_text="ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ–‡æœ¬è¯†åˆ«ã€‚ä¸ä¸é«˜çº§åˆ†å‰²/å…¨å…ƒç´ æ£€æµ‹åŒæ—¶ä½¿ç”¨ã€‚",
            model_var_name='transformer_ocr_model',
            model_list=trocr_models,
            tooltip_text="ç›´æ¥ä»å›¾åƒåƒç´ è¯†åˆ«æ–‡æœ¬ï¼Œé€‚åˆæ— å¤æ‚å¸ƒå±€çš„æ¸…æ™°å›¾åƒã€‚å¼€å¯æ­¤é¡¹æ—¶ï¼Œé«˜çº§åˆ†å‰²å°†è¢«å¿½ç•¥ã€‚"
        )
    def _browse_for_yolo_file(self, setting_var: tk.StringVar, title: str, filetypes: List[Tuple[str, str]]):
        """æ‰“å¼€æ–‡ä»¶å¯¹è¯æ¡†ä»¥é€‰æ‹©YOLOæ¨¡å‹æ–‡ä»¶ã€‚"""
        file_path = filedialog.askopenfilename(title=title, filetypes=filetypes)
        if file_path:
            setting_var.set(file_path)
            self.log_message(f"âœ… å·²é€‰æ‹©{title}: {os.path.basename(file_path)}", "SUCCESS")
    
    
    
    def _create_ocr_configuration_section(self):
        """
        åˆ›å»ºOCRé…ç½®åŒº (V4.7 - å¢å¼ºå¼•å¯¼ä¸UIé‡æ„ç‰ˆ)
        - å®Œå…¨æš´éœ²OEMå’ŒPSMå‚æ•°ï¼Œé‡‡ç”¨ç›´æ¥é€‰æ‹©é€»è¾‘ã€‚
        - æ–°å¢PSMå¸®åŠ©æŒ‰é’®å’Œå¢å¼ºçš„Tooltipï¼Œå¼•å¯¼ç”¨æˆ·åšå‡ºæ­£ç¡®é€‰æ‹©ã€‚
        - é‡æ„æ£€æµ‹æ¨¡å¼ä¸è¯†åˆ«å¼•æ“çš„UIå¸ƒå±€ï¼Œä½¿å…¶æ›´æ¸…æ™°ã€æ›´å…·åŠŸèƒ½æ€§ã€‚
        """
        # --- ä¸»å®¹å™¨ ---
        ocr_frame = ttk.LabelFrame(self.inner_control_frame, text="OCRä¸æ£€æµ‹é…ç½®", padding=design.get_spacing('3'))
        ocr_frame.pack(fill='x', pady=(0, design.get_spacing('4')))
        
        # 1. è¯­è¨€è®¾ç½®
        lang_frame = ttk.Frame(ocr_frame)
        lang_frame.pack(fill='x', pady=design.get_spacing('1'))
        lang_label = tk.Label(lang_frame, text="è¯†åˆ«è¯­è¨€:", bg=design.get_color('neutral', '50'))
        lang_label.pack(side='left', padx=(0, design.get_spacing('2')))
        lang_combo = ttk.Combobox(lang_frame, textvariable=self.settings['language'],
                                    values=['auto', 'chi_sim', 'eng', 'chi_tra', 'jpn', 'kor', 'chi_sim+eng'], 
                                    width=15, state='readonly')
        lang_combo.pack(side='right', fill='x', expand=True)
        Tooltip(lang_frame, "é€‰æ‹©å›¾ç‰‡ä¸­åŒ…å«çš„ä¸»è¦è¯­è¨€ã€‚\n'chi_sim+eng' é€‚åˆä¸­è‹±æ–‡æ··åˆçš„æ–‡æ¡£ã€‚")

        # 2. Tesseract æ ¸å¿ƒå‚æ•°
        params_frame = ttk.LabelFrame(ocr_frame, text="Tesseract æ ¸å¿ƒå‚æ•°", padding=design.get_spacing('2'))
        params_frame.pack(fill='x', pady=design.get_spacing('2'))
        
        path_frame = ttk.Frame(params_frame)
        path_frame.pack(fill='x', pady=design.get_spacing('1'), expand=True)
        path_label = tk.Label(path_frame, text="Tesseract è·¯å¾„:", bg=design.get_color('neutral', '50'))
        path_label.pack(side='left')
        path_entry = ttk.Entry(path_frame, textvariable=self.settings['tesseract_path'])
        path_entry.pack(side='left', fill='x', expand=True, padx=(design.get_spacing('1'), design.get_spacing('1')))
        browse_button = ttk.Button(path_frame, text="æµè§ˆ...", command=self._browse_for_tesseract)
        browse_button.pack(side='right')
        Tooltip(path_frame, "è®¾ç½®Tesseract OCRå¼•æ“å¯æ‰§è¡Œæ–‡ä»¶(tesseract.exe)çš„è·¯å¾„ã€‚\nå¦‚æœç³»ç»Ÿç¯å¢ƒå˜é‡å·²é…ç½®ï¼Œåˆ™å¯ç•™ç©ºã€‚")

        conf_frame = ttk.Frame(params_frame)
        conf_frame.pack(fill='x', pady=design.get_spacing('1'))
        conf_label = tk.Label(conf_frame, text="ç»“æœç½®ä¿¡åº¦é˜ˆå€¼:", bg=design.get_color('neutral', '50'))
        conf_label.pack(side='left')
        conf_scale = ttk.Scale(conf_frame, from_=0, to=100, variable=self.settings['confidence_threshold'], orient='horizontal', length=120)
        conf_scale.pack(side='right')
        Tooltip(conf_frame, "è¿‡æ»¤æ‰ç½®ä¿¡åº¦ä½äºæ­¤å€¼çš„è¯†åˆ«ç»“æœã€‚\nè°ƒé«˜å¯è·å¾—æ›´å‡†ç¡®ä½†å¯èƒ½ä¸å®Œæ•´çš„æ–‡æœ¬ï¼Œè°ƒä½åˆ™ç›¸åã€‚å»ºè®®60-85ã€‚")
        
        # --- å…¨æ–°çš„ PSM (é¡µé¢åˆ†å‰²æ¨¡å¼) UI ---
        psm_frame = ttk.Frame(params_frame)
        psm_frame.pack(fill='x', pady=design.get_spacing('1'))
        psm_label = tk.Label(psm_frame, text="é¡µé¢åˆ†å‰²æ¨¡å¼ (PSM):", bg=design.get_color('neutral', '50'))
        psm_label.pack(side='left')
        
        psm_help_button = tk.Button(psm_frame, text="?", command=self._show_psm_help, 
                                    font=('Arial', 8, 'bold'), relief='flat', 
                                    bg=design.get_color('neutral', '200'), 
                                    activebackground=design.get_color('neutral', '300'))
        psm_help_button.pack(side='right', padx=(5,0))
        Tooltip(psm_help_button, "ç‚¹å‡»æŸ¥çœ‹æ‰€æœ‰é¡µé¢åˆ†å‰²æ¨¡å¼çš„è¯¦ç»†è§£é‡Šã€‚")

        psm_values = [
            "0: æ–¹å‘å’Œè„šæœ¬æ£€æµ‹(OSD)", "1: è‡ªåŠ¨é¡µé¢åˆ†å‰²+OSD", "2: è‡ªåŠ¨é¡µé¢åˆ†å‰²(æ— OSD)",
            "3: å…¨è‡ªåŠ¨é¡µé¢åˆ†å‰²(é»˜è®¤)", "4: å‡è®¾ä¸ºå•åˆ—å¯å˜å¤§å°æ–‡æœ¬", "5: å‡è®¾ä¸ºå•ä¸ªç»Ÿä¸€çš„å‚ç›´æ–‡æœ¬å—",
            "6: å‡è®¾ä¸ºå•ä¸ªç»Ÿä¸€çš„æ–‡æœ¬å—", "7: å°†å›¾åƒè§†ä¸ºå•è¡Œæ–‡æœ¬", "8: å°†å›¾åƒè§†ä¸ºå•ä¸ªå•è¯",
            "9: å°†å›¾åƒè§†ä¸ºåœ†åœˆå†…çš„å•ä¸ªå•è¯", "10: å°†å›¾åƒè§†ä¸ºå•ä¸ªå­—ç¬¦",
            "11: ç¨€ç–æ–‡æœ¬", "12: å¸¦OSDçš„ç¨€ç–æ–‡æœ¬", "13: åŸå§‹è¡Œ(æ— åˆ†è¯ç­‰å¤„ç†)"
        ]
        psm_combo = ttk.Combobox(psm_frame, textvariable=self.settings['psm_mode'], values=psm_values, state='readonly')
        psm_combo.pack(side='right', fill='x', expand=True)
        psm_combo.set("6: å‡è®¾ä¸ºå•ä¸ªç»Ÿä¸€çš„æ–‡æœ¬å—") #ã€é‡è¦ã€‘å°†é»˜è®¤å€¼æ”¹ä¸ºå¯¹åˆ†å‰²åæœ€å‹å¥½çš„æ¨¡å¼6
        Tooltip(psm_frame, ("æŒ‡å¯¼Tesseractå¦‚ä½•åˆ†æé¡µé¢å¸ƒå±€ã€‚\n"
                           "é‡è¦æç¤ºï¼šåœ¨å¯ç”¨é«˜çº§åˆ†å‰²/å…¨å…ƒç´ æ£€æµ‹åï¼Œæ­¤è®¾ç½®å°†åº”ç”¨äºã€æ¯ä¸ªã€‘è¢«åˆ‡å‰²å‡ºçš„ç‹¬ç«‹æ–‡æœ¬å—ã€‚\n"
                           "ä¸ºè·å¾—æœ€ä½³æ•ˆæœï¼Œå¼ºçƒˆæ¨èé€‰æ‹©åŒºåŸŸçº§æ¨¡å¼ï¼Œå¦‚ 6 æˆ– 7ã€‚"))

        # --- å…¨æ–°çš„ OEM (å¼•æ“æ¨¡å¼) UI ---
        oem_frame = ttk.LabelFrame(params_frame, text="OEM (å¼•æ“æ¨¡å¼) - å¯å¤šé€‰", padding=design.get_spacing('2'))
        oem_frame.pack(fill='x', pady=design.get_spacing('2'))
        
        self.settings['oem_options'] = {
            '0': tk.BooleanVar(value=False),
            '1': tk.BooleanVar(value=False),
            '2': tk.BooleanVar(value=False),
            '3': tk.BooleanVar(value=True), # é»˜è®¤å‹¾é€‰æ¨èçš„ OEM 3
        }
        
        oem_defs = {
            '0': ("ç»å…¸å¼•æ“ (Legacy)", "é€Ÿåº¦æœ€å¿«ï¼ŒåŸºäºä¼ ç»Ÿæ¨¡å¼åŒ¹é…ï¼Œé€‚åˆææ¸…æ™°çš„æ‰“å°ä½“ã€‚"),
            '1': ("ç¥ç»ç½‘ç»œ (LSTM)", "ç°ä»£AIå¼•æ“ï¼Œå‡†ç¡®ç‡é«˜ï¼Œä½†æ¯”ç»å…¸å¼•æ“æ…¢ã€‚"),
            '2': ("ç»å…¸ + LSTM", "ç»„åˆä¸¤ä¸ªå¼•æ“ï¼Œé€Ÿåº¦æœ€æ…¢ï¼Œç”¨äºå®éªŒæ€§æ¯”è¾ƒã€‚"),
            '3': ("é»˜è®¤ (æ¨è)", "æ™ºèƒ½é€‰æ‹©LSTMå¼•æ“ï¼Œæ˜¯é€Ÿåº¦å’Œå‡†ç¡®ç‡çš„æœ€ä½³å¹³è¡¡ç‚¹ã€‚")
        }
        
        oem_info_label = ttk.Label(oem_frame, text="å‹¾é€‰è¦ä½¿ç”¨çš„è¯†åˆ«å¼•æ“ã€‚è‹¥ä¸é€‰ï¼Œå°†ä¸æŒ‡å®šOEMå‚æ•°ï¼Œç”±Tesseractå†³å®šã€‚",
                                   font=design.get_font('xs'), foreground='gray', wraplength=380)
        oem_info_label.pack(anchor='w', pady=(0, design.get_spacing('2')))

        checkbox_frame = ttk.Frame(oem_frame)
        checkbox_frame.pack(fill='x')
        for key, var in self.settings['oem_options'].items():
            oem_check = ttk.Checkbutton(checkbox_frame, text=oem_defs[key][0], variable=var)
            oem_check.pack(anchor='w') 
            Tooltip(oem_check, oem_defs[key][1])
            
        # 3. æ£€æµ‹æ¨¡å¼ä¸å¼•æ“é…ç½®
        detection_frame = ttk.LabelFrame(ocr_frame, text="æ£€æµ‹æ¨¡å¼ä¸å¼•æ“", padding=design.get_spacing('2'))
        detection_frame.pack(fill='x', pady=design.get_spacing('2'), padx=design.get_spacing('1'))
        
        yolo_checkbox = ttk.Checkbutton(detection_frame, text="âœ¨ å¯ç”¨å…¨å…ƒç´ æ£€æµ‹ (YOLO)",
                        variable=self.settings['enable_advanced_segmentation'], 
                        style='TCheckbutton')
        yolo_checkbox.pack(anchor='w', pady=(design.get_spacing('1'), 0))
        Tooltip(yolo_checkbox, "æ ¸å¿ƒæ¨¡å¼åˆ‡æ¢ï¼\n"
                               "â–¶ å‹¾é€‰: åŒæ—¶æ£€æµ‹æ–‡æœ¬ã€è¡¨æ ¼å’Œå›¾å½¢ï¼Œé€‚åˆå¤æ‚ç‰ˆé¢ã€‚\n"
                               "â–¶ ä¸å‹¾é€‰: ä»…è¿›è¡Œçº¯æ–‡æœ¬OCRï¼Œé€Ÿåº¦æ›´å¿«ï¼Œé€‚åˆæ™®é€šæ–‡æ¡£ã€‚")
        
        desc_label = ttk.Label(detection_frame, text="    å‹¾é€‰æ­¤é¡¹ä»¥æ£€æµ‹å›¾å½¢å’Œè¡¨æ ¼ï¼Œå¦åˆ™ä»…è¿›è¡Œçº¯æ–‡æœ¬OCRã€‚", 
                               font=design.get_font('xs'), foreground='gray', justify='left')
        desc_label.pack(anchor='w', pady=(0, design.get_spacing('2')))

        # A. çº¯æ–‡æœ¬æ£€æµ‹å¼•æ“ (é»˜è®¤æ¨¡å¼) -> ä¸å†éœ€è¦ï¼Œå› ä¸ºé«˜çº§åˆ†å‰²æŠ€æœ¯å·²ç»æ¥ç®¡
        
        # B. å…¨å…ƒç´ æ£€æµ‹å¼•æ“ (YOLO)
        yolo_frame = ttk.LabelFrame(detection_frame, text="å…¨å…ƒç´ æ£€æµ‹å¼•æ“ (YOLO)", padding=design.get_spacing('2'))
        yolo_frame.pack(fill='x', pady=design.get_spacing('1'))
        Tooltip(yolo_frame, "å½“'å¯ç”¨å…¨å…ƒç´ æ£€æµ‹'è¢«å‹¾é€‰æ—¶ä½¿ç”¨æ­¤å¼•æ“ã€‚\nå®ƒæ˜¯ä¸€ä¸ªé€šç”¨çš„å¯¹è±¡æ£€æµ‹å™¨ï¼Œèƒ½è¯†åˆ«æ–‡æœ¬å—ã€è¡¨æ ¼ã€å›¾è¡¨ç­‰å¤šç§é¡µé¢å…ƒç´ ã€‚")
        
        weights_row = ttk.Frame(yolo_frame)
        weights_row.pack(fill='x', pady=2)
        tk.Label(weights_row, text="æƒé‡ (.weights):", bg=design.get_color('neutral', '50'), width=15, anchor='w').pack(side='left')
        weights_entry = ttk.Entry(weights_row, textvariable=self.settings['yolo_weights_path'])
        weights_entry.pack(side='left', fill='x', expand=True, padx=5)
        ttk.Button(weights_row, text="æµè§ˆ...", command=lambda: self._browse_for_yolo_file(
            self.settings['yolo_weights_path'], "é€‰æ‹©æƒé‡æ–‡ä»¶", [("Weights files", "*.weights"), ("All files", "*.*")])).pack(side='right')
        Tooltip(weights_row, "YOLOæ¨¡å‹çš„'å¤§è„‘'ï¼ŒåŒ…å«äº†æ‰€æœ‰é€šè¿‡è®­ç»ƒå­¦åˆ°çš„çŸ¥è¯†ã€‚")

        cfg_row = ttk.Frame(yolo_frame)
        cfg_row.pack(fill='x', pady=2)
        tk.Label(cfg_row, text="é…ç½® (.cfg):", bg=design.get_color('neutral', '50'), width=15, anchor='w').pack(side='left')
        cfg_entry = ttk.Entry(cfg_row, textvariable=self.settings['yolo_cfg_path'])
        cfg_entry.pack(side='left', fill='x', expand=True, padx=5)
        ttk.Button(cfg_row, text="æµè§ˆ...", command=lambda: self._browse_for_yolo_file(
            self.settings['yolo_cfg_path'], "é€‰æ‹©é…ç½®æ–‡ä»¶", [("Config files", "*.cfg"), ("All files", "*.*")])).pack(side='right')
        Tooltip(cfg_row, "YOLOæ¨¡å‹çš„'è“å›¾'ï¼Œå®šä¹‰äº†ç¥ç»ç½‘ç»œçš„ç»“æ„ã€‚")

        names_row = ttk.Frame(yolo_frame)
        names_row.pack(fill='x', pady=2)
        tk.Label(names_row, text="ç±»åˆ« (.names):", bg=design.get_color('neutral', '50'), width=15, anchor='w').pack(side='left')
        names_entry = ttk.Entry(names_row, textvariable=self.settings['yolo_names_path'])
        names_entry.pack(side='left', fill='x', expand=True, padx=5)
        ttk.Button(names_row, text="æµè§ˆ...", command=lambda: self._browse_for_yolo_file(
            self.settings['yolo_names_path'], "é€‰æ‹©ç±»åˆ«æ–‡ä»¶", [("Names files", "*.names"), ("All files", "*.*")])).pack(side='right')
        Tooltip(names_row, "ä¸€ä¸ªç®€å•çš„æ–‡æœ¬æ–‡ä»¶ï¼Œåˆ—å‡ºäº†YOLOæ¨¡å‹èƒ½å¤Ÿè¯†åˆ«çš„æ‰€æœ‰å¯¹è±¡åç§°ã€‚")
        
        # C. æ–‡æœ¬å—è¯†åˆ«å¼•æ“
        recognizer_frame = ttk.LabelFrame(ocr_frame, text="æ–‡æœ¬å—è¯†åˆ«å¼•æ“", padding=design.get_spacing('2'))
        recognizer_frame.pack(fill='x', pady=design.get_spacing('1'))
        
        tesseract_row = ttk.Frame(recognizer_frame)
        tesseract_row.pack(fill='x', pady=(0, design.get_spacing('1')))
        
        tess_radio = ttk.Radiobutton(tesseract_row, text="Tesseract", variable=self.settings['segmentation_recognizer'], value="Tesseract")
        tess_radio.pack(side='left', padx=(0, design.get_spacing('2')))
        
        tess_fine_tune_check = ttk.Checkbutton(tesseract_row, text="å¯ç”¨ç²¾ç»†åŒ–é¢„å¤„ç†", variable=self.settings['enable_tesseract_fine_tuning'])
        tess_fine_tune_check.pack(side='left', padx=(0, design.get_spacing('2')))
        Tooltip(tess_fine_tune_check, "å¯¹æ¯ä¸ªæ–‡æœ¬å—è¿›è¡Œç¼©æ”¾ã€å¢å¼ºã€äºŒå€¼åŒ–ç­‰æ“ä½œï¼Œé€šå¸¸èƒ½æå‡Tesseractè¯†åˆ«ç‡ã€‚")

        btn_preview_region_proc = tk.Button(tesseract_row, text="ğŸ”¬ é¢„è§ˆ", command=self.preview_region_preprocessing)
        design.apply_button_style(btn_preview_region_proc, 'secondary')
        btn_preview_region_proc.pack(side='left')
        Tooltip(btn_preview_region_proc, "é¢„è§ˆç²¾ç»†åŒ–é¢„å¤„ç†å¯¹å•ä¸ªæ–‡æœ¬åŒºåŸŸçš„æ•ˆæœã€‚")

        trocr_row = ttk.Frame(recognizer_frame)
        trocr_row.pack(fill='x', pady=(design.get_spacing('1'), 0))

        trocr_radio = ttk.Radiobutton(trocr_row, text="TransformerOCR", variable=self.settings['segmentation_recognizer'], value="TransformerOCR")
        trocr_radio.pack(side='left', padx=(0, design.get_spacing('2')))

        trocr_models = [
            'microsoft/trocr-base-printed',
            'microsoft/trocr-base-handwritten',
            'microsoft/trocr-large-printed',
            'google/trocr-base-zh-printed'
        ]
        trocr_model_combo = ttk.Combobox(trocr_row, 
                                         textvariable=self.settings['transformer_ocr_model'],
                                         values=trocr_models, 
                                         width=30, 
                                         state='readonly')
        trocr_model_combo.pack(side='left', fill='x', expand=True, padx=(0, design.get_spacing('1')))
        
        self.trocr_model_status_label = ttk.Label(trocr_row, text=" (æœªåˆå§‹åŒ–)", foreground="gray")
        self.trocr_model_status_label.pack(side='left')
        
        recognizer_desc = ttk.Label(recognizer_frame, text="é€‰æ‹©ç”¨äºè¯†åˆ«å·²å®šä½æ–‡æœ¬å—çš„å¼•æ“ã€‚TransformerOCRç²¾åº¦æ›´é«˜ï¼Œä½†éœ€åŠ è½½æ¨¡å‹ã€‚", 
                                   font=design.get_font('xs'), foreground='gray', justify='left', wraplength=350)
        recognizer_desc.pack(anchor='w', pady=(design.get_spacing('2'), 0))
    def _show_psm_help(self):
        """åˆ›å»ºä¸€ä¸ªæ–°çª—å£ï¼Œç”¨è¡¨æ ¼è¯¦ç»†è§£é‡Šæ‰€æœ‰PSMæ¨¡å¼ã€‚"""
        help_window = tk.Toplevel(self.root)
        help_window.title("é¡µé¢åˆ†å‰²æ¨¡å¼ (PSM) è¯¦ç»†è¯´æ˜")
        help_window.geometry("700x550")
        help_window.transient(self.root)
        help_window.grab_set()

        main_frame = ttk.Frame(help_window, padding=design.get_spacing('4'))
        main_frame.pack(fill='both', expand=True)

        title_label = tk.Label(main_frame, text="Tesseract é¡µé¢åˆ†å‰²æ¨¡å¼ (PSM)", bg=design.get_color('neutral', '50'))
        design.apply_text_style(title_label, 'h3')
        title_label.pack(anchor='w', pady=(0, design.get_spacing('2')))
        
        desc_label = tk.Label(main_frame, bg=design.get_color('neutral', '50'),
                              text=("PSMæŒ‡å¯¼Tesseractå¦‚ä½•åˆ†æå’Œåˆ†å‰²é¡µé¢å¸ƒå±€ã€‚\n"
                                    "åœ¨å¯ç”¨é«˜çº§åˆ†å‰²åï¼Œæ­¤è®¾ç½®å°†åº”ç”¨äºã€æ¯ä¸€ä¸ªã€‘è¢«åˆ‡å‰²å‡ºçš„ç‹¬ç«‹æ–‡æœ¬å—ã€‚\n"
                                    "å› æ­¤ï¼Œé€‰æ‹©æ­£ç¡®çš„æ¨¡å¼è‡³å…³é‡è¦ï¼"),
                              wraplength=650, justify='left', font=design.get_font('body', family='primary'))
        desc_label.pack(anchor='w', pady=(0, design.get_spacing('4')))

        # ä½¿ç”¨Treeviewåˆ›å»ºä¸€ä¸ªè¡¨æ ¼
        columns = ('æ¨¡å¼', 'è¯´æ˜', 'é€‚ç”¨åœºæ™¯')
        tree = ttk.Treeview(main_frame, columns=columns, show='headings', height=15)
        
        tree.heading('æ¨¡å¼', text='æ¨¡å¼ (å€¼)')
        tree.column('æ¨¡å¼', width=100, anchor='center')
        tree.heading('è¯´æ˜', text='è¯´æ˜')
        tree.column('è¯´æ˜', width=300, anchor='w')
        tree.heading('é€‚ç”¨åœºæ™¯', text='æ¨èåœºæ™¯')
        tree.column('é€‚ç”¨åœºæ™¯', width=250, anchor='w')

        full_psm_data = [
            ("0", "æ–¹å‘å’Œè„šæœ¬æ£€æµ‹ (OSD)", "ä»…ç”¨äºæ£€æµ‹æ–‡å­—æ–¹å‘å’Œè¯­è¨€ï¼Œä¸è¿›è¡ŒOCRã€‚"),
            ("1", "è‡ªåŠ¨é¡µé¢åˆ†å‰² + OSD", "ã€ä¸æ¨èã€‘ç”¨äºå·²åˆ†å‰²åŒºåŸŸã€‚"),
            ("2", "è‡ªåŠ¨é¡µé¢åˆ†å‰² (æ— OSD)", "ã€ä¸æ¨èã€‘ç”¨äºå·²åˆ†å‰²åŒºåŸŸã€‚"),
            ("3", "å…¨è‡ªåŠ¨é¡µé¢åˆ†å‰² (é»˜è®¤)", "ã€ä¸æ¨èã€‘ç”¨äºå·²åˆ†å‰²åŒºåŸŸã€‚"),
            ("4", "å‡è®¾ä¸ºå•åˆ—å¯å˜å¤§å°æ–‡æœ¬", "ã€ä¸æ¨èã€‘ç”¨äºå·²åˆ†å‰²åŒºåŸŸã€‚"),
            ("5", "å‡è®¾ä¸ºå•ä¸ªç»Ÿä¸€çš„å‚ç›´æ–‡æœ¬å—", "ã€ç‰¹å®šåœºæ™¯ã€‘ç”¨äºå‚ç›´ä¹¦å†™çš„æ–‡æœ¬å—ã€‚"),
            ("6", "å‡è®¾ä¸ºå•ä¸ªç»Ÿä¸€çš„æ–‡æœ¬å—", "ã€å¼ºçƒˆæ¨èã€‘æœ€é€šç”¨çš„æ¨¡å¼ã€‚"),
            ("7", "å°†å›¾åƒè§†ä¸ºå•è¡Œæ–‡æœ¬", "ã€æ¨èã€‘ç”¨äºå•è¡Œæ–‡å­—ã€‚"),
            ("8", "å°†å›¾åƒè§†ä¸ºå•ä¸ªå•è¯", "ã€æ¨èã€‘ç”¨äºå•ä¸ªå•è¯ã€‚"),
            ("9", "å°†å›¾åƒè§†ä¸ºåœ†åœˆå†…çš„å•ä¸ªå•è¯", "ç‰¹å®šåœºæ™¯ï¼Œå¦‚å°ç« ã€‚"),
            ("10", "å°†å›¾åƒè§†ä¸ºå•ä¸ªå­—ç¬¦", "ç‰¹å®šåœºæ™¯ï¼Œå¦‚éªŒè¯ç ã€‚"),
            ("11", "ç¨€ç–æ–‡æœ¬", "ã€ä¸æ¨èã€‘ç”¨äºå·²åˆ†å‰²åŒºåŸŸã€‚"),
            ("12", "å¸¦OSDçš„ç¨€ç–æ–‡æœ¬", "ã€ä¸æ¨èã€‘ç”¨äºå·²åˆ†å‰²åŒºåŸŸã€‚"),
            ("13", "åŸå§‹è¡Œ", "ã€æ¨èã€‘ç”¨äºåºåˆ—å·ç­‰ã€‚")
        ]

        for item in full_psm_data:
            tree.insert('', 'end', values=item)

        tree.pack(fill='both', expand=True)

        close_button = tk.Button(main_frame, text="å…³é—­", command=help_window.destroy)
        design.apply_button_style(close_button, 'primary')
        close_button.pack(pady=(design.get_spacing('4'), 0))
    
    
    def _create_image_operations_section(self):
        """åˆ›å»ºå›¾åƒæ“ä½œåŒº"""
        image_frame = ttk.LabelFrame(self.inner_control_frame, text="å›¾åƒæ“ä½œ", padding=design.get_spacing('3'))
        image_frame.pack(fill='x', pady=(0, design.get_spacing('4')))
        
        btn_select_image = tk.Button(image_frame, text="ğŸ“ é€‰æ‹©å›¾ç‰‡", command=self.select_image)
        design.apply_button_style(btn_select_image, 'secondary')
        btn_select_image.pack(fill='x', pady=design.get_spacing('1'))

        btn_preview_process = tk.Button(image_frame, text="ğŸ”¬ é¢„è§ˆé¢„å¤„ç†", command=self.preview_preprocessing)
        design.apply_button_style(btn_preview_process, 'primary')
        btn_preview_process.pack(fill='x', pady=design.get_spacing('1'))

        # --- æ–°å¢ä»£ç å¼€å§‹ ---
        btn_preview_segmentation = tk.Button(image_frame, text="ğŸ“Š é¢„è§ˆåˆ†å‰²ç»“æœ", command=self.preview_segmentation)
        design.apply_button_style(btn_preview_segmentation, 'primary')
        btn_preview_segmentation.pack(fill='x', pady=design.get_spacing('1'))
        # --- æ–°å¢ä»£ç ç»“æŸ ---
        
        btn_generate_test = tk.Button(image_frame, text="ğŸ¨ ç”Ÿæˆæµ‹è¯•å›¾ç‰‡", command=self.generate_test_images)
        design.apply_button_style(btn_generate_test, 'secondary')
        btn_generate_test.pack(fill='x', pady=design.get_spacing('1'))
        
        btn_batch_select = tk.Button(image_frame, text="ğŸ“ æ‰¹é‡é€‰æ‹©", command=self.select_batch_images)
        design.apply_button_style(btn_batch_select, 'secondary')
        btn_batch_select.pack(fill='x', pady=design.get_spacing('1'))
    
    def _create_recognition_operations_section(self):
        """åˆ›å»ºæ–‡æœ¬è¯†åˆ«æ“ä½œåŒº"""
        recognition_frame = ttk.LabelFrame(self.inner_control_frame, text="æ–‡æœ¬è¯†åˆ«", padding=design.get_spacing('3'))
        recognition_frame.pack(fill='x', pady=(0, design.get_spacing('4')))
        
        # --- æŒ‰é’®1: é«˜çº§CVOCRè¯†åˆ« ---
        btn_start_recognition = tk.Button(recognition_frame, text="ğŸš€ é«˜çº§CVOCRè¯†åˆ«", command=self.start_enhanced_recognition)
        design.apply_button_style(btn_start_recognition, 'primary')
        btn_start_recognition.pack(fill='x', pady=design.get_spacing('1'))
        
        # ä¸­æ–‡æ³¨é‡Š
        advanced_desc = ttk.Label(recognition_frame, 
                                  text="ï¼ˆæ¨èï¼‰ä½¿ç”¨æ‚¨é…ç½®çš„æ‰€æœ‰é«˜çº§é¢„å¤„ç†å’Œåˆ†å‰²æŠ€æœ¯ï¼Œç²¾åº¦æœ€é«˜ã€‚",
                                  font=design.get_font('xs'), foreground='gray', wraplength=380, justify='left')
        advanced_desc.pack(anchor='w', pady=(0, design.get_spacing('2')))

        # --- æŒ‰é’®2: æ‰¹é‡å¤„ç† ---
        btn_batch_process = tk.Button(recognition_frame, text="âš¡ æ‰¹é‡å¤„ç†", command=self.batch_process)
        design.apply_button_style(btn_batch_process, 'secondary')
        btn_batch_process.pack(fill='x', pady=design.get_spacing('1'))
        
        # --- æŒ‰é’®3: å¿«é€ŸCVOCRè¯†åˆ« ---
        btn_quick_ocr = tk.Button(recognition_frame, text="âš¡ å¿«é€ŸCVOCRè¯†åˆ«", command=self.quick_ocr)
        design.apply_button_style(btn_quick_ocr, 'secondary')
        btn_quick_ocr.pack(fill='x', pady=design.get_spacing('1'))
        
        # ä¸­æ–‡æ³¨é‡Š
        quick_desc = ttk.Label(recognition_frame, 
                               text="ï¼ˆå¿«é€Ÿï¼‰è·³è¿‡æ‰€æœ‰å¤æ‚å¤„ç†ï¼Œç›´æ¥è°ƒç”¨Tesseractè¿›è¡Œç«¯åˆ°ç«¯è¯†åˆ«ã€‚",
                               font=design.get_font('xs'), foreground='gray', wraplength=380, justify='left')
        quick_desc.pack(anchor='w', pady=(0, design.get_spacing('2')))
    
    def _create_advanced_settings_section(self):
        """
        åˆ›å»ºé«˜çº§è®¾ç½®åŒºï¼ˆV4.1 - å®Œå…¨æ‰‹åŠ¨æ§åˆ¶ & é¢„è®¾ç®¡ç†ç‰ˆï¼‰ã€‚
        - ä¸ºæ‰€æœ‰é¢„å¤„ç†æ“ä½œæ·»åŠ ç‹¬ç«‹çš„å¯ç”¨/ç¦ç”¨å¤é€‰æ¡†ã€‚
        - ç§»é™¤æ‰€æœ‰åå°è‡ªåŠ¨ç­–ç•¥ï¼Œæµç¨‹å®Œå…¨ç”±ç”¨æˆ·å‹¾é€‰å†³å®šã€‚
        - æ–°å¢é¢„è®¾ä¿å­˜ä¸åŠ è½½åŠŸèƒ½ã€‚
        - æ–°å¢å¯¹æ ¸å¿ƒè½¬æ¢æ­¥éª¤ï¼ˆç°åº¦ã€äºŒå€¼åŒ–ï¼‰çš„æ§åˆ¶ã€‚
        """
        advanced_frame = ttk.LabelFrame(self.inner_control_frame, text="é«˜çº§è®¾ç½®", padding=design.get_spacing('3'))
        advanced_frame.pack(fill='x', pady=(0, design.get_spacing('4')))
        
        # --- é¢„è®¾ç®¡ç† ---
        preset_frame = ttk.LabelFrame(advanced_frame, text="é¢„è®¾ç®¡ç†", padding=design.get_spacing('2'))
        preset_frame.pack(fill='x', pady=design.get_spacing('1'), padx=design.get_spacing('1'))
        
        btn_save_preset = tk.Button(preset_frame, text="ğŸ’¾ ä¿å­˜å½“å‰é¢„è®¾", command=self._save_preset_dialog)
        design.apply_button_style(btn_save_preset, 'secondary')
        btn_save_preset.pack(side='left', padx=(0, design.get_spacing('2')))

        btn_load_preset = tk.Button(preset_frame, text="ğŸ“‚ åŠ è½½é¢„è®¾", command=self._load_preset_dialog)
        design.apply_button_style(btn_load_preset, 'secondary')
        btn_load_preset.pack(side='left')
        
        # --- é¢„å¤„ç†æ€»å¼€å…³ ---
        preprocessing_frame = ttk.LabelFrame(advanced_frame, text="å›¾åƒé¢„å¤„ç†é€‰é¡¹", padding=design.get_spacing('2'))
        preprocessing_frame.pack(fill='x', pady=design.get_spacing('1'))
        
        ttk.Checkbutton(preprocessing_frame, text="ğŸ”§ å¯ç”¨é¢„å¤„ç† (æ€»å¼€å…³)",
                        variable=self.settings['enable_preprocessing'], style='TCheckbutton').pack(anchor='w')
        
        ttk.Separator(preprocessing_frame, orient='horizontal').pack(fill='x', pady=design.get_spacing('2'))

        # --- å‡ ä½•æ ¡æ­£ç»„ (ç°åœ¨æ¯ä¸ªéƒ½æœ‰è‡ªå·±çš„å¼€å…³) ---
        geo_frame = ttk.LabelFrame(preprocessing_frame, text="å‡ ä½•æ ¡æ­£", padding=design.get_spacing('2'))
        geo_frame.pack(fill='x', pady=design.get_spacing('1'))
        
        deskew_row = ttk.Frame(geo_frame)
        deskew_row.pack(fill='x', pady=(0, design.get_spacing('1')))
        ttk.Checkbutton(deskew_row, text="ğŸ“ å€¾æ–œæ ¡æ­£", variable=self.settings['enable_deskew'], style='TCheckbutton').pack(side='left')
        ttk.Label(deskew_row, text="è§’åº¦é˜ˆå€¼:").pack(side='left', padx=(design.get_spacing('4'), design.get_spacing('1')))
        ttk.Scale(deskew_row, from_=0.1, to=5.0, variable=self.settings['deskew_angle_threshold'], orient='horizontal', length=100).pack(side='left')
        
        border_row = ttk.Frame(geo_frame)
        border_row.pack(fill='x', pady=(0, design.get_spacing('1')))
        ttk.Checkbutton(border_row, text="ğŸ–¼ï¸ ç§»é™¤è¾¹æ¡†", variable=self.settings['remove_borders'], style='TCheckbutton').pack(side='left')
        ttk.Label(border_row, text="è¾¹æ¡†é˜ˆå€¼:").pack(side='left', padx=(design.get_spacing('4'), design.get_spacing('1')))
        ttk.Scale(border_row, from_=0, to=100, variable=self.settings['border_threshold'], orient='horizontal', length=100).pack(side='left')
        
        ttk.Checkbutton(geo_frame, text="âœ‚ï¸ è£å‰ªåˆ°å†…å®¹", variable=self.settings['crop_to_content'], style='TCheckbutton').pack(anchor='w')
        ttk.Checkbutton(geo_frame, text="ğŸ“„ é¡µé¢è¾¹æ¡†æ£€æµ‹", variable=self.settings['page_border_detection'], style='TCheckbutton').pack(anchor='w')

        # --- å›¾åƒå¢å¼ºä¸é™å™ªç»„ (ç°åœ¨æ¯ä¸ªéƒ½æœ‰è‡ªå·±çš„å¼€å…³) ---
        enhance_frame = ttk.LabelFrame(preprocessing_frame, text="å›¾åƒå¢å¼ºä¸é™å™ª", padding=design.get_spacing('2'))
        enhance_frame.pack(fill='x', pady=design.get_spacing('1'))

        ttk.Checkbutton(enhance_frame, text="ğŸŒ«ï¸ é˜´å½±ç§»é™¤", variable=self.settings['shadow_removal'], style='TCheckbutton').pack(anchor='w')
        
        bilateral_row = ttk.Frame(enhance_frame)
        bilateral_row.pack(fill='x', pady=(0, design.get_spacing('1')))
        ttk.Checkbutton(bilateral_row, text="ğŸ’§ åŒè¾¹æ»¤æ³¢", variable=self.settings['bilateral_filter'], style='TCheckbutton').pack(side='left')
        ttk.Label(bilateral_row, text="ç›´å¾„:").pack(side='left', padx=(design.get_spacing('2'), design.get_spacing('1')))
        ttk.Scale(bilateral_row, from_=1, to=15, variable=self.settings['bilateral_d'], orient='horizontal', length=60).pack(side='left')
        
        ttk.Checkbutton(enhance_frame, text="ğŸ“ˆ ç›´æ–¹å›¾å‡è¡¡åŒ–", variable=self.settings['histogram_equalization'], style='TCheckbutton').pack(anchor='w')
        
        clahe_row = ttk.Frame(enhance_frame)
        clahe_row.pack(fill='x', pady=(0, design.get_spacing('1')))
        ttk.Checkbutton(clahe_row, text="ğŸ”† CLAHEå¢å¼º", variable=self.settings['apply_clahe'], style='TCheckbutton').pack(side='left')
        ttk.Label(clahe_row, text="è£å‰ªé™åˆ¶:").pack(side='left', padx=(design.get_spacing('2'), design.get_spacing('1')))
        ttk.Scale(clahe_row, from_=1.0, to=5.0, variable=self.settings['clahe_clip_limit'], orient='horizontal', length=80).pack(side='left')

        unsharp_row = ttk.Frame(enhance_frame)
        unsharp_row.pack(fill='x', pady=(0, design.get_spacing('1')))
        ttk.Checkbutton(unsharp_row, text="âœ¨ åé”åŒ–æ©æ¨¡", variable=self.settings['unsharp_mask'], style='TCheckbutton').pack(side='left')
        ttk.Label(unsharp_row, text="åŠå¾„:").pack(side='left', padx=(design.get_spacing('2'), design.get_spacing('1')))
        ttk.Scale(unsharp_row, from_=0.5, to=5.0, variable=self.settings['unsharp_radius'], orient='horizontal', length=80).pack(side='left')
        ttk.Label(unsharp_row, text="å¼ºåº¦:").pack(side='left', padx=(design.get_spacing('2'), design.get_spacing('1')))
        ttk.Scale(unsharp_row, from_=0.0, to=3.0, variable=self.settings['unsharp_amount'], orient='horizontal', length=80).pack(side='left')
        
        # --- æ ¸å¿ƒè½¬æ¢æ­¥éª¤æ§åˆ¶ ---
        core_conversion_frame = ttk.LabelFrame(preprocessing_frame, text="æ ¸å¿ƒè½¬æ¢æ­¥éª¤", padding=design.get_spacing('2'))
        core_conversion_frame.pack(fill='x', pady=design.get_spacing('1'))

        ttk.Checkbutton(core_conversion_frame, text="âš™ï¸ è½¬æ¢ä¸ºç°åº¦å›¾", 
                        variable=self.settings['enable_grayscale'], style='TCheckbutton').pack(anchor='w')
        
        binarization_row = ttk.Frame(core_conversion_frame)
        binarization_row.pack(fill='x', pady=(0, design.get_spacing('1')))
        ttk.Checkbutton(binarization_row, text="âš«âšª äºŒå€¼åŒ–", 
                        variable=self.settings['enable_binarization'], style='TCheckbutton').pack(side='left')

        ttk.Label(binarization_row, text="å—å¤§å°:").pack(side='left', padx=(design.get_spacing('4'), design.get_spacing('1')))
        ttk.Scale(binarization_row, from_=3, to=35, variable=self.settings['adaptive_block_size'], orient='horizontal', length=80).pack(side='left')
        ttk.Label(binarization_row, text="Cå€¼:").pack(side='left', padx=(design.get_spacing('2'), design.get_spacing('1')))
        ttk.Scale(binarization_row, from_=0, to=15, variable=self.settings['adaptive_c_constant'], orient='horizontal', length=80).pack(side='left')

        # --- æ˜¾ç¤ºä¸ä¿å­˜è®¾ç½® ---
        display_frame = ttk.LabelFrame(advanced_frame, text="æ˜¾ç¤ºä¸ä¿å­˜è®¾ç½®", padding=design.get_spacing('2'))
        display_frame.pack(fill='x', pady=design.get_spacing('1'))
        
        ttk.Checkbutton(display_frame, text="ğŸ“Š åœ¨ç»“æœè¡¨æ ¼ä¸­æ˜¾ç¤ºç½®ä¿¡åº¦",
                        variable=self.settings['show_confidence'], style='TCheckbutton').pack(anchor='w')
        ttk.Checkbutton(display_frame, text="ğŸ’¾ è‡ªåŠ¨ä¿å­˜è¯†åˆ«ç»“æœ (JSON)",
                        variable=self.settings['auto_save_results'], style='TCheckbutton').pack(anchor='w')
        
        # --- æ€§èƒ½è®¾ç½® ---
        performance_frame = ttk.LabelFrame(advanced_frame, text="æ€§èƒ½è®¾ç½®", padding=design.get_spacing('2'))
        performance_frame.pack(fill='x', pady=design.get_spacing('1'))
        
        ttk.Checkbutton(performance_frame, text="ğŸ–¥ï¸ ä½¿ç”¨GPUåŠ é€Ÿ (éœ€PyTorch GPUç‰ˆ)",
                        variable=self.settings['use_gpu'], style='TCheckbutton').pack(anchor='w')
    
    
    
    def _save_preset_dialog(self):
        """æ‰“å¼€å¯¹è¯æ¡†è®©ç”¨æˆ·å‘½åå¹¶ä¿å­˜å½“å‰é¢„è®¾ã€‚
        æ­¤ç‰ˆæœ¬ä¼šä¿å­˜æ‰€æœ‰é¢„å¤„ç†ç›¸å…³çš„è®¾ç½®ï¼ŒåŒ…æ‹¬æ–°çš„é«˜çº§åˆ†å‰²æŠ€æœ¯é€‰é¡¹ã€‚
        """
        from tkinter import simpledialog
        preset_name = simpledialog.askstring("ä¿å­˜é¢„è®¾", "è¯·è¾“å…¥é¢„è®¾åç§°:", parent=self.root)
        
        if preset_name:
            try:
                # æ”¶é›†æ‰€æœ‰ä¸é¢„å¤„ç†å’Œåˆ†å‰²æŠ€æœ¯ç›¸å…³çš„è®¾ç½®å€¼
                preset_settings = {}
                
                # å®šä¹‰ä¸€ä¸ªå®Œæ•´çš„åˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦ä¿å­˜åˆ°é¢„è®¾ä¸­çš„è®¾ç½®é¡¹çš„é”®
                preset_keys = [
                    # é¢„å¤„ç†æ€»å¼€å…³
                    'enable_preprocessing',
                    
                    # å‡ ä½•æ ¡æ­£
                    'enable_deskew', 
                    'deskew_angle_threshold', 
                    'remove_borders', 
                    'border_threshold', 
                    'crop_to_content', 
                    'page_border_detection', 
                    
                    # å›¾åƒå¢å¼ºä¸é™å™ª
                    'shadow_removal',
                    'bilateral_filter', 
                    'bilateral_d', 
                    'histogram_equalization', 
                    'apply_clahe',
                    'clahe_clip_limit', 
                    'unsharp_mask', 
                    'unsharp_radius', 
                    'unsharp_amount',
                    
                    # æ ¸å¿ƒè½¬æ¢æ­¥éª¤
                    'enable_grayscale', 
                    'enable_binarization',
                    'adaptive_block_size', 
                    'adaptive_c_constant',
                    
                    # é«˜çº§åˆ†å‰²æŠ€æœ¯é€‰é¡¹
                    'seg_simple_high_contrast', 
                    'seg_improved_mser', 
                    'seg_multiscale_contour',
                    'seg_gradient_based', 
                    'seg_multilevel_mser', 
                    'seg_stroke_width_transform',
                    'seg_connected_components', 
                    'seg_character_level'
                ]
                
                # éå†åˆ—è¡¨ï¼Œä» self.settings å­—å…¸ä¸­è·å–æ¯ä¸ªè®¾ç½®çš„å½“å‰å€¼
                for key in preset_keys:
                    if key in self.settings:
                        preset_settings[key] = self.settings[key].get()

                # è¯»å–ç°æœ‰çš„é¢„è®¾æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œä»¥ä¾¿åœ¨ä¸è¦†ç›–å…¶ä»–é¢„è®¾çš„æƒ…å†µä¸‹æ·»åŠ æˆ–æ›´æ–°
                presets = {}
                if os.path.exists('cvocr_presets.json'):
                    with open('cvocr_presets.json', 'r', encoding='utf-8') as f:
                        try:
                            presets = json.load(f)
                        except json.JSONDecodeError:
                            # å¦‚æœæ–‡ä»¶æŸåæˆ–ä¸ºç©ºï¼Œåˆ™å¿½ç•¥æ—§å†…å®¹
                            pass
                
                # æ›´æ–°æˆ–æ·»åŠ å½“å‰è¦ä¿å­˜çš„é¢„è®¾
                presets[preset_name] = preset_settings
                
                # å°†æ›´æ–°åçš„æ‰€æœ‰é¢„è®¾å†™å›æ–‡ä»¶
                with open('cvocr_presets.json', 'w', encoding='utf-8') as f:
                    json.dump(presets, f, indent=2, ensure_ascii=False)
                
                self.log_message(f"ğŸ’¾ é¢„è®¾ '{preset_name}' å·²ä¿å­˜ã€‚", 'SUCCESS')
                messagebox.showinfo("ä¿å­˜æˆåŠŸ", f"é¢„è®¾ '{preset_name}' å·²æˆåŠŸä¿å­˜ï¼")
                
            except Exception as e:
                self.log_message(f"âŒ ä¿å­˜é¢„è®¾å¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("ä¿å­˜å¤±è´¥", f"ä¿å­˜é¢„è®¾å¤±è´¥: {e}")
    def _load_preset_dialog(self):
        """æ‰“å¼€å¯¹è¯æ¡†è®©ç”¨æˆ·é€‰æ‹©å¹¶åŠ è½½é¢„è®¾"""
        if not os.path.exists('cvocr_presets.json'):
            messagebox.showinfo("æ— é¢„è®¾", "æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„é¢„è®¾æ–‡ä»¶ã€‚")
            return

        try:
            with open('cvocr_presets.json', 'r', encoding='utf-8') as f:
                presets = json.load(f)
            
            if not presets:
                messagebox.showinfo("æ— é¢„è®¾", "é¢„è®¾æ–‡ä»¶ä¸ºç©ºã€‚")
                return

            # åˆ›å»ºä¸€ä¸ªé€‰æ‹©çª—å£
            load_window = tk.Toplevel(self.root)
            load_window.title("åŠ è½½é¢„è®¾")
            load_window.geometry("300x400")
            load_window.transient(self.root)
            load_window.grab_set()

            tk.Label(load_window, text="è¯·é€‰æ‹©ä¸€ä¸ªé¢„è®¾åŠ è½½:").pack(pady=10)
            
            listbox = tk.Listbox(load_window)
            listbox.pack(fill='both', expand=True, padx=10, pady=5)
            for name in presets.keys():
                listbox.insert(tk.END, name)

            def on_load():
                selected_indices = listbox.curselection()
                if not selected_indices:
                    return
                
                selected_name = listbox.get(selected_indices[0])
                settings_to_load = presets[selected_name]
                
                # åº”ç”¨åŠ è½½çš„è®¾ç½®åˆ°UI
                for key, value in settings_to_load.items():
                    if key in self.settings:
                        self.settings[key].set(value)
                
                self.log_message(f"ğŸ“‚ é¢„è®¾ '{selected_name}' å·²åŠ è½½ã€‚", 'SUCCESS')
                load_window.destroy()

            load_button = tk.Button(load_window, text="åŠ è½½", command=on_load)
            design.apply_button_style(load_button, 'primary')
            load_button.pack(pady=10)

        except Exception as e:
            self.log_message(f"âŒ åŠ è½½é¢„è®¾å¤±è´¥: {e}", 'ERROR')
            messagebox.showerror("åŠ è½½å¤±è´¥", f"åŠ è½½é¢„è®¾å¤±è´¥: {e}")
    def _create_result_operations_section(self):
        """åˆ›å»ºç»“æœæ“ä½œåŒº"""
        result_frame = ttk.LabelFrame(self.inner_control_frame, text="ç»“æœæ“ä½œ", padding=design.get_spacing('3'))
        result_frame.pack(fill='x', pady=(0, design.get_spacing('4')))
        
        btn_show_vis = tk.Button(result_frame, text="ğŸ“Š æ˜¾ç¤ºå¯è§†åŒ–", command=self.show_visualization)
        design.apply_button_style(btn_show_vis, 'secondary')
        btn_show_vis.pack(fill='x', pady=design.get_spacing('1'))

        btn_export_results = tk.Button(result_frame, text="ğŸ“¤ å¯¼å‡ºç»“æœ", command=self.export_current_results)
        design.apply_button_style(btn_export_results, 'secondary')
        btn_export_results.pack(fill='x', pady=design.get_spacing('1'))

        btn_clear_results = tk.Button(result_frame, text="ğŸ§¹ æ¸…ç©ºç»“æœ", command=self.clear_results)
        design.apply_button_style(btn_clear_results, 'secondary')
        btn_clear_results.pack(fill='x', pady=design.get_spacing('1'))
        
        btn_compare_results = tk.Button(result_frame, text="ğŸ”„ æ¯”è¾ƒç»“æœ", command=self.compare_results)
        design.apply_button_style(btn_compare_results, 'secondary')
        btn_compare_results.pack(fill='x', pady=design.get_spacing('1'))
    
    def _create_log_section(self):
        """åˆ›å»ºæ—¥å¿—åŒºåŸŸ"""
        log_frame = ttk.LabelFrame(self.inner_control_frame, text="æ—¥å¿—ä¿¡æ¯", padding=design.get_spacing('3'))
        log_frame.pack(fill='both', expand=True)
        
        # æ—¥å¿—æ§åˆ¶æŒ‰é’®
        log_control_frame = ttk.Frame(log_frame)
        log_control_frame.pack(fill='x', pady=(0, design.get_spacing('2')))
        
        btn_clear_log = tk.Button(log_control_frame, text="æ¸…é™¤æ—¥å¿—", command=self.clear_log)
        design.apply_button_style(btn_clear_log, 'secondary')
        btn_clear_log.pack(side='left', padx=(0, design.get_spacing('2')))
        
        btn_save_log = tk.Button(log_control_frame, text="ä¿å­˜æ—¥å¿—", command=self.save_log)
        design.apply_button_style(btn_save_log, 'secondary')
        btn_save_log.pack(side='left')
        
        # æ—¥å¿—æ–‡æœ¬åŒºåŸŸ
        self.log_text = scrolledtext.ScrolledText(log_frame, height=15, width=40,
                                                    font=design.get_font('sm', family='primary'),
                                                    bg=design.get_color('neutral', '0'),
                                                    fg=design.get_color('neutral', '800'),
                                                    relief='flat', bd=1,
                                                    highlightbackground=design.get_color('neutral', '300'),
                                                    highlightthickness=1,
                                                    wrap='word')
        self.log_text.pack(fill='both', expand=True, padx=design.get_spacing('2'), pady=design.get_spacing('2'))
        self.log_text.config(state='disabled')
    
    def _on_inner_control_frame_configure(self, event):
        """å†…éƒ¨æ¡†æ¶é…ç½®äº‹ä»¶"""
        self.control_canvas.configure(scrollregion=self.control_canvas.bbox("all"))

    def _on_control_canvas_configure(self, event):
        """ç”»å¸ƒé…ç½®äº‹ä»¶"""
        self.control_canvas.itemconfigure(self.control_canvas_window, width=event.width)

    def _on_mousewheel(self, event):
        """é¼ æ ‡æ»šè½®äº‹ä»¶"""
        if sys.platform == "win32" or sys.platform == "darwin":
            self.control_canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")
        else:
            if event.num == 4:
                self.control_canvas.yview_scroll(-1, "units")
            elif event.num == 5:
                self.control_canvas.yview_scroll(1, "units")
    
    def create_display_area(self, parent):
        """åˆ›å»ºæ˜¾ç¤ºåŒºåŸŸ"""
        display_frame = ttk.Frame(parent)
        display_frame.pack(side='right', fill='both', expand=True)
        
        self.notebook = ttk.Notebook(display_frame)
        self.notebook.pack(fill='both', expand=True)
        
        # å›¾ç‰‡é¢„è§ˆæ ‡ç­¾é¡µ
        self.create_image_tab()
        
        # è¯†åˆ«ç»“æœæ ‡ç­¾é¡µ
        self.create_text_results_tab()
        
        # çº¯æ–‡æœ¬æ ‡ç­¾é¡µ
        self.create_text_tab()
        
        # å†å²è®°å½•æ ‡ç­¾é¡µ
        self.create_history_tab()
        
        # ç»Ÿè®¡ä¿¡æ¯æ ‡ç­¾é¡µ
        self.create_stats_tab()
        
        # æ¯”è¾ƒåˆ†ææ ‡ç­¾é¡µ
        self.create_comparison_tab()
   
    def create_image_tab(self):
        """åˆ›å»ºå›¾ç‰‡é¢„è§ˆæ ‡ç­¾é¡µ"""
        image_frame = ttk.Frame(self.notebook, padding=design.get_spacing('4'))
        self.notebook.add(image_frame, text="ğŸ–¼ï¸ å›¾ç‰‡é¢„è§ˆ")
        
        # å›¾ç‰‡ä¿¡æ¯æ¡†æ¶
        info_frame = ttk.Frame(image_frame, padding=design.get_spacing('2'))
        info_frame.pack(fill='x', pady=(0, design.get_spacing('3')))
        
        self.image_info_label = tk.Label(info_frame, text="æœªé€‰æ‹©å›¾ç‰‡", bg=design.get_color('neutral', '50'))
        design.apply_text_style(self.image_info_label, 'body_small')
        self.image_info_label.pack(side='left')
        
        # å›¾ç‰‡æ“ä½œæŒ‰é’®
        btn_frame = ttk.Frame(info_frame)
        btn_frame.pack(side='right')
        
        btn_reload = tk.Button(btn_frame, text="ğŸ”„ é‡æ–°åŠ è½½", command=self.reload_image)
        design.apply_button_style(btn_reload, 'secondary')
        btn_reload.pack(side='left', padx=design.get_spacing('1'))

        btn_show_explorer = tk.Button(btn_frame, text="ğŸ“ æ˜¾ç¤ºä½ç½®", command=self.show_in_explorer)
        design.apply_button_style(btn_show_explorer, 'secondary')
        btn_show_explorer.pack(side='left', padx=design.get_spacing('1'))
        
        btn_image_info = tk.Button(btn_frame, text="ğŸ“‹ å›¾ç‰‡ä¿¡æ¯", command=self.show_image_info)
        design.apply_button_style(btn_image_info, 'secondary')
        btn_image_info.pack(side='left', padx=design.get_spacing('1'))
        
        # å›¾ç‰‡æ˜¾ç¤ºåŒºåŸŸ
        self.image_canvas = tk.Canvas(image_frame, bg=design.get_color('neutral', '100'), 
                                        relief='flat', bd=1,
                                        highlightbackground=design.get_color('neutral', '300'),
                                        highlightthickness=1)
        self.image_canvas.pack(fill='both', expand=True, padx=design.get_spacing('4'), pady=design.get_spacing('3'))
        
        # æ»šåŠ¨æ¡
        h_scroll = ttk.Scrollbar(image_frame, orient='horizontal', command=self.image_canvas.xview)
        v_scroll = ttk.Scrollbar(image_frame, orient='vertical', command=self.image_canvas.yview)
        self.image_canvas.configure(xscrollcommand=h_scroll.set, yscrollcommand=v_scroll.set)
        
        h_scroll.pack(side='bottom', fill='x', padx=design.get_spacing('4'))
        v_scroll.pack(side='right', fill='y', pady=design.get_spacing('3'))

        self.image_canvas.bind('<Configure>', self._on_canvas_configure)
        self.image_canvas.bind('<Button-1>', self._on_canvas_click)

    def _on_canvas_configure(self, event):
        """Canvasé…ç½®äº‹ä»¶å¤„ç†"""
        if self.current_image_path and (event.width > 0 and event.height > 0):
            if not hasattr(self, '_resize_job_id'):
                self._resize_job_id = None
            
            if self._resize_job_id:
                self.root.after_cancel(self._resize_job_id)
            
            self._resize_job_id = self.root.after(100, lambda: self.display_image(self.current_image_path))
    
    def _on_canvas_click(self, event):
        """Canvasç‚¹å‡»äº‹ä»¶"""
        # å¯ä»¥ç”¨äºå®ç°å›¾åƒåŒºåŸŸé€‰æ‹©ç­‰åŠŸèƒ½
        pass
    
    def create_text_results_tab(self):
        """åˆ›å»ºæ–‡æœ¬è¯†åˆ«ç»“æœæ ‡ç­¾é¡µ"""
        results_frame = ttk.Frame(self.notebook, padding=design.get_spacing('4'))
        self.notebook.add(results_frame, text="ğŸ“„ è¯†åˆ«ç»“æœ")
        
        # ç»“æœç»Ÿè®¡æ¡†æ¶
        stats_frame = ttk.Frame(results_frame, padding=design.get_spacing('2'))
        stats_frame.pack(fill='x', pady=(0, design.get_spacing('3')))
        
        self.results_stats_label = tk.Label(stats_frame, text="æš‚æ— è¯†åˆ«ç»“æœ", bg=design.get_color('neutral', '50'))
        design.apply_text_style(self.results_stats_label, 'body_small')
        self.results_stats_label.pack(side='left')
        
        # æ“ä½œæŒ‰é’®
        btn_frame = ttk.Frame(stats_frame)
        btn_frame.pack(side='right')
        
        btn_filter_results = tk.Button(btn_frame, text="ğŸ” è¿‡æ»¤ç»“æœ", command=self.filter_results_dialog)
        design.apply_button_style(btn_filter_results, 'secondary')
        btn_filter_results.pack(side='left', padx=design.get_spacing('1'))
        
        btn_sort_results = tk.Button(btn_frame, text="ğŸ“Š æ’åº", command=self.sort_results_dialog)
        design.apply_button_style(btn_sort_results, 'secondary')
        btn_sort_results.pack(side='left', padx=design.get_spacing('1'))
        
        # æ–‡æœ¬ç»“æœè¡¨æ ¼
        columns = ('åºå·', 'æ–‡æœ¬å†…å®¹', 'ç½®ä¿¡åº¦', 'è¾¹ç•Œæ¡†', 'è¡Œå·', 'å—å·', 'CVOCRç»„ä»¶', 'å¸ƒå±€ä¿¡æ¯')
        self.results_tree = ttk.Treeview(results_frame, columns=columns, show='headings', height=22)
        
        # è®¾ç½®åˆ—æ ‡é¢˜å’Œå®½åº¦
        column_configs = {
            'åºå·': (50, 'center'),
            'æ–‡æœ¬å†…å®¹': (300, 'w'),
            'ç½®ä¿¡åº¦': (80, 'center'),
            'è¾¹ç•Œæ¡†': (150, 'center'),
            'è¡Œå·': (60, 'center'),
            'å—å·': (60, 'center'),
            'CVOCRç»„ä»¶': (120, 'center'),
            'å¸ƒå±€ä¿¡æ¯': (100, 'center')
        }
        
        for col, (width, anchor) in column_configs.items():
            self.results_tree.heading(col, text=col)
            self.results_tree.column(col, width=width, anchor=anchor)
        
        # æ·»åŠ æ»šåŠ¨æ¡
        tree_scroll = ttk.Scrollbar(results_frame, orient='vertical', command=self.results_tree.yview)
        self.results_tree.configure(yscrollcommand=tree_scroll.set)
        
        # å¸ƒå±€
        self.results_tree.pack(side='left', fill='both', expand=True, padx=(0, design.get_spacing('1')), pady=design.get_spacing('2'))
        tree_scroll.pack(side='right', fill='y', pady=design.get_spacing('2'))
        
        # ç»‘å®šåŒå‡»äº‹ä»¶
        self.results_tree.bind('<Double-1>', self.on_text_result_double_click)
        self.results_tree.bind('<Button-3>', self.on_text_result_right_click)  # å³é”®èœå•
    
    def create_text_tab(self):
        """åˆ›å»ºçº¯æ–‡æœ¬æ ‡ç­¾é¡µ"""
        text_frame = ttk.Frame(self.notebook, padding=design.get_spacing('4'))
        self.notebook.add(text_frame, text="ğŸ“ è¯†åˆ«æŠ¥å‘Š")
        
        # æ–‡æœ¬æ“ä½œæ¡†æ¶
        text_toolbar = ttk.Frame(text_frame, padding=design.get_spacing('2'))
        text_toolbar.pack(fill='x', pady=(0, design.get_spacing('3')))
        
        btn_copy_text = tk.Button(text_toolbar, text="ğŸ“‹ å¤åˆ¶æ–‡æœ¬", command=self.copy_recognized_text)
        design.apply_button_style(btn_copy_text, 'secondary')
        btn_copy_text.pack(side='left', padx=design.get_spacing('1'))

        btn_save_text = tk.Button(text_toolbar, text="ğŸ’¾ ä¿å­˜æ–‡æœ¬", command=self.save_recognized_text)
        design.apply_button_style(btn_save_text, 'secondary')
        btn_save_text.pack(side='left', padx=design.get_spacing('1'))
        
        btn_search_text = tk.Button(text_toolbar, text="ğŸ” æœç´¢æ–‡æœ¬", command=self.search_text_dialog)
        design.apply_button_style(btn_search_text, 'secondary')
        btn_search_text.pack(side='left', padx=design.get_spacing('1'))
        
        btn_text_analysis = tk.Button(text_toolbar, text="ğŸ“Š æ–‡æœ¬åˆ†æ", command=self.analyze_text)
        design.apply_button_style(btn_text_analysis, 'secondary')
        btn_text_analysis.pack(side='left', padx=design.get_spacing('1'))
        
        # æŠ¥å‘Šæ˜¾ç¤ºåŒºåŸŸ
        self.report_text = scrolledtext.ScrolledText(text_frame, 
                                                    font=design.get_font('base'),
                                                    bg=design.get_color('neutral', '0'),
                                                    fg=design.get_color('neutral', '700'),
                                                    wrap='word', height=30,
                                                    relief='flat', bd=1,
                                                    highlightbackground=design.get_color('neutral', '300'),
                                                    highlightcolor=design.get_color('primary', '600'),
                                                    highlightthickness=1)
        self.report_text.pack(fill='both', expand=True, padx=design.get_spacing('2'), pady=design.get_spacing('2'))
    
    def create_history_tab(self):
        """åˆ›å»ºå†å²è®°å½•æ ‡ç­¾é¡µ"""
        history_frame = ttk.Frame(self.notebook, padding=design.get_spacing('4'))
        self.notebook.add(history_frame, text="ğŸ“š å†å²è®°å½•")
        
        # å†å²è®°å½•å·¥å…·æ 
        history_toolbar = ttk.Frame(history_frame, padding=design.get_spacing('2'))
        history_toolbar.pack(fill='x', pady=(0, design.get_spacing('3')))
        
        btn_refresh_history = tk.Button(history_toolbar, text="ğŸ”„ åˆ·æ–°", command=self.refresh_history)
        design.apply_button_style(btn_refresh_history, 'secondary')
        btn_refresh_history.pack(side='left', padx=design.get_spacing('1'))

        btn_export_history = tk.Button(history_toolbar, text="ğŸ“¤ å¯¼å‡ºå†å²", command=self.export_history)
        design.apply_button_style(btn_export_history, 'secondary')
        btn_export_history.pack(side='left', padx=design.get_spacing('1'))

        btn_clear_history = tk.Button(history_toolbar, text="ğŸ§¹ æ¸…ç©ºå†å²", command=self.clear_history)
        design.apply_button_style(btn_clear_history, 'secondary')
        btn_clear_history.pack(side='left', padx=design.get_spacing('1'))
        
        btn_search_history = tk.Button(history_toolbar, text="ğŸ” æœç´¢å†å²", command=self.search_history_dialog)
        design.apply_button_style(btn_search_history, 'secondary')
        btn_search_history.pack(side='left', padx=design.get_spacing('1'))
        
        # å†å²è®°å½•è¡¨æ ¼
        columns = ('æ—¶é—´', 'å›¾ç‰‡åç§°', 'æ–‡æœ¬å—æ•°', 'å­—ç¬¦æ•°', 'å¹³å‡ç½®ä¿¡åº¦', 'ä½¿ç”¨ç»„ä»¶', 'çŠ¶æ€', 'å¤„ç†æ—¶é—´')
        self.history_tree = ttk.Treeview(history_frame, columns=columns, show='headings')
        
        history_column_configs = {
            'æ—¶é—´': (140, 'center'),
            'å›¾ç‰‡åç§°': (200, 'w'),
            'æ–‡æœ¬å—æ•°': (80, 'center'),
            'å­—ç¬¦æ•°': (80, 'center'),
            'å¹³å‡ç½®ä¿¡åº¦': (100, 'center'),
            'ä½¿ç”¨ç»„ä»¶': (150, 'center'),
            'çŠ¶æ€': (80, 'center'),
            'å¤„ç†æ—¶é—´': (100, 'center')
        }
        
        for col, (width, anchor) in history_column_configs.items():
            self.history_tree.heading(col, text=col)
            self.history_tree.column(col, width=width, anchor=anchor)
        
        # æ·»åŠ æ»šåŠ¨æ¡
        history_scroll = ttk.Scrollbar(history_frame, orient='vertical', command=self.history_tree.yview)
        self.history_tree.configure(yscrollcommand=history_scroll.set)
        
        # å¸ƒå±€
        self.history_tree.pack(side='left', fill='both', expand=True, padx=(0, design.get_spacing('1')), pady=design.get_spacing('2'))
        history_scroll.pack(side='right', fill='y', pady=design.get_spacing('2'))
        
        # ç»‘å®šåŒå‡»äº‹ä»¶
        self.history_tree.bind('<Double-1>', self.on_history_double_click)
        self.history_tree.bind('<Button-3>', self.on_history_right_click)
    
    def create_stats_tab(self):
        """åˆ›å»ºç»Ÿè®¡ä¿¡æ¯æ ‡ç­¾é¡µ"""
        stats_frame = ttk.Frame(self.notebook, padding=design.get_spacing('4'))
        self.notebook.add(stats_frame, text="ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
        
        # ç»Ÿè®¡æ§åˆ¶æ 
        stats_toolbar = ttk.Frame(stats_frame, padding=design.get_spacing('2'))
        stats_toolbar.pack(fill='x', pady=(0, design.get_spacing('3')))
        
        btn_refresh_stats = tk.Button(stats_toolbar, text="ğŸ”„ åˆ·æ–°ç»Ÿè®¡", command=self.update_enhanced_stats)
        design.apply_button_style(btn_refresh_stats, 'secondary')
        btn_refresh_stats.pack(side='left', padx=design.get_spacing('1'))
        
        btn_export_stats = tk.Button(stats_toolbar, text="ğŸ“Š å¯¼å‡ºç»Ÿè®¡", command=self.export_stats)
        design.apply_button_style(btn_export_stats, 'secondary')
        btn_export_stats.pack(side='left', padx=design.get_spacing('1'))
        
        btn_reset_stats = tk.Button(stats_toolbar, text="ğŸ”„ é‡ç½®ç»Ÿè®¡", command=self.reset_stats)
        design.apply_button_style(btn_reset_stats, 'secondary')
        btn_reset_stats.pack(side='left', padx=design.get_spacing('1'))
        
        # ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤ºåŒºåŸŸ
        self.stats_text = scrolledtext.ScrolledText(stats_frame, 
                                                    font=design.get_font('sm', family='primary'),
                                                    bg=design.get_color('neutral', '0'),
                                                    fg=design.get_color('neutral', '800'),
                                                    relief='flat', bd=1,
                                                    highlightbackground=design.get_color('neutral', '300'),
                                                    highlightthickness=1, wrap='word')
        self.stats_text.pack(fill='both', expand=True, padx=design.get_spacing('2'), pady=design.get_spacing('2'))
        self.stats_text.config(state='disabled')
    
    def create_comparison_tab(self):
        """åˆ›å»ºæ¯”è¾ƒåˆ†ææ ‡ç­¾é¡µ"""
        comparison_frame = ttk.Frame(self.notebook, padding=design.get_spacing('4'))
        self.notebook.add(comparison_frame, text="ğŸ”„ æ¯”è¾ƒåˆ†æ")
        
        # æ¯”è¾ƒå·¥å…·æ 
        comparison_toolbar = ttk.Frame(comparison_frame, padding=design.get_spacing('2'))
        comparison_toolbar.pack(fill='x', pady=(0, design.get_spacing('3')))
        
        btn_compare_images = tk.Button(comparison_toolbar, text="ğŸ–¼ï¸ æ¯”è¾ƒå›¾ç‰‡", command=self.compare_images)
        design.apply_button_style(btn_compare_images, 'secondary')
        btn_compare_images.pack(side='left', padx=design.get_spacing('1'))
        
        btn_compare_methods = tk.Button(comparison_toolbar, text="âš–ï¸ æ¯”è¾ƒæ–¹æ³•", command=self.compare_methods)
        design.apply_button_style(btn_compare_methods, 'secondary')
        btn_compare_methods.pack(side='left', padx=design.get_spacing('1'))
        
        # æ¯”è¾ƒç»“æœæ˜¾ç¤ºåŒºåŸŸ
        self.comparison_text = scrolledtext.ScrolledText(comparison_frame,
                                                        font=design.get_font('base'),
                                                        bg=design.get_color('neutral', '0'),
                                                        fg=design.get_color('neutral', '800'),
                                                        relief='flat', bd=1,
                                                        highlightbackground=design.get_color('neutral', '300'),
                                                        highlightthickness=1, wrap='word')
        self.comparison_text.pack(fill='both', expand=True, padx=design.get_spacing('2'), pady=design.get_spacing('2'))
        self.comparison_text.config(state='disabled')
    
    def create_status_bar(self):
        """åˆ›å»ºçŠ¶æ€æ """
        self.status_bar = ttk.Frame(self.root)
        self.status_bar.pack(side='bottom', fill='x', padx=design.get_spacing('2'), pady=design.get_spacing('1'))
        
        # çŠ¶æ€æ ‡ç­¾
        self.status_text = tk.Label(self.status_bar, text="å°±ç»ª", bg=design.get_color('neutral', '50'))
        design.apply_text_style(self.status_text, 'caption')
        self.status_text.pack(side='left', padx=design.get_spacing('1'))
        
        # è¿›åº¦æ¡
        self.progress_bar = ttk.Progressbar(self.status_bar, mode='indeterminate', 
                                            length=200)
        self.progress_bar.pack(side='right', padx=(design.get_spacing('4'), 0))
        
        # æ€§èƒ½æŒ‡æ ‡
        self.performance_label = tk.Label(self.status_bar, text="", bg=design.get_color('neutral', '50'))
        design.apply_text_style(self.performance_label, 'caption')
        self.performance_label.pack(side='right', padx=design.get_spacing('2'))
        
        # ç‰ˆæœ¬ä¿¡æ¯
        version_label = tk.Label(self.status_bar, text=f"CVOCR v{CVOCRConstants.VERSION}", 
                                bg=design.get_color('neutral', '50'))
        design.apply_text_style(version_label, 'caption')
        version_label.pack(side='right', padx=(0, design.get_spacing('4')))
    
    # æ ¸å¿ƒåŠŸèƒ½æ–¹æ³•å®ç°
    LOG_MESSAGE = 0
    GUI_TASK = 1 # ä¿æŒä¸å˜ï¼Œä½†ç°åœ¨ç”± loop.call_soon è°ƒåº¦

    def log_message(self, message: str, level: str = 'INFO'):
        """è®°å½•æ—¥å¿—æ¶ˆæ¯ï¼Œå¹¶æ”¾å…¥é˜Ÿåˆ—ç­‰å¾… GUI çº¿ç¨‹å¤„ç†"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        icons = {'INFO': 'â„¹ï¸', 'WARNING': 'âš ï¸', 'ERROR': 'âŒ', 'SUCCESS': 'âœ…', 'DEBUG': 'ğŸ›'}
        icon = icons.get(level.upper(), 'â„¹ï¸')
        
        formatted_message = f"[{timestamp}] {icon} {message}\n"
        
        if hasattr(self, 'log_queue'): # ç¡®ä¿ GUI å·²åˆå§‹åŒ–
            # ä½¿ç”¨ put_nowait é¿å…é˜»å¡æ—¥å¿—çº¿ç¨‹
            try:
                self.log_queue.put_nowait((self.LOG_MESSAGE, formatted_message, message, {}))
            except queue.Full:
                print(f"Log queue is full, dropping message: {formatted_message.strip()}")
        else:
            print(f"GUIæœªå®Œå…¨åˆå§‹åŒ–ï¼Œç›´æ¥æ‰“å°: {formatted_message.strip()}")

        # è®°å½•åˆ°æ ‡å‡†logger
        log_level_map = {
            'INFO': logging.INFO,
            'WARNING': logging.WARNING,
            'ERROR': logging.ERROR,
            'CRITICAL': logging.CRITICAL,
            'DEBUG': logging.DEBUG,
            'SUCCESS': logging.INFO
        }
        
        log_module_level = log_level_map.get(level.upper(), logging.INFO)
        logger.log(log_module_level, message)

    async def _process_queues(self):
        """å¼‚æ­¥å¤„ç†æ—¥å¿—é˜Ÿåˆ—å’Œ GUI ä»»åŠ¡"""
        while True:
            # å¤„ç†æ—¥å¿—é˜Ÿåˆ—
            while not self.log_queue.empty():
                task_type, formatted_message, status_message, kwargs = self.log_queue.get_nowait()
                if task_type == self.LOG_MESSAGE:
                    # ç¡®ä¿ GUI æ›´æ–°åœ¨ Tkinter ä¸»çº¿ç¨‹ä¸­è¿›è¡Œ
                    self.root.after(0, self._safe_update_gui_log, formatted_message, status_message)
            
            # éé˜»å¡ç­‰å¾…ï¼Œè®©äº‹ä»¶å¾ªç¯å¤„ç†å…¶ä»–åç¨‹
            await asyncio.sleep(0.01) # æ¯éš”10msæ£€æŸ¥ä¸€æ¬¡é˜Ÿåˆ—    

    # --- ä¿®æ­£4: ç§»é™¤é‡å¤çš„ã€éå¼‚æ­¥çš„ _process_queues æ–¹æ³• ---
    # (æ—§çš„ã€é‡å¤çš„æ–¹æ³•å®šä¹‰å·²åœ¨æ­¤å¤„åˆ é™¤)

    def _safe_update_gui_log(self, formatted_message: str, status_message: str):
        """å®‰å…¨æ›´æ–°GUIæ—¥å¿—"""
        try:
            self.log_text.config(state='normal')
            self.log_text.insert(tk.END, formatted_message)
            self.log_text.see(tk.END)
            self.log_text.config(state='disabled')
            
            self.status_text.config(text=status_message)
            self.root.update_idletasks()
        except Exception as e:
            print(f"Failed to update GUI log: {e}")
            logger.error(f"Failed to update GUI log: {e}")
    
    def set_processing(self, processing: bool):
        """è®¾ç½®å¤„ç†çŠ¶æ€"""
        self.processing = processing
        if processing:
            self.progress_bar.start()
        else:
            self.progress_bar.stop()
    
    def _load_settings(self):
        """åŠ è½½è®¾ç½®"""
        try:
            settings_file = 'cvocr_settings.json'
            if os.path.exists(settings_file):
                with open(settings_file, 'r', encoding='utf-8') as f:
                    saved_settings = json.load(f)
                    
                for key, value in saved_settings.items():
                    if key in self.settings:
                        # ç‰¹æ®Šå¤„ç† CLAHE tile grid sizeï¼Œå› ä¸ºå®ƒä»¬æ˜¯ä¸¤ä¸ªå˜é‡
                        if key == 'clahe_tile_grid_size_x' or key == 'clahe_tile_grid_size_y':
                            self.settings[key].set(value)
                        # å…¶ä»–æ™®é€šå˜é‡ç›´æ¥è®¾ç½®
                        else:
                            self.settings[key].set(value)

                # åŠ è½½å¹¶åº”ç”¨Tesseractè·¯å¾„
                tesseract_path = self.settings['tesseract_path'].get()
                if tesseract_path:
                    success, msg = self.cvocr_manager.set_tesseract_path(tesseract_path)
                    if success:
                        self.log_message(f"âœ… å·²ä»é…ç½®åŠ è½½Tesseractè·¯å¾„: {tesseract_path}", 'SUCCESS')
                    else:
                        self.log_message(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸­çš„Tesseractè·¯å¾„æ— æ•ˆ: {tesseract_path}", 'WARNING')
                
                self.log_message("âœ… è®¾ç½®å·²åŠ è½½", 'SUCCESS')
        except Exception as e:
            logger.error(f"åŠ è½½è®¾ç½®å¤±è´¥: {e}\n{traceback.format_exc()}")
    
    def _save_settings(self):
        """ä¿å­˜è®¾ç½®"""
        try:
            settings_file = 'cvocr_settings.json'
            settings_to_save = {}
            
            for key, var in self.settings.items():
                try:
                    settings_to_save[key] = var.get()
                except Exception:
                    pass # å¿½ç•¥æ— æ³•è·å–å€¼çš„å˜é‡
            
            with open(settings_file, 'w', encoding='utf-8') as f:
                json.dump(settings_to_save, f, ensure_ascii=False, indent=2)
            
            self.log_message("ğŸ’¾ è®¾ç½®å·²ä¿å­˜", 'SUCCESS')
        except Exception as e:
            logger.error(f"ä¿å­˜è®¾ç½®å¤±è´¥: {e}\n{traceback.format_exc()}")
    
    # æ ¸å¿ƒä¸šåŠ¡æ–¹æ³•å®ç°
    def initialize_cvocr(self):
        """
        åˆå§‹åŒ–CVOCRå¼•æ“ (V4.5 - æœ€ç»ˆé…ç½®åŒæ­¥ç‰ˆ)ã€‚
        - å…¨é¢ã€å®‰å…¨åœ°ä»GUIæ”¶é›†æ‰€æœ‰è®¾ç½®ã€‚
        - å°†æ‰€æœ‰è®¾ç½®å®Œæ•´åœ°æ›´æ–°åˆ°åç«¯ç®¡ç†å™¨ã€‚
        - ä½¿ç”¨æ­£ç¡®çš„è®¾ç½®å˜é‡å¯åŠ¨å¼‚æ­¥åˆå§‹åŒ–æµç¨‹ã€‚
        """
        # --- æ­¥éª¤1: å…¨é¢ã€å®‰å…¨åœ°ä»GUIæ”¶é›†æ‰€æœ‰è®¾ç½® ---
        current_gui_config = {}
        for key, var in self.settings.items():
            # å®‰å…¨åœ°è·å–å€¼ï¼Œè·³è¿‡åƒ 'oem_options' è¿™æ ·çš„ç‰¹æ®Šå­—å…¸
            if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar)):
                current_gui_config[key] = var.get()
        # æ‰‹åŠ¨æ·»åŠ OEMé€‰é¡¹å­—å…¸
        current_gui_config['oem_options'] = {k: v.get() for k, v in self.settings['oem_options'].items()}
        
        # --- æ­¥éª¤2: ä»æ”¶é›†çš„é…ç½®ä¸­æå–åˆå§‹åŒ–æ‰€éœ€çš„å…³é”®å‚æ•° ---
        language_str = current_gui_config.get('language', 'auto')
        language = OCRLanguage(language_str) if language_str != 'auto' else OCRLanguage.AUTO
        
        use_gpu = current_gui_config.get('use_gpu', False)

        # --- æ­¥éª¤3: å°†æ‰€æœ‰GUIè®¾ç½®å®Œæ•´åœ°åŒæ­¥åˆ°åç«¯ç®¡ç†å™¨çš„é…ç½®å­—å…¸ä¸­ ---
        self.cvocr_manager.config.update(current_gui_config)

        # --- æ­¥éª¤4: å®šä¹‰å¹¶å¯åŠ¨å¼‚æ­¥åˆå§‹åŒ–ä»»åŠ¡ ---
        async def init_worker_async():
            self.log_message(f"ğŸš€ æ­£åœ¨åˆå§‹åŒ–CVOCRå¼•æ“ (è¯­è¨€: {language.value}, ç²¾åº¦: è‡ªå®šä¹‰, GPU: {use_gpu})...", 'INFO')
            
            # ä¸ºæ—¥å¿—æ„å»ºå¯ç”¨çš„ç»„ä»¶åˆ—è¡¨
            enabled_components_log = ["Tesseract"] # Tesseract is always a base component
            if self.cvocr_manager.config.get('enable_layout_analysis'): enabled_components_log.append("LayoutLMv2")
            if self.cvocr_manager.config.get('enable_context_analysis'): enabled_components_log.append("GPT-Neo")
            if self.cvocr_manager.config.get('enable_transformer_ocr'): enabled_components_log.append("TransformerOCR")
            if self.settings['enable_advanced_segmentation'].get():
                 enabled_components_log.append("YOLO")
            else:
                 enabled_components_log.append("PP-OCRv3")

            self.log_message(f"ğŸ”§ å¯ç”¨ç»„ä»¶: {', '.join(enabled_components_log)}", 'INFO')
            
            try:
                # åœ¨åå°çº¿ç¨‹æ± ä¸­è¿è¡Œé˜»å¡çš„ initialize æ–¹æ³•
                success, message = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    self.cvocr_manager.initialize,
                    language,
                    use_gpu
                )
                # å°†ç»“æœå›è°ƒåˆ°ä¸»çº¿ç¨‹ä»¥æ›´æ–°UI
                self.root.after(0, self._handle_init_result, success, message)
            except Exception as e:
                error_msg = f"CVOCRå¼•æ“åˆå§‹åŒ–æ—¶å‘ç”Ÿæœªæ•è·çš„å¼‚å¸¸: {str(e)}"
                logger.error(error_msg, exc_info=True)
                self.root.after(0, self._handle_init_result, False, error_msg)
            finally:
                # ç¡®ä¿æ— è®ºæˆåŠŸä¸å¦ï¼ŒUIçš„â€œå¤„ç†ä¸­â€çŠ¶æ€éƒ½ä¼šè¢«é‡ç½®
                self.root.after(0, self.set_processing, False)

        # å¯åŠ¨UIçš„â€œå¤„ç†ä¸­â€çŠ¶æ€ï¼ˆä¾‹å¦‚ï¼Œå¼€å§‹è¿›åº¦æ¡åŠ¨ç”»ï¼‰
        self.set_processing(True)
        # ä»Tkinterä¸»çº¿ç¨‹å®‰å…¨åœ°å°†å¼‚æ­¥ä»»åŠ¡è°ƒåº¦åˆ°åå°çš„asyncioäº‹ä»¶å¾ªç¯ä¸­
        self.loop.call_soon_threadsafe(self.loop.create_task, init_worker_async())
    
    
    
    def _handle_init_result(self, success: bool, message: str):
        """
        å¤„ç†åˆå§‹åŒ–ç»“æœï¼Œå¹¶æ›´æ–°GUIçš„å„ä¸ªç›¸å…³éƒ¨åˆ†ã€‚
        - æ›´æ–°ç³»ç»ŸçŠ¶æ€åŒºçš„æ ‡ç­¾å’Œé¢œè‰²ã€‚
        - è®°å½•è¯¦ç»†çš„åˆå§‹åŒ–æ—¥å¿—ã€‚
        - æ›´æ–°æ–°å¢çš„TransformerOCRæ¨¡å‹åŠ è½½çŠ¶æ€æ ‡ç­¾ã€‚
        - å¼¹å‡ºå¯¹è¯æ¡†é€šçŸ¥ç”¨æˆ·åˆå§‹åŒ–ç»“æœã€‚
        """
        if success:
            self.status_label.config(text="CVOCRå¼•æ“å°±ç»ª", style='Success.TLabel')
            self.log_message(f"âœ… {message}", 'SUCCESS')
            
            # æ˜¾ç¤ºè¯¦ç»†çš„ç‰ˆæœ¬å’Œé…ç½®ä¿¡æ¯
            version_info = self.cvocr_manager.version_info
            self.log_message(f"ğŸ“Š åˆå§‹åŒ–è€—æ—¶: {version_info.get('init_time', 0):.2f}ç§’", 'INFO')
            self.log_message(f"ğŸ”§ Tesseractç‰ˆæœ¬: {version_info.get('tesseract', 'unknown')}", 'INFO')
            self.log_message(f"ğŸŒ è¯†åˆ«è¯­è¨€: {version_info.get('language', 'unknown')}", 'INFO')
            
            # æ˜¾ç¤ºå·²å¯ç”¨çš„AIç»„ä»¶çŠ¶æ€
            components = version_info.get('components', {})
            if components:
                enabled_components = [comp.replace('_enabled', '').upper() for comp, enabled in components.items() if enabled]
                if enabled_components:
                    self.log_message(f"ğŸ¯ å·²å¯ç”¨ç»„ä»¶: {', '.join(enabled_components)}", 'INFO')
            
            # --- æ–°å¢ï¼šæ›´æ–°TrOCRæ¨¡å‹åŠ è½½çŠ¶æ€æ ‡ç­¾ ---
            # æ ¹æ®åˆå§‹åŒ–ç»“æœä¸­çš„ç»„ä»¶çŠ¶æ€æ¥è®¾ç½®æ ‡ç­¾çš„æ–‡æœ¬å’Œé¢œè‰²ã€‚
            if components.get('transformer_ocr_enabled'):
                self.trocr_model_status_label.config(text="âœ… å·²åŠ è½½", foreground="green")
            elif self.settings['enable_transformer_ocr'].get():
                # å¦‚æœç”¨æˆ·å‹¾é€‰äº†å¯ç”¨ï¼Œä½†åˆå§‹åŒ–åç»„ä»¶çŠ¶æ€ä»ä¸ºæœªå¯ç”¨ï¼Œåˆ™è¯´æ˜åŠ è½½å¤±è´¥
                self.trocr_model_status_label.config(text="âŒ åŠ è½½å¤±è´¥", foreground="red")
            else:
                # å¦‚æœç”¨æˆ·æœªå‹¾é€‰å¯ç”¨ï¼Œåˆ™æ˜¾ç¤ºä¸ºæœªå¯ç”¨çŠ¶æ€
                self.trocr_model_status_label.config(text=" (æœªå¯ç”¨)", foreground="gray")

            messagebox.showinfo("åˆå§‹åŒ–æˆåŠŸ", f"{message}\n\nCVOCRå¼•æ“å·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹æ–‡æœ¬è¯†åˆ«ï¼")
        else:
            self.status_label.config(text="åˆå§‹åŒ–å¤±è´¥", style='Error.TLabel')
            self.log_message(f"âŒ {message}", 'ERROR')
            
            # --- æ–°å¢ï¼šåœ¨åˆå§‹åŒ–å¤±è´¥æ—¶ï¼ŒåŒæ ·æ›´æ–°TrOCRæ¨¡å‹çŠ¶æ€æ ‡ç­¾ ---
            # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œæ‰€æœ‰AIæ¨¡å‹éƒ½åº”è¢«è§†ä¸ºæœªåŠ è½½
            self.trocr_model_status_label.config(text="âŒ æœªåŠ è½½", foreground="red")
            
            messagebox.showerror("åˆå§‹åŒ–å¤±è´¥", f"{message}\n\nå»ºè®®å…ˆè¿è¡Œç³»ç»Ÿæ£€æŸ¥ã€‚")

    async def _trigger_initial_system_check_async(self):
        """å¼‚æ­¥è§¦å‘åˆå§‹ç³»ç»Ÿæ£€æŸ¥"""
        await self.check_system_async()

    def check_system(self):
        """ç³»ç»Ÿæ£€æŸ¥ (ç°åœ¨è°ƒç”¨å¼‚æ­¥ç‰ˆæœ¬)"""
        # è¿™ä¸ªåŒæ­¥æ–¹æ³•ç°åœ¨åªæ˜¯ä¸€ä¸ªåŒ…è£…å™¨ï¼Œç”¨äºä»TkinteræŒ‰é’®è°ƒç”¨
        # å®ƒå°†å®é™…å·¥ä½œæäº¤ç»™asyncioå¾ªç¯
        if self.loop and self.loop.is_running():
            self.loop.call_soon_threadsafe(self.loop.create_task, self.check_system_async())
        else:
            messagebox.showerror("é”™è¯¯", "Asyncioäº‹ä»¶å¾ªç¯æœªè¿è¡Œï¼Œæ— æ³•æ‰§è¡Œç³»ç»Ÿæ£€æŸ¥ã€‚")
            
    async def check_system_async(self):
        """ç³»ç»Ÿæ£€æŸ¥ (ç°åœ¨æ˜¯å¼‚æ­¥åç¨‹)"""
        async def check_worker_async():
            self.log_message("ğŸ” å¼€å§‹CVOCRç³»ç»Ÿæ£€æŸ¥...", 'INFO')
            
            try:
                # é˜»å¡æ“ä½œæ”¾å…¥çº¿ç¨‹æ± 
                compatible, issues = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor, # ä½¿ç”¨ OCR å¤„ç†å™¨çš„çº¿ç¨‹æ± 
                    CVOCRVersionManager.check_compatibility,
                    self.settings['tesseract_path'].get()
                )
                
                system_info = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    CVOCRVersionManager.get_system_info
                )
                self.log_message(f"ğŸ’» ç³»ç»Ÿ: {system_info['platform']} {system_info['architecture']}", 'INFO')
                self.log_message(f"ğŸ Python: {system_info['python_version']}", 'INFO')
                
                versions = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    CVOCRVersionManager.get_dependency_versions,
                    self.settings['tesseract_path'].get()
                )
                for lib, version in versions.items():
                     self.log_message(f"ğŸ“¦ {lib}: {version}", 'INFO')

                try:
                    memory = await self.loop.run_in_executor(
                        self.async_ocr_processor.executor,
                        psutil.virtual_memory
                    )
                    total_gb = memory.total / (1024**3)
                    available_gb = memory.available / (1024**3)
                    self.log_message(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: {total_gb:.1f}GB æ€»é‡, {available_gb:.1f}GB å¯ç”¨", 'INFO')
                    if available_gb < 1:
                        issues.append(f"å¯ç”¨å†…å­˜è¾ƒå°‘: {available_gb:.1f}GBï¼Œå»ºè®®è‡³å°‘1GB")
                except ImportError:
                    self.log_message("âš ï¸ æ— æ³•æ£€æŸ¥å†…å­˜ä¿¡æ¯ (psutilæœªå®‰è£…)", 'WARNING')
                
                self.root.after(0, self.show_system_issues, issues)
                    
            except Exception as e:
                error_msg = f"ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
                self.log_message(f"âŒ {error_msg}", 'ERROR')
                self.root.after(0, messagebox.showerror, "ç³»ç»Ÿæ£€æŸ¥å¤±è´¥", f"æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:\n{str(e)}")
            
            finally:
                self.root.after(0, self.set_processing, False)

        self.set_processing(True)
        # æäº¤å¼‚æ­¥ä»»åŠ¡åˆ° asyncio äº‹ä»¶å¾ªç¯
        await check_worker_async()
    def show_system_issues(self, issues: List[str]):
        """
        æ˜¾ç¤ºç³»ç»Ÿç¯å¢ƒé—®é¢˜åŠè§£å†³æ–¹æ¡ˆ (å¢å¼ºä¸“ä¸šç‰ˆ)
        - æ™ºèƒ½åˆ†ç±»é—®é¢˜ä¸¥é‡æ€§
        - æä¾›é’ˆå¯¹æ€§çš„è§£å†³æ–¹æ¡ˆå’Œå®‰è£…å‘½ä»¤
        - é›†æˆTesseractè·¯å¾„ä¿®å¤å¼•å¯¼
        """
        if not issues:
            self.status_label.config(text="ç³»ç»Ÿæ£€æŸ¥é€šè¿‡", style='Success.TLabel')
            self.log_message("âœ… ç³»ç»Ÿæ£€æŸ¥å®Œæˆï¼Œç¯å¢ƒä¼˜ç§€", 'SUCCESS')
            # ç³»ç»Ÿæ£€æŸ¥é€šè¿‡åï¼Œè‡ªåŠ¨æç¤ºåˆå§‹åŒ–
            self._prompt_initialize_cvocr_after_check()
            return

        self.status_label.config(text="ç³»ç»Ÿå­˜åœ¨é—®é¢˜", style='Error.TLabel')
        self.log_message(f"âš ï¸ ç³»ç»Ÿæ£€æŸ¥å‘ç° {len(issues)} ä¸ªé—®é¢˜ï¼Œè¯·è§£å†³åé‡è¯•", 'WARNING')

        # --- é—®é¢˜åˆ†ç±» ---
        critical_issues = []
        optional_issues = []
        tesseract_issue = None

        # å…³é”®é˜»å¡æ€§é—®é¢˜å…³é”®è¯
        critical_keywords = ['Tesseractä¸å¯ç”¨', 'pytesseractæœªå®‰è£…', 'OpenCVæœªå®‰è£…', 'Pillowæœªå®‰è£…', 'NumPyæœªå®‰è£…']
        
        for issue in issues:
            if any(keyword in issue for keyword in critical_keywords):
                if 'Tesseract' in issue:
                    tesseract_issue = issue
                else:
                    critical_issues.append(issue)
            else:
                optional_issues.append(issue)

        # --- Tesseract ä¸“é¡¹å¤„ç† ---
        if tesseract_issue:
            # å¦‚æœæ˜¯Tesseracté—®é¢˜ï¼Œä¼˜å…ˆå¼¹å‡ºäº¤äº’å¼ä¿®å¤å¯¹è¯æ¡†
            if messagebox.askyesno("å…³é”®é—®é¢˜ï¼šTesseract OCR æœªæ‰¾åˆ°",
                                     f"ç³»ç»Ÿæ£€æŸ¥å‘ç°ä¸€ä¸ªå…³é”®é—®é¢˜ï¼š\n\n{tesseract_issue}\n\n"
                                     "è¿™æ˜¯æ ¸å¿ƒOCRå¼•æ“ï¼Œç¼ºå°‘å®ƒç¨‹åºå°†æ— æ³•å·¥ä½œã€‚\n"
                                     "è¿™é€šå¸¸æ˜¯å› ä¸ºTesseractæœªå®‰è£…ï¼Œæˆ–å…¶è·¯å¾„æœªåœ¨ç³»ç»Ÿç¯å¢ƒä¸­ã€‚\n\n"
                                     "æ˜¯å¦éœ€è¦ç«‹å³æ‰‹åŠ¨é€‰æ‹© `tesseract.exe` æ–‡ä»¶æ¥ä¿®å¤æ­¤é—®é¢˜ï¼Ÿ"):
                self._browse_for_tesseract()
                # å¼•å¯¼ç”¨æˆ·ä¿®å¤åï¼Œä¸å†æ˜¾ç¤ºé€šç”¨é”™è¯¯çª—å£ï¼Œå› ä¸ºä¿®å¤åä¼šè‡ªåŠ¨é‡æ–°æ£€æŸ¥
                return
        
        # --- åˆ›å»ºè¯¦ç»†é—®é¢˜æŠ¥å‘Šçª—å£ ---
        issue_window = tk.Toplevel(self.root)
        issue_window.title("CVOCR ç³»ç»Ÿç¯å¢ƒæŠ¥å‘Š")
        issue_window.geometry("850x650")
        issue_window.minsize(700, 500)
        issue_window.transient(self.root)
        issue_window.grab_set()
        
        main_frame = ttk.Frame(issue_window, padding=design.get_spacing('6'))
        main_frame.pack(fill='both', expand=True)
        
        # --- çª—å£å†…å®¹ ---
        title_label = tk.Label(main_frame, text="ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š", bg=design.get_color('neutral', '50'))
        design.apply_text_style(title_label, 'h2')
        title_label.pack(anchor='w', pady=(0, design.get_spacing('4')))
        
        notebook = ttk.Notebook(main_frame)
        notebook.pack(fill='both', expand=True, pady=design.get_spacing('4'))

        # --- è§£å†³æ–¹æ¡ˆæ ‡ç­¾é¡µ ---
        solution_tab = ttk.Frame(notebook, padding=design.get_spacing('4'))
        notebook.add(solution_tab, text="ğŸ’¡ è§£å†³æ–¹æ¡ˆ")
        
        solution_text = scrolledtext.ScrolledText(solution_tab, wrap='word', height=20, 
                                                                                                    font=design.get_font('body'),
                                                  bg=design.get_color('neutral', '0'),
                                                  fg=design.get_color('neutral', '800'))
        solution_text.pack(fill='both', expand=True)

        solution_content = []
        
        def add_solution(title, description, commands=None):
            solution_content.append(f"ğŸ“Œ {title}\n")
            solution_content.append(f"   {description}\n")
            if commands:
                solution_content.append("   è§£å†³æ–¹æ¡ˆ:\n")
                for cmd_desc, cmd in commands:
                    solution_content.append(f"     â€¢ {cmd_desc}:\n       `{cmd}`\n")
            solution_content.append("-" * 60 + "\n")

        # ç”ŸæˆåŠ¨æ€è§£å†³æ–¹æ¡ˆ
        if tesseract_issue:
            add_solution("Tesseract OCR å¼•æ“ä¸å¯ç”¨ (å…³é”®)",
                         "è¿™æ˜¯æ‰§è¡ŒOCRçš„æ ¸å¿ƒç»„ä»¶ï¼Œå¿…é¡»å®‰è£…å¹¶é…ç½®ã€‚",
                         [("Windows (æ¨è)", "è®¿é—® https://github.com/UB-Mannheim/tesseract/wiki ä¸‹è½½å¹¶å®‰è£…"),
                          ("macOS (ä½¿ç”¨Homebrew)", "brew install tesseract tesseract-lang"),
                          ("Ubuntu/Debian", "sudo apt update && sudo apt install tesseract-ocr tesseract-ocr-chi-sim tesseract-ocr-eng")])
        
        for issue in critical_issues:
            if 'pytesseract' in issue:
                add_solution("Python Tesseract æ¥å£æœªå®‰è£… (å…³é”®)",
                             "ç¼ºå°‘è¿æ¥Pythonä¸Tesseractå¼•æ“çš„æ¡¥æ¢ã€‚",
                             [("å®‰è£…å‘½ä»¤", "pip install pytesseract")])
            elif 'OpenCV' in issue:
                add_solution("OpenCV åº“æœªå®‰è£… (å…³é”®)",
                             "æ ¸å¿ƒå›¾åƒå¤„ç†åº“ï¼Œç”¨äºè¯»å–ã€æ“ä½œå’Œæ˜¾ç¤ºå›¾åƒã€‚",
                             [("å®‰è£…å‘½ä»¤", "pip install opencv-python")])
            elif 'Pillow' in issue:
                add_solution("Pillow (PIL) åº“æœªå®‰è£… (å…³é”®)",
                             "åŸºç¡€å›¾åƒå¤„ç†åº“ï¼Œç”¨äºä¸Tkinteräº¤äº’ã€‚",
                             [("å®‰è£…å‘½ä»¤", "pip install Pillow")])
            elif 'NumPy' in issue:
                add_solution("NumPy åº“æœªå®‰è£… (å…³é”®)",
                             "Pythonç§‘å­¦è®¡ç®—çš„åŸºç¡€åº“ï¼Œå›¾åƒå¤„ç†ä¾èµ–å®ƒã€‚",
                             [("å®‰è£…å‘½ä»¤", "pip install numpy")])

        if optional_issues:
            solution_content.append("\n=== å¯é€‰åŠŸèƒ½ä¾èµ–é—®é¢˜ ===\n")
            solution_content.append("ä»¥ä¸‹é—®é¢˜ä¸å½±å“æ ¸å¿ƒOCRåŠŸèƒ½ï¼Œä½†ä¼šä½¿é«˜çº§AIå¢å¼ºç‰¹æ€§ä¸å¯ç”¨ã€‚\n\n")

            for issue in optional_issues:
                if 'Transformers' in issue:
                    add_solution("Transformers åº“æœªå®‰è£… (å¯é€‰)",
                                 "ç”¨äºLayoutLMv2å¸ƒå±€åˆ†æå’ŒGPT-Neoä¸Šä¸‹æ–‡çº é”™ã€‚",
                                 [("å®‰è£…å‘½ä»¤", "pip install transformers")])
                elif 'PyTorch' in issue:
                    add_solution("PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶æœªå®‰è£… (å¯é€‰)",
                                 "Transformersåº“ä¾èµ–æ­¤æ¡†æ¶è¿è¡Œã€‚",
                                 [("CPUç‰ˆæœ¬ (æ¨è)", "pip install torch torchvision torchaudio"),
                                  ("NVIDIA GPUç‰ˆæœ¬ (CUDA 11.8)", "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")])
                elif 'ç‰ˆæœ¬è¿‡ä½' in issue:
                    lib_name = issue.split('ç‰ˆæœ¬è¿‡ä½')[0].strip()
                    add_solution(f"{lib_name} ç‰ˆæœ¬è¿‡ä½ (å»ºè®®å‡çº§)",
                                 f"å½“å‰ç‰ˆæœ¬å¯èƒ½å­˜åœ¨å…¼å®¹æ€§é—®é¢˜æˆ–ç¼ºå°‘å¿…è¦åŠŸèƒ½ã€‚",
                                 [("å‡çº§å‘½ä»¤", f"pip install --upgrade {lib_name.lower()}")])
                elif 'å¯ç”¨å†…å­˜è¾ƒå°‘' in issue: # æ·»åŠ psutilæ£€æµ‹åˆ°çš„å†…å­˜é—®é¢˜è§£å†³æ–¹æ¡ˆ
                    add_solution("å¯ç”¨å†…å­˜ä¸è¶³ (å»ºè®®)",
                                 "ç³»ç»Ÿå¯ç”¨å†…å­˜å¯èƒ½ä¸è¶³ä»¥è¿è¡Œæ‰€æœ‰é«˜çº§OCRæ¨¡å‹ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™æˆ–å´©æºƒã€‚",
                                 [("å»ºè®®", "å…³é—­ä¸å¿…è¦çš„åº”ç”¨ç¨‹åºï¼Œæˆ–è€ƒè™‘å‡çº§ç³»ç»Ÿå†…å­˜ã€‚")])


        solution_text.insert(1.0, "".join(solution_content))
        solution_text.config(state='disabled')

        # --- å®Œæ•´é—®é¢˜åˆ—è¡¨æ ‡ç­¾é¡µ ---
        issues_tab = ttk.Frame(notebook, padding=design.get_spacing('4'))
        notebook.add(issues_tab, text=f"ğŸ“‹ é—®é¢˜åˆ—è¡¨ ({len(issues)})")
        
        issues_list_text = scrolledtext.ScrolledText(issues_tab, wrap='word', height=20,
                                                     font=design.get_font('body'),
                                                     bg=design.get_color('neutral', '0'),
                                                     fg=design.get_color('neutral', '800'))
        issues_list_text.pack(fill='both', expand=True)
        
        full_issues_content = "æ£€æµ‹åˆ°çš„æ‰€æœ‰ç¯å¢ƒé—®é¢˜ï¼š\n\n"
        for i, issue in enumerate(issues, 1):
            full_issues_content += f"{i}. {issue}\n"
        issues_list_text.insert(1.0, full_issues_content)
        issues_list_text.config(state='disabled')

        # --- åº•éƒ¨æŒ‰é’®åŒºåŸŸ ---
        btn_frame = ttk.Frame(main_frame)
        btn_frame.pack(fill='x', pady=(design.get_spacing('4'), 0))

        def copy_solutions_to_clipboard():
            try:
                self.root.clipboard_clear()
                self.root.clipboard_append(solution_text.get(1.0, tk.END))
                self.log_message("ğŸ“‹ è§£å†³æ–¹æ¡ˆå·²å¤åˆ¶åˆ°å‰ªè´´æ¿", 'SUCCESS')
            except Exception as e:
                messagebox.showerror("å¤åˆ¶å¤±è´¥", f"æ— æ³•å¤åˆ¶å†…å®¹: {e}")

        btn_copy = tk.Button(btn_frame, text="ğŸ“‹ å¤åˆ¶è§£å†³æ–¹æ¡ˆ", command=copy_solutions_to_clipboard)
        design.apply_button_style(btn_copy, 'secondary')
        btn_copy.pack(side='left')

        btn_retry = tk.Button(btn_frame, text="ğŸ”„ é‡æ–°æ£€æŸ¥", 
                              command=lambda: (issue_window.destroy(), self.check_system()))
        design.apply_button_style(btn_retry, 'primary')
        btn_retry.pack(side='right')
        
        btn_close_issue = tk.Button(btn_frame, text="å…³é—­", command=issue_window.destroy)
        design.apply_button_style(btn_close_issue, 'secondary')
        btn_close_issue.pack(side='right', padx=design.get_spacing('2'))

    def _browse_for_tesseract(self):
        """æ‰“å¼€æ–‡ä»¶å¯¹è¯æ¡†è®©ç”¨æˆ·é€‰æ‹©tesseract.exe"""
        self.log_message("ğŸ” æ­£åœ¨ç­‰å¾…ç”¨æˆ·é€‰æ‹© Tesseract.exe...", 'INFO')
        
        filetypes = [("Tesseract å¯æ‰§è¡Œæ–‡ä»¶", "tesseract.exe"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")] if sys.platform == "win32" else [("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        
        tesseract_path = filedialog.askopenfilename(
            title="è¯·é€‰æ‹© tesseract.exe æ–‡ä»¶",
            filetypes=filetypes
        )
        
        if tesseract_path:
            success, msg = self.cvocr_manager.set_tesseract_path(tesseract_path)
            if success:
                self.settings['tesseract_path'].set(tesseract_path)
                self._save_settings()  # ä¿å­˜è®¾ç½®ä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨
                self.log_message(f"âœ… Tesseractè·¯å¾„å·²æˆåŠŸè®¾ç½®å¹¶ä¿å­˜ã€‚", 'SUCCESS')
                messagebox.showinfo("è®¾ç½®æˆåŠŸ",
                                    f"Tesseract è·¯å¾„å·²æˆåŠŸè®¾ç½®ä¸º:\n{tesseract_path}\n\n"
                                    "è®¾ç½®å·²ä¿å­˜ã€‚æ­£åœ¨é‡æ–°æ£€æŸ¥ç³»ç»ŸçŠ¶æ€...")
                # é‡æ–°è¿›è¡Œç³»ç»Ÿæ£€æŸ¥ä»¥ç¡®è®¤
                self.check_system()
            else:
                self.log_message(f"âŒ è®¾ç½®Tesseractè·¯å¾„å¤±è´¥: {msg}", 'ERROR')
                messagebox.showerror("è®¾ç½®å¤±è´¥", f"è®¾ç½®Tesseractè·¯å¾„å¤±è´¥: {msg}")
    
    def _prompt_initialize_cvocr_after_check(self):
        """ç³»ç»Ÿæ£€æŸ¥åæç¤ºåˆå§‹åŒ–CVOCR"""
        if self.cvocr_manager.is_initialized:
            return

        if messagebox.askyesno("CVOCRå¼•æ“åˆå§‹åŒ–", 
                                "ç³»ç»Ÿæ£€æŸ¥å®Œæˆã€‚æ˜¯å¦ç«‹å³åˆå§‹åŒ–CVOCRå¼•æ“ï¼Ÿ\n"
                                "é¦–æ¬¡åˆå§‹åŒ–å¯èƒ½éœ€è¦ä¸‹è½½è¯­è¨€åŒ…ï¼Œè¯·ç¡®ä¿ç½‘ç»œç•…é€šã€‚"):
            self.initialize_cvocr()
    
    def select_image(self):
        """
        é€‰æ‹©å›¾ç‰‡æ–‡ä»¶ï¼Œå¹¶è¿›è¡ŒéªŒè¯ã€‚
        (V4.3 - ç¼“å­˜æ¸…é™¤ç‰ˆ): é€‰æ‹©æ–°å›¾ç‰‡æ—¶ï¼Œä¼šè‡ªåŠ¨æ¸…é™¤ä¸Šä¸€å¼ å›¾ç‰‡çš„é¢„å¤„ç†ç¼“å­˜ï¼Œ
        ä»¥ç¡®ä¿åç»­é¢„è§ˆåŠŸèƒ½ï¼ˆå¦‚åˆ†å‰²é¢„è§ˆï¼‰ä½¿ç”¨çš„æ˜¯å½“å‰å›¾ç‰‡çš„æœ€æ–°é¢„å¤„ç†ç»“æœã€‚
        """
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
            filetypes=[
                ("æ‰€æœ‰æ”¯æŒçš„å›¾ç‰‡", "*.jpg *.jpeg *.png *.bmp *.tiff *.tif *.webp *.gif"),
                ("JPEGæ–‡ä»¶", "*.jpg *.jpeg"),
                ("PNGæ–‡ä»¶", "*.png"),
                ("BMPæ–‡ä»¶", "*.bmp"),
                ("TIFFæ–‡ä»¶", "*.tiff *.tif"),
                ("WebPæ–‡ä»¶", "*.webp"),
                ("GIFæ–‡ä»¶", "*.gif"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        if file_path:
            # ä½¿ç”¨å¢å¼ºçš„å›¾åƒéªŒè¯æ–¹æ³•
            valid, message = AdvancedTextImageProcessor.validate_image(file_path)
            if not valid:
                self.log_message(f"âŒ å›¾ç‰‡éªŒè¯å¤±è´¥: {message}", 'ERROR')
                messagebox.showerror("å›¾ç‰‡æ— æ•ˆ", f"é€‰æ‹©çš„æ–‡ä»¶æ— æ•ˆ:\n{message}")
                return
            
            self.current_image_path = file_path
            
            # --- å…³é”®ä¿®æ­£ï¼šæ¸…é™¤æ—§çš„é¢„å¤„ç†ç¼“å­˜ ---
            self._cached_preprocessed_image = None
            self.log_message("æ–°å›¾ç‰‡å·²é€‰æ‹©ï¼Œé¢„å¤„ç†ç¼“å­˜å·²æ¸…é™¤ã€‚", "DEBUG")
            # --- ä¿®æ­£ç»“æŸ ---

            self.display_image(file_path)
            
            # è·å–å¹¶æ˜¾ç¤ºè¯¦ç»†çš„å›¾ç‰‡ä¿¡æ¯
            try:
                with Image.open(file_path) as img:
                    width, height = img.size
                    mode = img.mode
                    file_size = os.path.getsize(file_path) / 1024
                    
                    info_text = f"æ–‡ä»¶: {os.path.basename(file_path)} | å°ºå¯¸: {width}x{height} | æ¨¡å¼: {mode} | å¤§å°: {file_size:.1f}KB"
                    self.image_info_label.config(text=info_text)

                self.log_message(f"âœ… å·²é€‰æ‹©å›¾ç‰‡: {os.path.basename(file_path)}", 'SUCCESS')
            except Exception as e:
                self.log_message(f"âŒ è¯»å–å›¾ç‰‡ä¿¡æ¯å¤±è´¥: {e}", 'ERROR')


    def select_batch_images(self):
        """é€‰æ‹©å¤šä¸ªå›¾ç‰‡æ–‡ä»¶è¿›è¡Œæ‰¹é‡å¤„ç†"""
        file_paths = filedialog.askopenfilenames(
            title="é€‰æ‹©å¤šä¸ªå›¾ç‰‡æ–‡ä»¶",
            filetypes=[
                ("æ‰€æœ‰æ”¯æŒçš„å›¾ç‰‡", "*.jpg *.jpeg *.png *.bmp *.tiff *.tif *.webp *.gif"),
                ("JPEGæ–‡ä»¶", "*.jpg *.jpeg"),
                ("PNGæ–‡ä»¶", "*.png"),
                ("BMPæ–‡ä»¶", "*.bmp"),
                ("TIFFæ–‡ä»¶", "*.tiff *.tif"),
                ("WebPæ–‡ä»¶", "*.webp"),
                ("GIFæ–‡ä»¶", "*.gif"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )

        if file_paths:
            # éªŒè¯æ‰€æœ‰å›¾ç‰‡
            valid_files = []
            for path in file_paths:
                valid, message = AdvancedTextImageProcessor.validate_image(path)
                if valid:
                    valid_files.append(path)
                else:
                    self.log_message(f"âš ï¸ æ‰¹é‡é€‰æ‹©ä¸­è·³è¿‡æ— æ•ˆå›¾ç‰‡ '{os.path.basename(path)}': {message}", 'WARNING')
            
            if not valid_files:
                messagebox.showwarning("æ— æœ‰æ•ˆå›¾ç‰‡", "æ‰€é€‰æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡å¯ç”¨äºæ‰¹é‡å¤„ç†ã€‚")
                self.log_message("âŒ æ‰¹é‡å¤„ç†ï¼šæ²¡æœ‰é€‰æ‹©åˆ°ä»»ä½•æœ‰æ•ˆå›¾ç‰‡ã€‚", 'ERROR')
                return

            self.batch_image_paths = valid_files
            self.log_message(f"âœ… å·²é€‰æ‹© {len(valid_files)} å¼ å›¾ç‰‡è¿›è¡Œæ‰¹é‡å¤„ç†ã€‚", 'SUCCESS')
            self.settings['batch_processing'].set(True) # è‡ªåŠ¨åˆ‡æ¢åˆ°æ‰¹é‡å¤„ç†æ¨¡å¼
            
            # å°è¯•åœ¨å›¾åƒé¢„è§ˆåŒºæ˜¾ç¤ºç¬¬ä¸€å¼ å›¾ç‰‡
            if self.batch_image_paths:
                self.current_image_path = self.batch_image_paths[0]
                self.display_image(self.current_image_path)
                self.image_info_label.config(text=f"æ‰¹é‡å¤„ç†æ¨¡å¼ | å·²åŠ è½½ {len(self.batch_image_paths)} å¼ å›¾ç‰‡")
            self.notebook.select(self.notebook.index("end") - 1) # åˆ‡æ¢åˆ°å†å²è®°å½•æˆ–ç»Ÿè®¡é¡µ
            self.notebook.select(self.notebook.index("end") - 2) # åˆ‡æ¢åˆ°å†å²è®°å½•æˆ–ç»Ÿè®¡é¡µ
            messagebox.showinfo("æ‰¹é‡å¤„ç†", f"å·²é€‰æ‹© {len(valid_files)} å¼ å›¾ç‰‡ï¼Œç‚¹å‡» 'æ‰¹é‡å¤„ç†' æŒ‰é’®å¼€å§‹ã€‚")

    def display_image(self, image_path: str, text_blocks: Optional[List[Dict]] = None, shape_blocks: Optional[List[Dict]] = None):
        """
        åœ¨Canvasä¸Šæ˜¾ç¤ºå›¾åƒï¼Œå¹¶æ ¹æ®éœ€è¦ç²¾ç¡®ç»˜åˆ¶æ–‡æœ¬å’Œå›¾å½¢çš„è¾¹ç•Œæ¡†ã€‚
        - ä¿æŒå›¾åƒçš„åŸå§‹çºµæ¨ªæ¯”è¿›è¡Œç¼©æ”¾ã€‚
        - å°†ç¼©æ”¾åçš„å›¾åƒåœ¨ç”»å¸ƒä¸­å±…ä¸­æ˜¾ç¤ºã€‚
        - å­˜å‚¨åæ ‡è½¬æ¢å‚æ•°ï¼Œä»¥ä¾¿åç»­åŠŸèƒ½ï¼ˆå¦‚é«˜äº®ï¼‰ä½¿ç”¨ã€‚
        - ä¸ºæ–‡æœ¬å’Œå›¾å½¢ç»˜åˆ¶ä¸åŒæ ·å¼çš„è¾¹ç•Œæ¡†ã€‚

        Args:
            image_path (str): è¦æ˜¾ç¤ºçš„å›¾åƒæ–‡ä»¶çš„å®Œæ•´è·¯å¾„ã€‚
            text_blocks (Optional[List[Dict]]): åŒ…å«å·²è¯†åˆ«æ–‡æœ¬å—åŠå…¶è¾¹ç•Œæ¡†çš„åˆ—è¡¨ã€‚
            shape_blocks (Optional[List[Dict]]): åŒ…å«å·²æ£€æµ‹å›¾å½¢åŠå…¶è¾¹ç•Œæ¡†çš„åˆ—è¡¨ã€‚
        """
        try:
            # 1. éªŒè¯æ–‡ä»¶è·¯å¾„
            if not os.path.exists(image_path):
                self.log_message(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}", 'ERROR')
                self.image_canvas.delete("all")
                return

            # 2. åŠ è½½åŸå§‹å›¾åƒå¹¶æ¸…ç©ºç”»å¸ƒ
            original_img = Image.open(image_path)
            self.image_canvas.delete("all")

            # 3. å­˜å‚¨å…³é”®çš„åŸå§‹å°ºå¯¸ä¿¡æ¯
            self._last_original_image_size = original_img.size
            img_width, img_height = self._last_original_image_size

            # 4. è·å–ç”»å¸ƒå°ºå¯¸
            canvas_width = self.image_canvas.winfo_width()
            canvas_height = self.image_canvas.winfo_height()

            # å¦‚æœç”»å¸ƒå°šæœªæ¸²æŸ“ï¼ˆå°ºå¯¸ä¸º0æˆ–1ï¼‰ï¼Œåˆ™ä¸­æ­¢ç»˜åˆ¶ä»¥é¿å…é”™è¯¯
            if canvas_width <= 1 or canvas_height <= 1:
                return

            # 5. è®¡ç®—ç¼©æ”¾æ¯”ä¾‹å’Œåç§»é‡ä»¥ä¿æŒçºµæ¨ªæ¯”å¹¶å±…ä¸­
            # åˆ†åˆ«è®¡ç®—æ°´å¹³å’Œå‚ç›´æ–¹å‘çš„ç¼©æ”¾æ¯”ä¾‹
            scale_ratio_x = canvas_width / img_width
            scale_ratio_y = canvas_height / img_height

            # é€‰æ‹©è¾ƒå°çš„æ¯”ä¾‹ä½œä¸ºæœ€ç»ˆçš„ç»Ÿä¸€ç¼©æ”¾å› å­ï¼Œä»¥ç¡®ä¿æ•´ä¸ªå›¾åƒéƒ½èƒ½è¢«å®¹çº³
            final_scale_ratio = min(scale_ratio_x, scale_ratio_y)

            # è®¡ç®—ç¼©æ”¾åçš„æ˜¾ç¤ºå°ºå¯¸
            display_width = int(img_width * final_scale_ratio)
            display_height = int(img_height * final_scale_ratio)
            
            # è®¡ç®—ä¸ºäº†åœ¨ç”»å¸ƒä¸­å±…ä¸­è€Œäº§ç”Ÿçš„å·¦ä¸Šè§’åç§»é‡
            x_offset = (canvas_width - display_width) // 2
            y_offset = (canvas_height - display_height) // 2
            
            # 6. å­˜å‚¨è¿™äº›è½¬æ¢å‚æ•°ï¼Œä»¥ä¾¿åç»­åŠŸèƒ½ï¼ˆå¦‚é«˜äº®ã€ç‚¹å‡»ç­‰ï¼‰å¯ä»¥å¤ç”¨
            self._last_display_scale_ratio_x = final_scale_ratio
            self._last_display_scale_ratio_y = final_scale_ratio
            self._last_display_x_offset = x_offset
            self._last_display_y_offset = y_offset

            # 7. ç¼©æ”¾å›¾åƒå¹¶æ˜¾ç¤º
            # ä½¿ç”¨LANCZOSï¼ˆæŠ—é”¯é½¿ï¼‰ç®—æ³•ä»¥è·å¾—æœ€ä½³çš„å›¾åƒç¼©å°è´¨é‡
            resized_img = original_img.resize((display_width, display_height), Image.Resampling.LANCZOS)
            self.photo = ImageTk.PhotoImage(resized_img)
            self.image_canvas.create_image(x_offset, y_offset, image=self.photo, anchor='nw', tags="image")
            
            # 8. ç»˜åˆ¶æ–‡æœ¬å—çš„è¾¹ç•Œæ¡†ï¼ˆçº¢è‰²ï¼‰
            if text_blocks:
                for block in text_blocks:
                    bbox = block.get('bbox')
                    # ç¡®ä¿bboxå­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
                    if not bbox or len(bbox) != 4:
                        continue
                    
                    # è·å–åŸå§‹åæ ‡
                    x1_orig, y1_orig, x2_orig, y2_orig = bbox
                    
                    # åº”ç”¨ç¼©æ”¾å’Œåç§»ï¼Œè®¡ç®—å‡ºåœ¨Canvasä¸Šçš„æœ€ç»ˆåæ ‡
                    x1_canvas = int(x1_orig * self._last_display_scale_ratio_x + x_offset)
                    y1_canvas = int(y1_orig * self._last_display_scale_ratio_y + y_offset)
                    x2_canvas = int(x2_orig * self._last_display_scale_ratio_x + x_offset)
                    y2_canvas = int(y2_orig * self._last_display_scale_ratio_y + y_offset)
                    
                    # ç»˜åˆ¶ä¸å›¾åƒä¸Šæ–‡å­—å®Œç¾å¯¹é½çš„çŸ©å½¢æ¡†
                    self.image_canvas.create_rectangle(
                        x1_canvas, y1_canvas, x2_canvas, y2_canvas, 
                        outline='red', width=2, tags=("bbox", "text_bbox")
                    )

            # 9. ç»˜åˆ¶å›¾å½¢çš„è¾¹ç•Œæ¡†ï¼ˆç»¿è‰²ï¼Œæ›´ç²—ï¼‰
            if shape_blocks:
                for block in shape_blocks:
                    bbox = block.get('bbox')
                    if not bbox or len(bbox) != 4:
                        continue
                    
                    x1_orig, y1_orig, x2_orig, y2_orig = bbox
                    
                    x1_canvas = int(x1_orig * self._last_display_scale_ratio_x + x_offset)
                    y1_canvas = int(y1_orig * self._last_display_scale_ratio_y + y_offset)
                    x2_canvas = int(x2_orig * self._last_display_scale_ratio_x + x_offset)
                    y2_canvas = int(y2_orig * self._last_display_scale_ratio_y + y_offset)

                    self.image_canvas.create_rectangle(
                        x1_canvas, y1_canvas, x2_canvas, y2_canvas, 
                        outline='green', width=3, tags=("bbox", "shape_bbox")
                    )

            # 10. æ›´æ–°ç”»å¸ƒçš„æ»šåŠ¨åŒºåŸŸä»¥åŒ…å«æ‰€æœ‰ç»˜åˆ¶çš„å†…å®¹
            self.image_canvas.config(scrollregion=self.image_canvas.bbox("all"))

            # å¼ºåˆ¶Tkinterç«‹å³æ›´æ–°ç•Œé¢
            self.root.update_idletasks()

        except Exception as e:
            # æ•è·æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸ï¼Œå¦‚æ–‡ä»¶æŸåã€å†…å­˜ä¸è¶³ç­‰
            self.log_message(f"âŒ æ˜¾ç¤ºå›¾åƒæˆ–ç»˜åˆ¶è¾¹ç•Œæ¡†æ—¶å¤±è´¥: {e}", 'ERROR')
            # æ‰“å°å®Œæ•´çš„å †æ ˆè·Ÿè¸ªä»¥æ–¹ä¾¿è°ƒè¯•
            traceback.print_exc()
    
    
    def reload_image(self):
        """é‡æ–°åŠ è½½å½“å‰å›¾ç‰‡"""
        if self.current_image_path:
            self.display_image(self.current_image_path)
            self.log_message(f"âœ… å·²é‡æ–°åŠ è½½å›¾ç‰‡: {os.path.basename(self.current_image_path)}", 'SUCCESS')
        else:
            self.log_message("âš ï¸ æ²¡æœ‰å›¾ç‰‡å¯ä¾›é‡æ–°åŠ è½½ã€‚", 'WARNING')

    def show_in_explorer(self):
        """åœ¨æ–‡ä»¶æµè§ˆå™¨ä¸­æ˜¾ç¤ºå½“å‰å›¾ç‰‡"""
        if self.current_image_path and os.path.exists(self.current_image_path):
            try:
                if platform.system() == "Windows":
                    os.startfile(os.path.dirname(self.current_image_path))
                elif platform.system() == "Darwin":  # macOS
                    subprocess.Popen(["open", os.path.dirname(self.current_image_path)])
                else:  # Linux
                    subprocess.Popen(["xdg-open", os.path.dirname(self.current_image_path)])
                self.log_message(f"ğŸ“ å·²åœ¨æ–‡ä»¶æµè§ˆå™¨ä¸­æ‰“å¼€: {os.path.dirname(self.current_image_path)}", 'INFO')
            except Exception as e:
                self.log_message(f"âŒ æ— æ³•æ‰“å¼€æ–‡ä»¶æµè§ˆå™¨: {e}", 'ERROR')
                messagebox.showerror("é”™è¯¯", f"æ— æ³•åœ¨æ–‡ä»¶æµè§ˆå™¨ä¸­æ‰“å¼€è·¯å¾„:\n{e}")
        else:
            self.log_message("âš ï¸ æ²¡æœ‰å›¾ç‰‡è·¯å¾„æˆ–æ–‡ä»¶ä¸å­˜åœ¨ã€‚", 'WARNING')

    def show_image_info(self):
        """æ˜¾ç¤ºå½“å‰å›¾ç‰‡è¯¦ç»†ä¿¡æ¯"""
        if not self.current_image_path or not os.path.exists(self.current_image_path):
            messagebox.showinfo("å›¾ç‰‡ä¿¡æ¯", "æœªé€‰æ‹©å›¾ç‰‡æˆ–å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
            return

        try:
            with Image.open(self.current_image_path) as img:
                width, height = img.size
                mode = img.mode
                file_size_bytes = os.path.getsize(self.current_image_path)
                file_size_mb = file_size_bytes / (1024 * 1024)
                file_ext = os.path.splitext(self.current_image_path)[1].lower()
                
                info_content = (
                    f"æ–‡ä»¶å: {os.path.basename(self.current_image_path)}\n"
                    f"å®Œæ•´è·¯å¾„: {self.current_image_path}\n"
                    f"å›¾ç‰‡å°ºå¯¸: {width} x {height} åƒç´ \n"
                    f"é¢œè‰²æ¨¡å¼: {mode}\n"
                    f"æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB ({file_size_bytes} å­—èŠ‚)\n"
                    f"æ–‡ä»¶ç±»å‹: {file_ext.upper()}\n"
                    f"ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(os.path.getmtime(self.current_image_path)).strftime('%Y-%m-%d %H:%M:%S')}\n"
                )
                
                # æ·»åŠ é¢„å¤„ç†å™¨çš„è´¨é‡è¯„ä¼°ä¿¡æ¯
                _, _, metadata = self.image_processor.intelligent_preprocess_image(
                    self.current_image_path, enable_preprocessing=True # å¼ºåˆ¶è¯„ä¼°
                )
                if metadata and 'quality_metrics' in metadata:
                    info_content += "\n--- å›¾åƒè´¨é‡è¯„ä¼° ---\n"
                    quality_metrics = metadata['quality_metrics']
                    for key, value in quality_metrics.items():
                        info_content += f"{key.replace('_', ' ').title()}: {value:.2f}\n"
                    info_content += f"è´¨é‡ç­‰çº§: {metadata.get('quality_level', 'N/A')}\n"
                    info_content += f"æ€»è´¨é‡åˆ†æ•°: {metadata.get('quality_score', 0):.2f}\n"

                messagebox.showinfo("å›¾ç‰‡è¯¦ç»†ä¿¡æ¯", info_content)
                self.log_message(f"ğŸ“‹ å·²æ˜¾ç¤ºå›¾ç‰‡ '{os.path.basename(self.current_image_path)}' çš„è¯¦ç»†ä¿¡æ¯ã€‚", 'INFO')

        except Exception as e:
            self.log_message(f"âŒ è·å–å›¾ç‰‡è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}", 'ERROR')
            messagebox.showerror("é”™è¯¯", f"è·å–å›¾ç‰‡è¯¦ç»†ä¿¡æ¯å¤±è´¥:\n{e}")
    def _get_enabled_segmentation_algorithms(self) -> List[str]:
        """æ”¶é›†æ‰€æœ‰å½“å‰å¯ç”¨çš„é«˜çº§åˆ†å‰²ç®—æ³•åç§°"""
        enabled_algos = []
        for key, var in self.settings.items():
            if key.startswith('seg_') and var.get():
                # å°† 'seg_improved_mser' è½¬æ¢ä¸º 'improved_mser'
                algo_name = key.replace('seg_', '')
                enabled_algos.append(algo_name)
        return enabled_algos
    def start_enhanced_recognition(self):
        """
        å¼€å§‹å¢å¼ºæ–‡æœ¬è¯†åˆ« (V4.2 - GUIå‚æ•°å®Œå…¨åŒæ­¥æœ€ç»ˆç‰ˆ)ã€‚
        æ­¤æ–¹æ³•ä½œä¸ºç”¨æˆ·ç‚¹å‡»â€œå¼€å§‹è¯†åˆ«â€æŒ‰é’®çš„å…¥å£ï¼Œè´Ÿè´£ï¼š
        1. æ‰§è¡Œæ‰€æœ‰å‰ç½®æ£€æŸ¥ï¼ˆå¦‚å¤„ç†çŠ¶æ€ã€å¼•æ“åˆå§‹åŒ–ã€å›¾ç‰‡é€‰æ‹©ï¼‰ã€‚
        2. å…¨é¢æ”¶é›†GUIç•Œé¢ä¸Šæ‰€æœ‰ç›¸å…³çš„è®¾ç½®ï¼ŒåŒ…æ‹¬æ‰€æœ‰é¢„å¤„ç†å¼€å…³å’Œé«˜çº§åˆ†å‰²æŠ€æœ¯é€‰é¡¹ã€‚
        3. å°†è¿™äº›è®¾ç½®æ›´æ–°åˆ°åç«¯çš„ CVOCRManager å®ä¾‹ä¸­ã€‚
        4. åˆ›å»ºå¹¶è°ƒåº¦ä¸€ä¸ªå¼‚æ­¥çš„è¯†åˆ«ä»»åŠ¡ï¼Œä»¥é¿å…é˜»å¡GUIã€‚
        """
        # --- æ­¥éª¤ 1: æ‰§è¡Œæ‰€æœ‰å‰ç½®æ£€æŸ¥ ---
        if self.processing:
            messagebox.showwarning("å¤„ç†ä¸­", "å½“å‰æ­£åœ¨è¿›è¡Œè¯†åˆ«æˆ–æ‰¹é‡å¤„ç†ï¼Œè¯·ç¨å€™ã€‚")
            return
        
        if not self.cvocr_manager.is_initialized:
            if messagebox.askyesno("CVOCRå¼•æ“æœªåˆå§‹åŒ–", "CVOCRå¼•æ“å°šæœªåˆå§‹åŒ–ã€‚æ˜¯å¦ç«‹å³åˆå§‹åŒ–ï¼Ÿ"):
                self.initialize_cvocr()
            else:
                self.log_message("âŒ è¯†åˆ«æ“ä½œå–æ¶ˆï¼šCVOCRå¼•æ“æœªåˆå§‹åŒ–ã€‚", 'ERROR')
                return

        if not self.current_image_path:
            messagebox.showwarning("æœªé€‰æ‹©å›¾ç‰‡", "è¯·å…ˆé€‰æ‹©ä¸€å¼ å›¾ç‰‡ã€‚")
            self.log_message("âŒ è¯†åˆ«æ“ä½œå–æ¶ˆï¼šæœªé€‰æ‹©å›¾ç‰‡ã€‚", 'ERROR')
            return
        
        if not os.path.exists(self.current_image_path):
            messagebox.showerror("å›¾ç‰‡ä¸å­˜åœ¨", f"å›¾ç‰‡æ–‡ä»¶ '{self.current_image_path}' ä¸å­˜åœ¨ã€‚")
            self.log_message("âŒ è¯†åˆ«æ“ä½œå–æ¶ˆï¼šå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ã€‚", 'ERROR')
            return

        # --- æ­¥éª¤ 2: è®¾ç½®å¤„ç†çŠ¶æ€å¹¶è®°å½•æ—¥å¿— ---
        self.set_processing(True)
        self.log_message(f"ğŸš€ å¼€å§‹è¯†åˆ«å›¾ç‰‡: {os.path.basename(self.current_image_path)}", 'INFO')
        
        # --- æ­¥éª¤ 3: å…¨é¢æ”¶é›†GUIè®¾ç½®å¹¶æ›´æ–°åç«¯ç®¡ç†å™¨ ---
        language_str = self.settings['language'].get()
        language = OCRLanguage(language_str) if language_str != 'auto' else OCRLanguage.AUTO
        enable_preprocessing = self.settings['enable_preprocessing'].get()
        use_gpu = self.settings['use_gpu'].get()

        self.cvocr_manager.config.update({
            # OCRæ ¸å¿ƒå‚æ•°
            'language': language.value,
            'psm': self.settings['psm_mode'].get(),
            'confidence_threshold': self.settings['confidence_threshold'].get(),
            'oem_options': {k: v.get() for k, v in self.settings['oem_options'].items()},
            
            # é¢„å¤„ç†ä¸»å¼€å…³
            'enable_preprocessing_optimization': enable_preprocessing,
            
            # è¯¦ç»†é¢„å¤„ç†å‚æ•°
            'enable_deskew': self.settings['enable_deskew'].get(),
            'deskew_angle_threshold': self.settings['deskew_angle_threshold'].get(),
            'remove_borders': self.settings['remove_borders'].get(),
            'border_threshold': self.settings['border_threshold'].get(),
            'crop_to_content': self.settings['crop_to_content'].get(),
            'page_border_detection': self.settings['page_border_detection'].get(),
            'shadow_removal': self.settings['shadow_removal'].get(),
            'bilateral_filter': self.settings['bilateral_filter'].get(),
            'bilateral_d': self.settings['bilateral_d'].get(),
            'bilateral_sigma_color': self.settings['bilateral_sigma_color'].get(),
            'bilateral_sigma_space': self.settings['bilateral_sigma_space'].get(),
            'histogram_equalization': self.settings['histogram_equalization'].get(),
            'apply_clahe': self.settings['apply_clahe'].get(),
            'clahe_clip_limit': self.settings['clahe_clip_limit'].get(),
            'clahe_tile_grid_size': (self.settings['clahe_tile_grid_size_x'].get(), self.settings['clahe_tile_grid_size_y'].get()),
            'unsharp_mask': self.settings['unsharp_mask'].get(),
            'unsharp_radius': self.settings['unsharp_radius'].get(),
            'unsharp_amount': self.settings['unsharp_amount'].get(),
            'adaptive_block_size': self.settings['adaptive_block_size'].get(),
            'adaptive_c_constant': self.settings['adaptive_c_constant'].get(),
            'enable_grayscale': self.settings['enable_grayscale'].get(),
            'enable_binarization': self.settings['enable_binarization'].get(),
            
            # AIç»„ä»¶å¼€å…³
            'enable_layout_analysis': self.settings['enable_layout_analysis'].get(),
            'enable_context_analysis': self.settings['enable_context_analysis'].get(),
            'enable_transformer_ocr': self.settings['enable_transformer_ocr'].get(),
            
            # æ€§èƒ½ä¸é«˜çº§æ¨¡å‹å‚æ•°
            'use_gpu': use_gpu,
            'transformer_ocr_model': self.settings['transformer_ocr_model'].get(),
            
            # é«˜çº§åˆ†å‰²/å…¨å…ƒç´ æ£€æµ‹å‚æ•°
            'enable_advanced_segmentation': self.settings['enable_advanced_segmentation'].get(),
            'segmentation_recognizer': self.settings['segmentation_recognizer'].get(),
            'enable_tesseract_fine_tuning': self.settings['enable_tesseract_fine_tuning'].get(),
            'enabled_segmentation_algorithms': self._get_enabled_segmentation_algorithms(),
            'enable_smart_line_merge': self.settings['enable_smart_line_merge'].get(),
        })
        
        # --- æ­¥éª¤ 4: åˆ›å»ºå¹¶è°ƒåº¦å¼‚æ­¥è¯†åˆ«ä»»åŠ¡ ---
        async def recognition_worker_async(image_path_to_process, enable_preproc, lang):
            try:
                # åœ¨æ‰§è¡Œå‰ï¼Œç¡®ä¿managerå†…éƒ¨çš„languageæ˜¯æœ€æ–°çš„
                self.cvocr_manager.language = lang
                
                # æ›´æ–°Tesseracté…ç½®ä»¥åŒ¹é…æœ€æ–°çš„è¯­è¨€å’ŒPSMè®¾ç½®
                init_tess_success, init_tess_msg = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    self.cvocr_manager._initialize_tesseract
                )
                if not init_tess_success:
                    self.log_message(f"âŒ Tesseractå¼•æ“é…ç½®æ›´æ–°å¤±è´¥: {init_tess_msg}", 'ERROR')
                    self.root.after(0, self.set_processing, False)
                    self.root.after(0, messagebox.showerror, "è¯†åˆ«å¤±è´¥", f"Tesseractå¼•æ“é…ç½®æ›´æ–°å¤±è´¥: {init_tess_msg}")
                    return

                # è°ƒç”¨æ ¸å¿ƒè¯†åˆ«æ–¹æ³•ï¼Œå®ƒå°†ä½¿ç”¨managerä¸­å·²æ›´æ–°çš„config
                results, message = await self.async_ocr_processor.run_blocking_ocr_task(
                    image_path_to_process,
                    enable_preproc
                )
                
                # å°†ç»“æœå›è°ƒåˆ°ä¸»çº¿ç¨‹å¤„ç†GUIæ›´æ–°
                self.root.after(0, self._handle_recognition_result, image_path_to_process, results, message)
            except Exception as e:
                error_msg = f"è¯†åˆ«å›¾ç‰‡ '{os.path.basename(image_path_to_process)}' å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
                self.root.after(0, self._handle_recognition_result, image_path_to_process, None, error_msg)
            finally:
                # ç¡®ä¿æ— è®ºæˆåŠŸå¤±è´¥ï¼Œå¤„ç†çŠ¶æ€éƒ½ä¼šè¢«é‡ç½®
                self.root.after(0, self.set_processing, False)
                self.root.after(0, self._update_performance_display)

        # å°†å¼‚æ­¥ä»»åŠ¡æäº¤åˆ°äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œ
        self.loop.call_soon_threadsafe(self.loop.create_task, recognition_worker_async(
            self.current_image_path, 
            enable_preprocessing, 
            language
        ))
    
    
    def preview_preprocessing(self):
        """
        é¢„è§ˆå½“å‰å›¾åƒåº”ç”¨æ‰€æœ‰é¢„å¤„ç†è®¾ç½®åçš„æ•ˆæœã€‚
        æ­¤ç‰ˆæœ¬ä¿®å¤äº†å› å¼•ç”¨å·²ç§»é™¤çš„ 'enable_advanced_preprocessing' è®¾ç½®è€Œå¯¼è‡´çš„ KeyErrorã€‚
        """
        if self.processing:
            messagebox.showwarning("å¤„ç†ä¸­", "å½“å‰æ­£åœ¨è¿›è¡Œå…¶ä»–æ“ä½œï¼Œè¯·ç¨å€™ã€‚")
            return
            
        if not self.current_image_path:
            messagebox.showwarning("æœªé€‰æ‹©å›¾ç‰‡", "è¯·å…ˆé€‰æ‹©ä¸€å¼ å›¾ç‰‡ä»¥é¢„è§ˆå…¶é¢„å¤„ç†æ•ˆæœã€‚")
            return

        self.set_processing(True)
        self.log_message(f"ğŸ”¬ æ­£åœ¨ç”Ÿæˆé¢„å¤„ç†é¢„è§ˆ: {os.path.basename(self.current_image_path)}", 'INFO')

        # æ”¶é›†æ‰€æœ‰ç›¸å…³çš„é¢„å¤„ç†è®¾ç½®
        # --- æ ¸å¿ƒä¿®æ­£ï¼šç§»é™¤äº†å¯¹ä¸å­˜åœ¨çš„ 'enable_advanced_preprocessing' çš„å¼•ç”¨ ---
        preprocess_options = {
            'enable_preprocessing': True, # é¢„è§ˆæ—¶å¼ºåˆ¶å¯ç”¨
            'enable_advanced_segmentation': False, # æ¨¡æ‹Ÿçº¯æ–‡æœ¬è¯†åˆ«æµç¨‹ä»¥å±•ç¤ºæ‰€æœ‰æ•ˆæœ
            # 'force_intensive_preprocessing' é”®å·²ç§»é™¤
            'enable_deskew': self.settings['enable_deskew'].get(),
            'deskew_angle_threshold': self.settings['deskew_angle_threshold'].get(),
            'remove_borders': self.settings['remove_borders'].get(),
            'border_threshold': self.settings['border_threshold'].get(),
            'crop_to_content': self.settings['crop_to_content'].get(),
            'page_border_detection': self.settings['page_border_detection'].get(),
            'shadow_removal': self.settings['shadow_removal'].get(),
            # 'denoise_strength' å’Œ 'edge_preservation' åœ¨å½“å‰ image_processor ä¸­æœªç›´æ¥ä½¿ç”¨ï¼Œä½†ä¿ç•™ä»¥å¤‡å°†æ¥æ‰©å±•
            # 'denoise_strength': self.settings['denoise_strength'].get(),
            # 'edge_preservation': self.settings['edge_preservation'].get(),
            'unsharp_mask': self.settings['unsharp_mask'].get(),
            'unsharp_radius': self.settings['unsharp_radius'].get(),
            'unsharp_amount': self.settings['unsharp_amount'].get(),
            'histogram_equalization': self.settings['histogram_equalization'].get(),
            'bilateral_filter': self.settings['bilateral_filter'].get(),
            'bilateral_d': self.settings['bilateral_d'].get(),
            'bilateral_sigma_color': self.settings['bilateral_sigma_color'].get(),
            'bilateral_sigma_space': self.settings['bilateral_sigma_space'].get(),
            'apply_clahe': self.settings['apply_clahe'].get(),
            'clahe_clip_limit': self.settings['clahe_clip_limit'].get(),
            'clahe_tile_grid_size': (self.settings['clahe_tile_grid_size_x'].get(), self.settings['clahe_tile_grid_size_y'].get()),
            'adaptive_block_size': self.settings['adaptive_block_size'].get(),
            'adaptive_c_constant': self.settings['adaptive_c_constant'].get(),
            'enable_grayscale': self.settings['enable_grayscale'].get(),
            'enable_binarization': self.settings['enable_binarization'].get(),
        }

        async def preview_worker_async():
            try:
                # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œé˜»å¡çš„å›¾åƒå¤„ç†ä»»åŠ¡
                task_to_run = functools.partial(
                    self.image_processor.intelligent_preprocess_image,
                    self.current_image_path,
                    **preprocess_options
                )
                
                processed_image_np, msg, metadata = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    task_to_run
                )
                
                # å°†ç»“æœå›è°ƒåˆ°ä¸»çº¿ç¨‹ä»¥æ˜¾ç¤ºé¢„è§ˆçª—å£
                if processed_image_np is not None:
                    original_image = Image.open(self.current_image_path)
                    processed_image_pil = Image.fromarray(cv2.cvtColor(processed_image_np, cv2.COLOR_BGR2RGB))
                    self.root.after(0, self._show_preprocessing_preview_window, original_image, processed_image_pil, metadata)
                else:
                    self.log_message(f"âŒ é¢„å¤„ç†é¢„è§ˆç”Ÿæˆå¤±è´¥: {msg}", 'ERROR')
                    self.root.after(0, messagebox.showerror, "é¢„è§ˆå¤±è´¥", f"ç”Ÿæˆé¢„å¤„ç†é¢„è§ˆå¤±è´¥:\n{msg}")

            except Exception as e:
                error_msg = f"ç”Ÿæˆé¢„å¤„ç†é¢„è§ˆæ—¶å‘ç”Ÿé”™è¯¯: {e}\n{traceback.format_exc()}"
                self.log_message(f"âŒ {error_msg}", 'ERROR')
                self.root.after(0, messagebox.showerror, "é¢„è§ˆå¤±è´¥", error_msg)
            finally:
                self.root.after(0, self.set_processing, False)
        
        # å°†å¼‚æ­¥ä»»åŠ¡æäº¤åˆ°äº‹ä»¶å¾ªç¯ä¸­
        self.loop.call_soon_threadsafe(self.loop.create_task, preview_worker_async())
    
    
    
    
    def preview_segmentation(self):
        """
        å¯åŠ¨ä¸€ä¸ªå¼‚æ­¥ä»»åŠ¡ï¼Œä»¥é¢„è§ˆå½“å‰å›¾åƒåº”ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„æ–‡æœ¬åˆ†å‰²ï¼ˆåˆ‡å‰²ï¼‰æŠ€æœ¯åçš„æ•ˆæœã€‚
        (V4.5 - æœ€ç»ˆè°ƒç”¨ä¿®æ­£ç‰ˆ)
        """
        if self.processing:
            messagebox.showwarning("å¤„ç†ä¸­", "å½“å‰æ­£åœ¨è¿›è¡Œå…¶ä»–æ“ä½œï¼Œè¯·ç¨å€™ã€‚")
            return
            
        if not self.current_image_path:
            messagebox.showwarning("æœªé€‰æ‹©å›¾ç‰‡", "è¯·å…ˆé€‰æ‹©ä¸€å¼ å›¾ç‰‡ä»¥é¢„è§ˆå…¶åˆ†å‰²æ•ˆæœã€‚")
            return
            
        if not self.cvocr_manager.is_initialized or not self.cvocr_manager.text_detector:
            messagebox.showerror("å¼•æ“æœªå°±ç»ª", "CVOCRå¼•æ“æˆ–æ–‡æœ¬æ£€æµ‹å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œåˆ†å‰²é¢„è§ˆã€‚")
            return

        self.set_processing(True)
        self.log_message(f"ğŸ“Š æ­£åœ¨ç”Ÿæˆåˆ†å‰²é¢„è§ˆ: {os.path.basename(self.current_image_path)}", 'INFO')

        async def preview_worker_async():
            try:
                processed_image_np = None

                if self._cached_preprocessed_image is not None:
                    self.log_message("   - æ­¥éª¤1: æ£€æµ‹åˆ°å·²ç¼“å­˜çš„é¢„å¤„ç†å›¾åƒï¼Œç›´æ¥ä½¿ç”¨ã€‚", 'INFO')
                    processed_image_np = self._cached_preprocessed_image
                else:
                    self.log_message("   - æ­¥éª¤1: æœªæ‰¾åˆ°ç¼“å­˜ï¼Œæ­£åœ¨å®æ—¶åº”ç”¨å›¾åƒé¢„å¤„ç†...", 'WARNING')
                    preprocess_options = { key: var.get() for key, var in self.settings.items() if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar)) }
                    preprocess_options['enable_preprocessing'] = True

                    task_preprocess = functools.partial(
                        self.image_processor.intelligent_preprocess_image,
                        self.current_image_path,
                        **preprocess_options
                    )
                    processed_image_np, _, _ = await self.loop.run_in_executor(
                        self.async_ocr_processor.executor, task_preprocess
                    )

                if processed_image_np is None:
                    raise Exception("å›¾åƒé¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è¿›è¡Œåˆ†å‰²ã€‚")
                
                self.log_message(f"   - æ­¥éª¤2: ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æŠ€æœ¯ç»„åˆè¿›è¡Œæ–‡æœ¬æ£€æµ‹...", 'INFO')
                
                enabled_algorithms = self._get_enabled_segmentation_algorithms()
                if not enabled_algorithms:
                     raise Exception("æ²¡æœ‰é€‰æ‹©ä»»ä½•åˆ†å‰²æŠ€æœ¯ã€‚è¯·åœ¨'é«˜çº§æ–‡æœ¬åˆ†å‰²æŠ€æœ¯'åŒºåŸŸå‹¾é€‰è‡³å°‘ä¸€é¡¹ã€‚")
                
                if len(processed_image_np.shape) == 2:
                    image_for_detection = cv2.cvtColor(processed_image_np, cv2.COLOR_GRAY2BGR)
                else:
                    image_for_detection = processed_image_np

                # --- æ ¸å¿ƒä¿®æ­£ï¼šé‡‡ç”¨â€œå…ˆæ›´æ–°é…ç½®ï¼Œå†è°ƒç”¨â€çš„ç»Ÿä¸€æ¨¡å¼ ---
                
                # 1. æ”¶é›†å¹¶æ›´æ–°æ£€æµ‹å™¨çš„å†…éƒ¨é…ç½®
                current_config = {key: var.get() for key, var in self.settings.items() if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar))}
                self.cvocr_manager.text_detector.config.update(current_config)
                
                # 2. å‡†å¤‡ä¸å¸¦ precision_level å‚æ•°çš„è°ƒç”¨
                task_detect = functools.partial(
                    self.cvocr_manager.text_detector.detect_text_regions_advanced,
                    image_for_detection,
                    enabled_algorithms
                )
                regions, metadata = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor, task_detect
                )
                
                self.log_message(f"   - æ­¥éª¤3: æ£€æµ‹åˆ° {len(regions)} ä¸ªæ–‡æœ¬åŒºåŸŸï¼Œæ­£åœ¨ç”Ÿæˆå¯è§†åŒ–...", 'INFO')
                
                task_draw = functools.partial(
                    self._draw_segmentation_on_image,
                    self.current_image_path,
                    regions,
                    processed_image_np
                )
                original_pil, processed_pil_with_boxes = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor, task_draw
                )

                self.root.after(0, self._show_segmentation_preview_window, original_pil, processed_pil_with_boxes, metadata)

            except Exception as e:
                error_msg = f"ç”Ÿæˆåˆ†å‰²é¢„è§ˆæ—¶å‘ç”Ÿé”™è¯¯: {e}"
                logger.error(f"{error_msg}\n{traceback.format_exc()}", exc_info=True)
                self.log_message(f"âŒ {error_msg}", 'ERROR')
                self.root.after(0, messagebox.showerror, "é¢„è§ˆå¤±è´¥", error_msg)
            finally:
                self.root.after(0, self.set_processing, False)

        self.loop.call_soon_threadsafe(self.loop.create_task, preview_worker_async())
    
    def _draw_segmentation_on_image(self, image_path: str, regions: List[np.ndarray], processed_image_np: np.ndarray) -> Tuple[Image.Image, Image.Image]:
        """
        åŠ è½½åŸå§‹å›¾åƒï¼Œå¹¶åœ¨é¢„å¤„ç†åçš„å›¾åƒå‰¯æœ¬ä¸Šç»˜åˆ¶åˆ†å‰²åŒºåŸŸã€‚
        è¿™æ˜¯ä¸€ä¸ªè¾…åŠ©æ–¹æ³•ï¼Œè®¾è®¡ä¸ºåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œã€‚

        Args:
            image_path (str): åŸå§‹å›¾åƒçš„æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºåœ¨é¢„è§ˆçª—å£å·¦ä¾§æ˜¾ç¤ºã€‚
            regions (List[np.ndarray]): æ£€æµ‹åˆ°çš„æ–‡æœ¬åŒºåŸŸï¼ˆåˆ†å‰²æ¡†ï¼‰åˆ—è¡¨ã€‚
            processed_image_np (np.ndarray): ç»è¿‡é¢„å¤„ç†åçš„å›¾åƒNumPyæ•°ç»„ï¼Œå°†åœ¨æ­¤å›¾åƒä¸Šç»˜åˆ¶åˆ†å‰²æ¡†ã€‚

        Returns:
            Tuple[Image.Image, Image.Image]: ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªPILå›¾åƒçš„å…ƒç»„ï¼š
                                             1. åŸå§‹å›¾åƒã€‚
                                             2. å¸¦æœ‰åˆ†å‰²æ¡†çš„é¢„å¤„ç†åå›¾åƒã€‚
        """
        # åŠ è½½åŸå§‹å›¾åƒç”¨äºå·¦ä¾§æ˜¾ç¤º
        original_image_np = cv2.imread(image_path)
        original_pil = Image.fromarray(cv2.cvtColor(original_image_np, cv2.COLOR_BGR2RGB))
        
        # ä½¿ç”¨ä¼ å…¥çš„ã€å·²é¢„å¤„ç†çš„å›¾åƒä½œä¸ºç»˜åˆ¶çš„ç”»å¸ƒ
        # é¦–å…ˆç¡®ä¿å®ƒæ˜¯RGBæ ¼å¼ä»¥ä¾¿PILå¤„ç†
        if len(processed_image_np.shape) == 2: # å¦‚æœæ˜¯ç°åº¦å›¾
            image_with_regions = cv2.cvtColor(processed_image_np, cv2.COLOR_GRAY2RGB)
        else: # å¦‚æœæ˜¯BGRå›¾
            image_with_regions = cv2.cvtColor(processed_image_np, cv2.COLOR_BGR2RGB)
        
        # ç»˜åˆ¶æ‰€æœ‰æ£€æµ‹åˆ°çš„å¤šè¾¹å½¢åŒºåŸŸ
        if regions:
            # å°†æ‰€æœ‰åŒºåŸŸç‚¹è½¬æ¢ä¸ºé€‚ç”¨äº polylines çš„æ•´æ•°åæ ‡æ ¼å¼
            pts = [np.array(region, np.int32) for region in regions]
            # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ‰€æœ‰å¤šè¾¹å½¢ï¼Œé¢œè‰²ä¸ºäº®ç»¿è‰²ï¼Œçº¿å®½ä¸º2åƒç´ 
            cv2.polylines(image_with_regions, pts, isClosed=True, color=(0, 255, 0), thickness=2)
            
        # å°†ç»˜åˆ¶åçš„ NumPy æ•°ç»„è½¬ä¸º PIL å›¾åƒï¼Œç”¨äºåœ¨é¢„è§ˆçª—å£å³ä¾§æ˜¾ç¤º
        segmented_pil = Image.fromarray(image_with_regions)
        
        return original_pil, segmented_pil

    def _show_segmentation_preview_window(self, original_img: Image.Image, segmented_processed_img: Image.Image, metadata: Dict):
        """
        åˆ›å»ºä¸€ä¸ªæ–°çª—å£æ¥å¹¶æ’æ˜¾ç¤ºåŸå§‹å›¾åƒå’Œå¸¦æœ‰åˆ†å‰²ç»“æœçš„é¢„å¤„ç†åå›¾åƒã€‚
        (V4.3 - å·¥ä½œæµä¿®æ­£ç‰ˆ): 
        - å·¦ä¾§æ˜¾ç¤ºåŸå§‹å›¾ï¼Œç”¨äºåŸºå‡†å¯¹æ¯”ã€‚
        - å³ä¾§æ˜¾ç¤ºåœ¨é¢„å¤„ç†åçš„å›¾åƒä¸Šç»˜åˆ¶çš„åˆ†å‰²æ¡†ï¼Œç›´è§‚å±•ç¤ºé¢„å¤„ç†+åˆ†å‰²çš„è”åˆæ•ˆæœã€‚
        - åº•éƒ¨æ˜¾ç¤ºæœ¬æ¬¡æ“ä½œæ‰€ä½¿ç”¨çš„å…·ä½“åˆ†å‰²ç®—æ³•ç»„åˆã€‚
        """
        preview_window = tk.Toplevel(self.root)
        preview_window.title("æ–‡æœ¬åˆ†å‰²ï¼ˆåˆ‡å‰²ï¼‰æ•ˆæœé¢„è§ˆ")
        preview_window.geometry("1600x800")
        preview_window.transient(self.root)
        preview_window.grab_set()

        main_frame = ttk.Frame(preview_window, padding=design.get_spacing('4'))
        main_frame.pack(fill='both', expand=True)

        # å›¾åƒæ˜¾ç¤ºåŒº
        image_frame = ttk.Frame(main_frame)
        image_frame.pack(fill='both', expand=True)

        # å·¦ä¾§ï¼šåŸå§‹å›¾åƒ
        original_frame = ttk.LabelFrame(image_frame, text="åŸå§‹å›¾åƒ", padding=design.get_spacing('2'))
        original_frame.pack(side='left', fill='both', expand=True, padx=(0, design.get_spacing('2')))
        original_canvas = tk.Canvas(original_frame, bg=design.get_color('neutral', '100'))
        original_canvas.pack(fill='both', expand=True)

        # å³ä¾§ï¼šé¢„å¤„ç† + åˆ†å‰²ç»“æœ
        segmented_frame = ttk.LabelFrame(image_frame, text="é¢„å¤„ç† + åˆ†å‰²ç»“æœ (ç»¿è‰²æ¡†)", padding=design.get_spacing('2'))
        segmented_frame.pack(side='right', fill='both', expand=True, padx=(design.get_spacing('2'), 0))
        segmented_canvas = tk.Canvas(segmented_frame, bg=design.get_color('neutral', '100'))
        segmented_canvas.pack(fill='both', expand=True)

        # åº•éƒ¨ä¿¡æ¯åŒº
        info_frame = ttk.LabelFrame(main_frame, text="æ£€æµ‹ä¿¡æ¯", padding=design.get_spacing('3'))
        info_frame.pack(fill='x', pady=(design.get_spacing('4'), 0))

        # æ˜¾ç¤ºå…ƒæ•°æ®
        total_regions = metadata.get('total_regions', 0)
        proc_time = metadata.get('processing_time', 0.0)
        # ä»å…ƒæ•°æ®ä¸­è·å–å®é™…ä½¿ç”¨çš„ç®—æ³•åˆ—è¡¨
        algorithms_used = ", ".join(metadata.get('algorithms_used', ['N/A']))
        
        info_text = f"ä½¿ç”¨ç®—æ³•: {algorithms_used} | æ£€æµ‹åˆ°åŒºåŸŸæ•°: {total_regions} | è€—æ—¶: {proc_time:.3f} ç§’"
        info_label = tk.Label(info_frame, text=info_text, justify='left', bg=design.get_color('neutral', '50'))
        design.apply_text_style(info_label, 'body')
        info_label.pack(anchor='w')

        # åŠ¨æ€è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥é€‚åº”Canvasçš„å‡½æ•°
        def resize_and_display(canvas: tk.Canvas, img: Image.Image):
            canvas.update_idletasks()
            canvas_w, canvas_h = canvas.winfo_width(), canvas.winfo_height()
            if canvas_w <= 1 or canvas_h <= 1: return
            
            img_w, img_h = img.size
            scale = min(canvas_w / img_w, canvas_h / img_h)
            new_w, new_h = int(img_w * scale), int(img_h * scale)
            
            resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            photo = ImageTk.PhotoImage(resized)
            
            # å­˜å‚¨å¼•ç”¨é˜²æ­¢è¢«åƒåœ¾å›æ”¶
            canvas.image = photo
            
            x_offset = (canvas_w - new_w) // 2
            y_offset = (canvas_h - new_h) // 2
            canvas.create_image(x_offset, y_offset, image=photo, anchor='nw')

        # å»¶è¿Ÿç»‘å®šresizeäº‹ä»¶ï¼Œç¡®ä¿çª—å£å·²åˆ›å»º
        preview_window.after(100, lambda: [
            resize_and_display(original_canvas, original_img),
            resize_and_display(segmented_canvas, segmented_processed_img),
            original_canvas.bind('<Configure>', lambda e: resize_and_display(original_canvas, original_img)),
            segmented_canvas.bind('<Configure>', lambda e: resize_and_display(segmented_canvas, segmented_processed_img))
        ])

        self.log_message("âœ… æˆåŠŸç”Ÿæˆåˆ†å‰²é¢„è§ˆçª—å£ã€‚", 'SUCCESS')


    def _show_preprocessing_preview_window(self, original_img: Image.Image, processed_img: Image.Image, metadata: Dict):
        """
        åˆ›å»ºä¸€ä¸ªæ–°çª—å£æ¥å¹¶æ’æ˜¾ç¤ºåŸå§‹å›¾åƒå’Œé¢„å¤„ç†åçš„å›¾åƒã€‚
        (V4.3 - ç¼“å­˜ç»“æœç‰ˆ): æ­¤ç‰ˆæœ¬åœ¨æ˜¾ç¤ºé¢„è§ˆçš„åŒæ—¶ï¼Œä¼šå°†å¤„ç†åçš„å›¾åƒç¼“å­˜åˆ°å®ä¾‹å˜é‡ä¸­ï¼Œ
        ä»¥ä¾›â€œé¢„è§ˆåˆ†å‰²ç»“æœâ€åŠŸèƒ½ç›´æ¥ä½¿ç”¨ï¼Œå®ç°å·¥ä½œæµçš„æ— ç¼è¡”æ¥ã€‚
        """
        preview_window = tk.Toplevel(self.root)
        preview_window.title("å›¾åƒé¢„å¤„ç†æ•ˆæœé¢„è§ˆ")
        preview_window.geometry("1600x800")
        preview_window.transient(self.root)
        preview_window.grab_set()

        main_frame = ttk.Frame(preview_window, padding=design.get_spacing('4'))
        main_frame.pack(fill='both', expand=True)

        # å›¾åƒæ˜¾ç¤ºåŒº
        image_frame = ttk.Frame(main_frame)
        image_frame.pack(fill='both', expand=True)

        # åŸå§‹å›¾åƒ
        original_frame = ttk.LabelFrame(image_frame, text="åŸå§‹å›¾åƒ", padding=design.get_spacing('2'))
        original_frame.pack(side='left', fill='both', expand=True, padx=(0, design.get_spacing('2')))
        original_canvas = tk.Canvas(original_frame, bg=design.get_color('neutral', '100'))
        original_canvas.pack(fill='both', expand=True)

        # é¢„å¤„ç†åå›¾åƒ
        processed_frame = ttk.LabelFrame(image_frame, text="é¢„å¤„ç†å", padding=design.get_spacing('2'))
        processed_frame.pack(side='right', fill='both', expand=True, padx=(design.get_spacing('2'), 0))
        processed_canvas = tk.Canvas(processed_frame, bg=design.get_color('neutral', '100'))
        processed_canvas.pack(fill='both', expand=True)

        # åº•éƒ¨ä¿¡æ¯åŒº
        info_frame = ttk.LabelFrame(main_frame, text="å¤„ç†ä¿¡æ¯", padding=design.get_spacing('3'))
        info_frame.pack(fill='x', pady=(design.get_spacing('4'), 0))

        # æ˜¾ç¤ºå¤„ç†æ­¥éª¤
        operations = metadata.get('operations', ['æ— æ“ä½œ'])
        operations_text = " -> ".join(operations)
        info_label = tk.Label(info_frame, text=f"å¤„ç†æµç¨‹: {operations_text}", 
                              wraplength=1500, justify='left', bg=design.get_color('neutral', '50'))
        design.apply_text_style(info_label, 'body_small')
        info_label.pack(anchor='w')

        # åŠ¨æ€è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥é€‚åº”Canvas
        def resize_and_display(canvas: tk.Canvas, img: Image.Image):
            canvas.update_idletasks() # ç¡®ä¿è·å–åˆ°æ­£ç¡®çš„canvaså°ºå¯¸
            canvas_w, canvas_h = canvas.winfo_width(), canvas.winfo_height()
            if canvas_w <= 1 or canvas_h <= 1: return
            
            img_w, img_h = img.size
            scale = min(canvas_w / img_w, canvas_h / img_h)
            new_w, new_h = int(img_w * scale), int(img_h * scale)
            
            resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            photo = ImageTk.PhotoImage(resized)
            
            # å­˜å‚¨å¼•ç”¨é˜²æ­¢è¢«åƒåœ¾å›æ”¶
            canvas.image = photo 
            
            # åœ¨Canvasä¸­å¤®æ˜¾ç¤ºå›¾ç‰‡
            x_offset = (canvas_w - new_w) // 2
            y_offset = (canvas_h - new_h) // 2
            canvas.create_image(x_offset, y_offset, image=photo, anchor='nw')

        # å»¶è¿Ÿç»‘å®šresizeäº‹ä»¶ï¼Œç¡®ä¿çª—å£å·²åˆ›å»º
        preview_window.after(100, lambda: [
            resize_and_display(original_canvas, original_img),
            resize_and_display(processed_canvas, processed_img),
            original_canvas.bind('<Configure>', lambda e: resize_and_display(original_canvas, original_img)),
            processed_canvas.bind('<Configure>', lambda e: resize_and_display(processed_canvas, processed_img))
        ])

        # å°†å¤„ç†åçš„å›¾åƒï¼ˆPIL.Imageï¼‰è½¬æ¢ä¸ºNumPyæ•°ç»„ï¼ˆBGRæ ¼å¼ï¼‰å¹¶ç¼“å­˜
        # è¿™æ˜¯å®ç°â€œé¢„å¤„ç† -> åˆ†å‰²é¢„è§ˆâ€å·¥ä½œæµè¡”æ¥çš„å…³é”®æ­¥éª¤
        self._cached_preprocessed_image = cv2.cvtColor(np.array(processed_img), cv2.COLOR_RGB2BGR)
        self.log_message("âœ… æˆåŠŸç”Ÿæˆé¢„å¤„ç†é¢„è§ˆçª—å£ï¼Œå¹¶å·²ç¼“å­˜å¤„ç†ç»“æœã€‚", 'SUCCESS')
    
    
    def _handle_recognition_result(self, image_path: str, results: Optional[Dict], message: str):
        """
        å¤„ç†è¯†åˆ«ç»“æœï¼Œå¹¶å…¨é¢æ›´æ–°GUIçš„å„ä¸ªéƒ¨åˆ†ã€‚
        """
        try:
            if results is None or results.get('error'):
                self.log_message(f"âŒ è¯†åˆ«å¤±è´¥: {message}", 'ERROR')
                messagebox.showerror("è¯†åˆ«å¤±è´¥", f"è¯†åˆ«å›¾ç‰‡ '{os.path.basename(image_path)}' å¤±è´¥:\n{message}")
                
                self.report_text.config(state='normal')
                self.report_text.delete(1.0, tk.END)
                self.report_text.insert(tk.END, f"è¯†åˆ«å¤±è´¥: {message}")
                self.report_text.config(state='disabled')
                
                self.results_tree.delete(*self.results_tree.get_children())
                self.results_stats_label.config(text="è¯†åˆ«å¤±è´¥")

                fail_results_entry = {
                    'full_text': '', 'text_blocks': [], 'error': message,
                    'total_blocks': 0, 'total_characters': 0, 'average_confidence': 0,
                    'language': self.settings['language'].get(),
                    'cvocr_components': self.cvocr_manager.config.get('components', {}),
                    'processing_metadata': {'total_processing_time': 0, 'error': message}
                }
                self.result_manager.add_result(image_path, fail_results_entry, fail_results_entry.get('processing_metadata'))
                return

            self.log_message(f"âœ… è¯†åˆ«æˆåŠŸ: {message}", 'SUCCESS')
            
            entry = self.result_manager.add_result(image_path, results, results.get('processing_metadata'))
            if entry and self.settings['auto_save_results'].get():
                try:
                    base_name = os.path.splitext(os.path.basename(image_path))[0]
                    save_dir = "ocr_results"
                    os.makedirs(save_dir, exist_ok=True)
                    output_file = os.path.join(save_dir, f"{base_name}_result.json")
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(entry, f, ensure_ascii=False, indent=2)
                    self.log_message(f"ğŸ’¾ è¯†åˆ«ç»“æœå·²è‡ªåŠ¨ä¿å­˜åˆ°: {output_file}", 'INFO')
                except Exception as e:
                    self.log_message(f"âŒ è‡ªåŠ¨ä¿å­˜ç»“æœå¤±è´¥: {e}", 'ERROR')

            self.report_text.config(state='normal')
            self.report_text.delete(1.0, tk.END)
            self.report_text.insert(tk.END, results.get('full_text', ''))
            self.report_text.config(state='disabled')

            self.results_tree.delete(*self.results_tree.get_children())
            all_blocks = results.get('text_blocks', [])
            
            for i, block in enumerate(all_blocks):
                confidence_str = f"{block.get('confidence', 0):.1f}%"
                bbox = block.get('bbox', [0,0,0,0])
                bbox_str = f"({bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]})"
                
                if block.get('is_shape', False):
                    components_str = "å›¾å½¢æ£€æµ‹"
                    text_display = block.get('text', '')
                    layout_info_str = 'N/A'
                else:
                    text_display = block.get('text', '')[:50] + "..." if len(block.get('text', '')) > 50 else block.get('text', '')
                    components_from_entry = entry.get('cvocr_components', {}) 
                    used_components = [k.replace('_used', '') for k, v in components_from_entry.items() if v]
                    components_str = "+".join(used_components) if used_components else 'Tesseract'
                    layout_info_str = block.get('layout_info', {}).get('region_type', 'N/A')
                
                self.results_tree.insert('', 'end', values=(
                    i + 1, text_display, confidence_str, bbox_str,
                    block.get('line_num', 0), block.get('block_num', 0),
                    components_str, layout_info_str
                ), iid=f"block_{i}")

            total_char_count = results.get('total_characters', 0)
            avg_confidence_display = results.get('average_confidence', 0)
            self.results_stats_label.config(text=f"æ€»å…ƒç´ å—: {len(all_blocks)} | æ€»å­—ç¬¦: {total_char_count} | å¹³å‡ç½®ä¿¡åº¦: {avg_confidence_display:.1f}%")

            text_blocks_to_draw = [b for b in all_blocks if not b.get('is_shape', False)]
            shape_blocks_to_draw = [b for b in all_blocks if b.get('is_shape', False)]
            self.display_image(image_path, text_blocks=text_blocks_to_draw, shape_blocks=shape_blocks_to_draw)
            
            self.refresh_history()
            self.update_enhanced_stats()

            self.notebook.select(1)
            self.root.update_idletasks()

        except Exception as e:
            error_msg = f"å¤„ç†è¯†åˆ«ç»“æœå¹¶æ›´æ–°GUIæ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.log_message(f"âŒ {error_msg}", 'ERROR')
            messagebox.showerror("GUIæ›´æ–°å¤±è´¥", error_msg)
        finally:
            self.set_processing(False)
            self._update_performance_display()
    
    
    def batch_process(self):
        """æ‰¹é‡å¤„ç†å¤šä¸ªå›¾ç‰‡æ–‡ä»¶ (ç°åœ¨æ˜¯å¼‚æ­¥åç¨‹)"""
        if self.processing:
            messagebox.showwarning("å¤„ç†ä¸­", "å½“å‰æ­£åœ¨è¿›è¡Œè¯†åˆ«æˆ–æ‰¹é‡å¤„ç†ï¼Œè¯·ç¨å€™ã€‚")
            return

        if not self.cvocr_manager.is_initialized:
            if messagebox.askyesno("CVOCRå¼•æ“æœªåˆå§‹åŒ–", "CVOCRå¼•æ“å°šæœªåˆå§‹åŒ–ã€‚æ˜¯å¦ç«‹å³åˆå§‹åŒ–ï¼Ÿ"):
                self.initialize_cvocr()
            else:
                self.log_message("âŒ æ‰¹é‡å¤„ç†å–æ¶ˆï¼šCVOCRå¼•æ“æœªåˆå§‹åŒ–ã€‚", 'ERROR')
                return

        if not hasattr(self, 'batch_image_paths') or not self.batch_image_paths:
            messagebox.showwarning("æ— å›¾ç‰‡å¯æ‰¹é‡å¤„ç†", "è¯·å…ˆç‚¹å‡» 'æ‰¹é‡é€‰æ‹©' æŒ‰é’®é€‰æ‹©è¦æ‰¹é‡å¤„ç†çš„å›¾ç‰‡ã€‚")
            self.log_message("âŒ æ‰¹é‡å¤„ç†å–æ¶ˆï¼šæœªé€‰æ‹©æ‰¹é‡å›¾ç‰‡ã€‚", 'ERROR')
            return

        self.set_processing(True)
        self.log_message(f"âš¡ å¼€å§‹æ‰¹é‡è¯†åˆ« {len(self.batch_image_paths)} å¼ å›¾ç‰‡...", 'INFO')

       
        language_str = self.settings['language'].get()
        language = OCRLanguage(language_str) if language_str != 'auto' else OCRLanguage.AUTO
        enable_preprocessing = self.settings['enable_preprocessing'].get()
        use_gpu = self.settings['use_gpu'].get()

        self.cvocr_manager.config.update({
            'language': language.value,
            'enable_preprocessing_optimization': enable_preprocessing,
            'use_gpu': use_gpu,
            'enable_deskew': self.settings['enable_deskew'].get(),
            'deskew_angle_threshold': self.settings['deskew_angle_threshold'].get(),
            'remove_borders': self.settings['remove_borders'].get(),
            'border_threshold': self.settings['border_threshold'].get(),
            'crop_to_content': self.settings['crop_to_content'].get(),
            'page_border_detection': self.settings['page_border_detection'].get(),
            'shadow_removal': self.settings['shadow_removal'].get(),
            'unsharp_mask': self.settings['unsharp_mask'].get(),
            'unsharp_radius': self.settings['unsharp_radius'].get(),
            'unsharp_amount': self.settings['unsharp_amount'].get(),
            'histogram_equalization': self.settings['histogram_equalization'].get(),
            'bilateral_filter': self.settings['bilateral_filter'].get(),
            'bilateral_d': self.settings['bilateral_d'].get(),
            'bilateral_sigma_color': self.settings['bilateral_sigma_color'].get(),
            'bilateral_sigma_space': self.settings['bilateral_sigma_space'].get(),
            'apply_clahe': self.settings['apply_clahe'].get(),
            'clahe_clip_limit': self.settings['clahe_clip_limit'].get(),
            'clahe_tile_grid_size': (self.settings['clahe_tile_grid_size_x'].get(), self.settings['clahe_tile_grid_size_y'].get()),
            'adaptive_block_size': self.settings['adaptive_block_size'].get(),
            'adaptive_c_constant': self.settings['adaptive_c_constant'].get(),
            'psm': self.settings['psm_mode'].get(),
            'confidence_threshold': self.settings['confidence_threshold'].get(),
            'enable_layout_analysis': self.settings['enable_layout_analysis'].get(),
            'enable_context_analysis': self.settings['enable_context_analysis'].get(),
            'enable_transformer_ocr': self.settings['enable_transformer_ocr'].get(),
        })

        self.cvocr_manager.language = language
        
        async def batch_process_async():
            init_tess_success, init_tess_msg = await self.loop.run_in_executor(
                self.async_ocr_processor.executor,
                self.cvocr_manager._initialize_tesseract
            )
            if not init_tess_success:
                self.log_message(f"âŒ æ‰¹é‡å¤„ç†å–æ¶ˆï¼šTesseractå¼•æ“é…ç½®æ›´æ–°å¤±è´¥: {init_tess_msg}", 'ERROR')
                self.root.after(0, self.set_processing, False)
                self.root.after(0, messagebox.showerror, "æ‰¹é‡å¤„ç†å¤±è´¥", f"Tesseractå¼•æ“é…ç½®æ›´æ–°å¤±è´¥: {init_tess_msg}")
                return

            tasks = []
            for i, image_path_to_process in enumerate(self.batch_image_paths):
                task = self.async_ocr_processor.run_blocking_ocr_task(
                    image_path_to_process,
                    enable_preprocessing
                )
                tasks.append(task)
            
            completed_count = 0
            total_count = len(tasks)
            # ä½¿ç”¨ enumerate æ¥åŒæ—¶è·å–ç´¢å¼•å’Œ future å¯¹è±¡
            for i, future in enumerate(asyncio.as_completed(tasks)):
                completed_count += 1
                # ä»åŸå§‹åˆ—è¡¨ä¸­è·å–å¯¹åº”çš„å›¾ç‰‡è·¯å¾„
                image_path_for_result = self.batch_image_paths[i]
                try:
                    results, message = await future
                    self.root.after(0, self._handle_batch_result, image_path_for_result, results, message, completed_count, total_count)
                except Exception as e:
                    error_msg = f"æ‰¹é‡è¯†åˆ«å›¾ç‰‡ '{os.path.basename(image_path_for_result)}' å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
                    self.log_message(f"âŒ [{completed_count}/{total_count}] {error_msg}", 'ERROR')
                    self.root.after(0, self._handle_batch_result, image_path_for_result, None, error_msg, completed_count, total_count)

            self.log_message(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼å…±å¤„ç† {total_count} å¼ å›¾ç‰‡ã€‚", 'SUCCESS')
            self.root.after(0, self.set_processing, False)
            self.root.after(0, self._update_performance_display)

        self.loop.call_soon_threadsafe(self.loop.create_task, batch_process_async())
    
    def _handle_batch_result(self, image_path: str, results: Optional[Dict], message: str, completed_count: int, total_count: int):
        """å¤„ç†æ‰¹é‡è¯†åˆ«ä¸­çš„å•ä¸ªç»“æœï¼Œæ›´æ–°GUIå’Œå†å²è®°å½•"""
        progress_msg = f"âš¡ [{completed_count}/{total_count}]"
        if results is None or results.get('error'):
            self.log_message(f"{progress_msg} è¯†åˆ«å¤±è´¥å›¾ç‰‡ '{os.path.basename(image_path)}': {message}", 'ERROR')
            # ä»ç„¶æ·»åŠ åˆ°å†å²è®°å½•ï¼Œä½†æ ‡è®°ä¸ºå¤±è´¥
            fail_results = {
                'full_text': '', 'text_blocks': [], 'error': message,
                'total_blocks': 0, 'total_characters': 0, 'average_confidence': 0,
                'language': self.settings['language'].get(),
                'cvocr_components': self.cvocr_manager.config.get('components', {}),
                'processing_metadata': {'total_processing_time': 0, 'error': message}
            }
            self.result_manager.add_result(image_path, fail_results, fail_results.get('processing_metadata'))
        else:
            self.log_message(f"{progress_msg} è¯†åˆ«æˆåŠŸå›¾ç‰‡ '{os.path.basename(image_path)}': {message}", 'SUCCESS')
            self.result_manager.add_result(image_path, results, results.get('processing_metadata'))
        
        # åˆ·æ–°å†å²è®°å½•å’Œç»Ÿè®¡ä¿¡æ¯ï¼Œä½†å¯èƒ½ä¸éœ€è¦æ¯æ¬¡éƒ½æ›´æ–°è¯¦ç»†ç»“æœå’Œå›¾ç‰‡é¢„è§ˆ
        self.refresh_history()
        self.update_enhanced_stats()
        self.notebook.select(3) # åˆ‡æ¢åˆ°å†å²è®°å½•æ ‡ç­¾é¡µ

    def quick_ocr(self):
        """å¿«é€ŸOCRï¼Œç›´æ¥è¯†åˆ«å½“å‰å›¾ç‰‡ (ç°åœ¨æ˜¯å¼‚æ­¥åç¨‹)"""
        if self.processing:
            messagebox.showwarning("å¤„ç†ä¸­", "å½“å‰æ­£åœ¨è¿›è¡Œè¯†åˆ«ï¼Œè¯·ç¨å€™ã€‚")
            return
        if not self.cvocr_manager.is_initialized:
            if messagebox.askyesno("CVOCRå¼•æ“æœªåˆå§‹åŒ–", "CVOCRå¼•æ“å°šæœªåˆå§‹åŒ–ã€‚æ˜¯å¦ç«‹å³åˆå§‹åŒ–ï¼Ÿ"):
                self.initialize_cvocr()
            else:
                self.log_message("âŒ å¿«é€ŸOCRå–æ¶ˆï¼šCVOCRå¼•æ“æœªåˆå§‹åŒ–ã€‚", 'ERROR')
                return
        if not self.current_image_path:
            messagebox.showwarning("æœªé€‰æ‹©å›¾ç‰‡", "è¯·å…ˆé€‰æ‹©ä¸€å¼ å›¾ç‰‡ã€‚")
            self.log_message("âŒ å¿«é€ŸOCRå–æ¶ˆï¼šæœªé€‰æ‹©å›¾ç‰‡ã€‚", 'ERROR')
            return
        
        self.log_message(f"âš¡ å¼€å§‹å¿«é€ŸOCRè¯†åˆ«å›¾ç‰‡: {os.path.basename(self.current_image_path)}", 'INFO')
        self.set_processing(True)

        language_str = self.settings['language'].get()
        language = OCRLanguage(language_str) if language_str != 'auto' else OCRLanguage.AUTO
        
        # ã€æœ€ç»ˆå¼ºåŒ–ã€‘: åˆ›å»ºä¸€ä¸ªå¹²å‡€ã€ç‹¬ç«‹çš„é…ç½®å­—å…¸ç”¨äºå¿«é€ŸOCRï¼Œç¡®ä¿ä¸å—ä»»ä½•å…¶ä»–è®¾ç½®çš„å¹²æ‰°ã€‚
        quick_config = {
            'language': language.value,
            'psm': 3,  # ä½¿ç”¨PSM 3è¿›è¡Œæ•´é¡µè‡ªåŠ¨åˆ†å‰²ï¼Œæœ€ç¬¦åˆå¿«é€Ÿç«¯åˆ°ç«¯è¯†åˆ«çš„é€»è¾‘ã€‚
            'oem': 3,  # ä½¿ç”¨é»˜è®¤çš„LSTMå¼•æ“ã€‚
            'confidence_threshold': 0, # åœ¨å¿«é€Ÿæ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›çœ‹åˆ°æ‰€æœ‰ç»“æœï¼Œä¸è¿‡æ»¤ã€‚
            'use_gpu': self.settings['use_gpu'].get(),
            'quick_mode': True, # <--- æ–°å¢ï¼šæ·»åŠ ä¸€ä¸ªæ˜ç¡®çš„â€œå¿«é€Ÿæ¨¡å¼â€æ ‡è®°

            # --- æ˜¾å¼ç¦ç”¨æ‰€æœ‰é«˜çº§åŠŸèƒ½ ---
            'enable_preprocessing': False, # ç¦ç”¨æ‰€æœ‰åœ¨AdvancedTextImageProcessorä¸­çš„å¤æ‚é¢„å¤„ç†ã€‚
            'enable_preprocessing_optimization': False, # ç¡®ä¿managerä¹ŸçŸ¥é“é¢„å¤„ç†å·²ç¦ç”¨ã€‚
            'enable_advanced_segmentation': False, # å¼ºåˆ¶å…³é—­å…¨å…ƒç´ æ£€æµ‹/é«˜çº§åˆ†å‰²æ¨¡å¼ã€‚
            'enable_layout_analysis': False,
            'enable_context_analysis': False,
            'enable_transformer_ocr': False,
            'enable_smart_line_merge': False,
            'enable_layoutlm_merge': False,
        }

        # å°†è¿™ä¸ªå¹²å‡€çš„é…ç½®åº”ç”¨åˆ°ç®¡ç†å™¨
        self.cvocr_manager.config.update(quick_config)
        self.cvocr_manager.language = language
        
        async def quick_ocr_worker_async(image_path_to_process, lang):
            try:
                # é‡æ–°åˆå§‹åŒ–Tesseracté…ç½®ï¼Œä»¥ç¡®ä¿ä½¿ç”¨PSM 3
                init_tess_success, init_tess_msg = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    self.cvocr_manager._initialize_tesseract
                )
                if not init_tess_success:
                    self.log_message(f"âŒ å¿«é€ŸOCRå–æ¶ˆï¼šTesseractå¼•æ“é…ç½®æ›´æ–°å¤±è´¥: {init_tess_msg}", 'ERROR')
                    self.root.after(0, self.set_processing, False)
                    self.root.after(0, messagebox.showerror, "å¿«é€ŸOCRå¤±è´¥", f"Tesseractå¼•æ“é…ç½®æ›´æ–°å¤±è´¥: {init_tess_msg}")
                    return

                # è°ƒç”¨æ ¸å¿ƒè¯†åˆ«å‡½æ•°ï¼Œç¬¬äºŒä¸ªå‚æ•° `enable_preprocessing` ä¸º False
                results, message = await self.async_ocr_processor.run_blocking_ocr_task(
                    image_path_to_process,
                    False 
                )
                self.root.after(0, self._handle_recognition_result, image_path_to_process, results, message)
            except Exception as e:
                error_msg = f"å¿«é€ŸOCRå›¾ç‰‡ '{os.path.basename(image_path_to_process)}' å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
                self.root.after(0, self._handle_recognition_result, image_path_to_process, None, error_msg)
            finally:
                self.root.after(0, self.set_processing, False)
                self.root.after(0, self._update_performance_display)

        self.loop.call_soon_threadsafe(self.loop.create_task, quick_ocr_worker_async(self.current_image_path, language))
    
    
    def show_visualization(self):
        """æ˜¾ç¤ºå½“å‰è¯†åˆ«ç»“æœçš„è¾¹ç•Œæ¡†å¯è§†åŒ–"""
        if not self.result_manager.current_results:
            messagebox.showwarning("æ— ç»“æœ", "è¯·å…ˆæ‰§è¡ŒOCRè¯†åˆ«æ“ä½œä»¥è·å–ç»“æœã€‚")
            return
        
        results = self.result_manager.current_results
        # Use the image path from the current result in result_manager
        current_result_entry = self.result_manager.get_result_by_id(self.result_manager.history[0]['id']) if self.result_manager.history else None
        image_path = current_result_entry['image_path'] if current_result_entry else None

        if not image_path:
            messagebox.showwarning("æ— å›¾ç‰‡", "æ— æ³•æ‰¾åˆ°å¯¹åº”çš„åŸå§‹å›¾ç‰‡ã€‚")
            return

        bboxes = []
        for block in results.get('text_blocks', []):
            bboxes.append(block['bbox'])
        
        self.display_image(image_path, bboxes=bboxes)
        self.log_message(f"ğŸ“Š å·²åœ¨å›¾ç‰‡é¢„è§ˆä¸­æ˜¾ç¤ºè¾¹ç•Œæ¡†ã€‚", 'INFO')

    def export_current_results(self):
        """å¯¼å‡ºå½“å‰è¯†åˆ«ç»“æœ"""
        if not self.result_manager.current_results:
            messagebox.showwarning("æ— ç»“æœ", "æ²¡æœ‰å¯å¯¼å‡ºçš„å½“å‰è¯†åˆ«ç»“æœã€‚")
            return
        
        # å…è®¸ç”¨æˆ·é€‰æ‹©å¯¼å‡ºæ ¼å¼
        file_options = [
            ("JSONæ–‡ä»¶", "*.json"),
            ("æ–‡æœ¬æ–‡ä»¶", "*.txt"),
            ("æ‰€æœ‰æ–‡ä»¶", "*.*")
        ]
        
        file_path = filedialog.asksaveasfilename(
            defaultextension=".json",
            filetypes=file_options,
            title="ä¿å­˜è¯†åˆ«ç»“æœ"
        )
        
        if file_path:
            try:
                extension = os.path.splitext(file_path)[1].lower()
                results_to_export = self.result_manager.current_results
                
                if extension == ".json":
                    with open(file_path, 'w', encoding='utf-8') as f:
                        json.dump(results_to_export, f, ensure_ascii=False, indent=2)
                elif extension == ".txt":
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(results_to_export.get('full_text', ''))
                else:
                    messagebox.showwarning("ä¸æ”¯æŒçš„æ ¼å¼", "è¯·é€‰æ‹©JSONæˆ–TXTæ ¼å¼è¿›è¡Œå¯¼å‡ºã€‚")
                    self.log_message(f"âŒ å¯¼å‡ºç»“æœå¤±è´¥ï¼šä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ {extension}ã€‚", 'ERROR')
                    return

                self.log_message(f"ğŸ“¤ å½“å‰è¯†åˆ«ç»“æœå·²å¯¼å‡ºåˆ°: {file_path}", 'SUCCESS')
                messagebox.showinfo("å¯¼å‡ºæˆåŠŸ", f"è¯†åˆ«ç»“æœå·²æˆåŠŸå¯¼å‡ºåˆ°:\n{file_path}")
            except Exception as e:
                self.log_message(f"âŒ å¯¼å‡ºå½“å‰è¯†åˆ«ç»“æœå¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("å¯¼å‡ºå¤±è´¥", f"å¯¼å‡ºè¯†åˆ«ç»“æœå¤±è´¥:\n{e}")

    def clear_results(self):
        """æ¸…ç©ºå½“å‰æ˜¾ç¤ºçš„è¯†åˆ«ç»“æœå’Œå›¾ç‰‡ä¸Šçš„è¾¹ç•Œæ¡†"""
        self.report_text.config(state='normal')
        self.report_text.delete(1.0, tk.END)
        self.report_text.config(state='disabled')
        
        self.results_tree.delete(*self.results_tree.get_children())
        self.results_stats_label.config(text="æš‚æ— è¯†åˆ«ç»“æœ")
        
        self.image_canvas.delete("bbox") # æ¸…é™¤æ‰€æœ‰tagä¸º"bbox"çš„å…ƒç´ 
        self.image_canvas.delete("highlight_bbox") # æ¸…é™¤é«˜äº®è¾¹æ¡†
        self.current_bboxes = []
        self.log_message("ğŸ§¹ å½“å‰è¯†åˆ«ç»“æœå·²æ¸…ç©ºã€‚", 'INFO')

    def compare_results(self):
        """æ‰“å¼€ä¸€ä¸ªæ–°çª—å£ä»¥æ¯”è¾ƒä¸¤ä¸ªå†å²è¯†åˆ«ç»“æœ"""
        # è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„åŠŸèƒ½ï¼Œéœ€è¦å•ç‹¬çš„UIæ¥é€‰æ‹©ä¸¤ä¸ªå†å²ç»“æœå¹¶è¿›è¡Œæ¯”è¾ƒ
        # æš‚æ—¶åªå¼¹å‡ºä¸€ä¸ªæç¤ºæ¡†ï¼Œå®é™…åŠŸèƒ½å¾…å®ç°
        messagebox.showinfo("åŠŸèƒ½å¾…å®ç°", "æ¯”è¾ƒç»“æœåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼")
        self.log_message("â„¹ï¸ æ¯”è¾ƒç»“æœåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ã€‚", 'INFO')

    def copy_recognized_text(self):
        """å¤åˆ¶è¯†åˆ«åˆ°çš„çº¯æ–‡æœ¬åˆ°å‰ªè´´æ¿"""
        text = self.report_text.get(1.0, tk.END).strip()
        if text:
            try:
                self.root.clipboard_clear()
                self.root.clipboard_append(text)
                self.log_message("ğŸ“‹ è¯†åˆ«æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ã€‚", 'SUCCESS')
            except Exception as e:
                self.log_message(f"âŒ å¤åˆ¶æ–‡æœ¬åˆ°å‰ªè´´æ¿å¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("å¤åˆ¶å¤±è´¥", f"æ— æ³•å¤åˆ¶æ–‡æœ¬åˆ°å‰ªè´´æ¿:\n{e}")
        else:
            messagebox.showwarning("æ— æ–‡æœ¬", "æ²¡æœ‰å¯å¤åˆ¶çš„è¯†åˆ«æ–‡æœ¬ã€‚")

    def save_recognized_text(self):
        """ä¿å­˜è¯†åˆ«åˆ°çš„çº¯æ–‡æœ¬åˆ°æ–‡ä»¶"""
        text = self.report_text.get(1.0, tk.END).strip()
        if not text:
            messagebox.showwarning("æ— æ–‡æœ¬", "æ²¡æœ‰å¯ä¿å­˜çš„è¯†åˆ«æ–‡æœ¬ã€‚")
            return
        
        file_path = filedialog.asksaveasfilename(
            defaultextension=".txt",
            filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")],
            title="ä¿å­˜è¯†åˆ«æ–‡æœ¬"
        )
        
        if file_path:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(text)
                self.log_message(f"ğŸ’¾ è¯†åˆ«æ–‡æœ¬å·²ä¿å­˜åˆ°: {file_path}", 'SUCCESS')
                messagebox.showinfo("ä¿å­˜æˆåŠŸ", f"è¯†åˆ«æ–‡æœ¬å·²æˆåŠŸä¿å­˜åˆ°:\n{file_path}")
            except Exception as e:
                self.log_message(f"âŒ ä¿å­˜è¯†åˆ«æ–‡æœ¬å¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("ä¿å­˜å¤±è´¥", f"ä¿å­˜è¯†åˆ«æ–‡æœ¬å¤±è´¥:\n{e}")

    def search_text_dialog(self):
        """åœ¨å½“å‰æŠ¥å‘Šæ–‡æœ¬ä¸­æœç´¢"""
        search_window = tk.Toplevel(self.root)
        search_window.title("æœç´¢æ–‡æœ¬")
        search_window.geometry("400x150")
        search_window.transient(self.root)
        search_window.grab_set()

        search_frame = ttk.Frame(search_window, padding=design.get_spacing('4'))
        search_frame.pack(fill='both', expand=True)

        tk.Label(search_frame, text="æœç´¢å†…å®¹:", bg=design.get_color('neutral', '50')).pack(anchor='w', pady=(0, design.get_spacing('1')))
        search_entry = ttk.Entry(search_frame, width=40)
        search_entry.pack(fill='x', pady=(0, design.get_spacing('2')))
        search_entry.focus_set()

        def perform_search():
            query = search_entry.get()
            if not query:
                return

            text_content = self.report_text.get(1.0, tk.END)
            start_index = "1.0"
            count = tk.IntVar()
            
            self.report_text.tag_remove("search_highlight", "1.0", tk.END) # æ¸…é™¤æ—§é«˜äº®
            
            while True:
                start_index = self.report_text.search(query, start_index, stopindex=tk.END, count=count, nocase=True)
                if not start_index:
                    break
                end_index = self.report_text.index(f"{start_index}+{len(query)}c")
                self.report_text.tag_add("search_highlight", start_index, end_index)
                start_index = end_index
            
            self.report_text.tag_config("search_highlight", background="yellow", foreground="black")
            
            if count.get() > 0:
                self.log_message(f"ğŸ” åœ¨æŠ¥å‘Šä¸­æ‰¾åˆ° '{query}' {count.get()} æ¬¡ã€‚", 'INFO')
                messagebox.showinfo("æœç´¢ç»“æœ", f"æ‰¾åˆ° '{query}' {count.get()} æ¬¡ã€‚")
            else:
                self.log_message(f"ğŸ” åœ¨æŠ¥å‘Šä¸­æœªæ‰¾åˆ° '{query}'ã€‚", 'INFO')
                messagebox.showinfo("æœç´¢ç»“æœ", f"æœªæ‰¾åˆ° '{query}'ã€‚")

            search_window.destroy()

        search_button = tk.Button(search_frame, text="æœç´¢", command=perform_search)
        design.apply_button_style(search_button, 'primary')
        search_button.pack(pady=(design.get_spacing('2'), 0))

        search_entry.bind("<Return>", lambda event: perform_search())

    def analyze_text(self):
        """å¯¹å½“å‰è¯†åˆ«æŠ¥å‘Šè¿›è¡Œæ–‡æœ¬åˆ†æ"""
        full_text = self.report_text.get(1.0, tk.END).strip()
        if not full_text:
            messagebox.showwarning("æ— æ–‡æœ¬", "æ²¡æœ‰å¯åˆ†æçš„æ–‡æœ¬ã€‚")
            return

        analysis_report = []
        analysis_report.append("--- æ–‡æœ¬åˆ†ææŠ¥å‘Š ---\n")
        
        # å­—ç¬¦æ•° (åŒ…æ‹¬ç©ºæ ¼)
        char_count = len(full_text)
        analysis_report.append(f"æ€»å­—ç¬¦æ•° (å«ç©ºæ ¼): {char_count}\n")

        # å­—ç¬¦æ•° (ä¸å«ç©ºæ ¼)
        char_count_no_spaces = len(full_text.replace(" ", "").replace("\n", "").replace("\t", ""))
        analysis_report.append(f"æ€»å­—ç¬¦æ•° (ä¸å«ç©ºæ ¼): {char_count_no_spaces}\n")
        
        # è¯æ±‡æ•°
        words = full_text.split()
        word_count = len(words)
        analysis_report.append(f"æ€»è¯æ±‡æ•°: {word_count}\n")
        
        # å¹³å‡è¯é•¿
        if word_count > 0:
            avg_word_length = sum(len(word) for word in words) / word_count
            analysis_report.append(f"å¹³å‡è¯é•¿: {avg_word_length:.2f}\n")
        
        # å”¯ä¸€è¯æ±‡æ•°
        unique_words = set(w.lower() for w in words)
        unique_word_count = len(unique_words)
        analysis_report.append(f"å”¯ä¸€è¯æ±‡æ•°: {unique_word_count}\n")

        # è¡Œæ•°
        line_count = full_text.count('\n') + 1 # å‡è®¾è‡³å°‘æœ‰ä¸€è¡Œ
        analysis_report.append(f"æ€»è¡Œæ•°: {line_count}\n")

        # æœ€å¸¸è§è¯æ±‡
        if word_count > 0:
            from collections import Counter
            word_frequencies = Counter(w.lower() for w in words)
            most_common_words = word_frequencies.most_common(5)
            analysis_report.append("\næœ€å¸¸è§è¯æ±‡ (å‰5):\n")
            for word, freq in most_common_words:
                analysis_report.append(f"  - {word}: {freq} æ¬¡\n")

        # è¯­è¨€åˆ†å¸ƒ (å¦‚æœç»“æœä¸­åŒ…å«)
        if self.result_manager.current_results and 'language' in self.result_manager.current_results:
            analysis_report.append(f"\næ£€æµ‹è¯­è¨€: {self.result_manager.current_results['language']}\n")
        
        # æ€»ä½“ç½®ä¿¡åº¦ (å¦‚æœç»“æœä¸­åŒ…å«)
        if self.result_manager.current_results and 'average_confidence' in self.result_manager.current_results:
            analysis_report.append(f"å¹³å‡ç½®ä¿¡åº¦: {self.result_manager.current_results['average_confidence']:.2f}%\n")
        
        analysis_report.append(f"\næŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # åœ¨æ–°çª—å£ä¸­æ˜¾ç¤ºæŠ¥å‘Š
        analysis_window = tk.Toplevel(self.root)
        analysis_window.title("æ–‡æœ¬åˆ†ææŠ¥å‘Š")
        analysis_window.geometry("600x500")
        analysis_window.transient(self.root)
        analysis_window.grab_set()

        analysis_text_area = scrolledtext.ScrolledText(analysis_window, wrap='word', 
                                                       font=design.get_font('body'),
                                                       bg=design.get_color('neutral', '0'),
                                                       fg=design.get_color('neutral', '800'))
        analysis_text_area.pack(fill='both', expand=True, padx=design.get_spacing('2'), pady=design.get_spacing('2'))
        analysis_text_area.insert(tk.END, "".join(analysis_report))
        analysis_text_area.config(state='disabled')
        
        self.log_message("ğŸ“Š å·²ç”Ÿæˆæ–‡æœ¬åˆ†ææŠ¥å‘Šã€‚", 'INFO')

    def refresh_history(self):
        """åˆ·æ–°å†å²è®°å½•åˆ—è¡¨"""
        self.history_tree.delete(*self.history_tree.get_children())
        history_entries = self.result_manager.get_history()
        
        for i, entry in enumerate(history_entries):
            components = entry.get('cvocr_components', {})
            used_components_str = "+".join([k.replace('_used', '') for k, v in components.items() if v]) if components else "Tesseract"
            
            status = "æˆåŠŸ" 
            if 'error' in entry.get('results', {}):
                status = "é”™è¯¯"
            elif entry.get('total_blocks', 0) == 0 and entry.get('full_text', '') == '':
                status = "æ— æ–‡æœ¬" # Differentiate from a processing 'error'

            self.history_tree.insert('', 'end', values=(
                datetime.fromisoformat(entry['timestamp']).strftime('%Y-%m-%d %H:%M:%S'),
                entry['image_name'],
                entry.get('total_blocks', 0),
                entry.get('total_characters', 0),
                f"{entry.get('avg_confidence', 0):.1f}%",
                used_components_str,
                status,
                f"{entry.get('processing_time', 0):.2f}s"
            ), iid=entry['id'])
        
        self.log_message(f"ğŸ“š å†å²è®°å½•å·²åˆ·æ–°ï¼Œå…± {len(history_entries)} æ¡è®°å½•ã€‚", 'INFO')

    def export_history(self):
        """å¯¼å‡ºæ‰€æœ‰å†å²è®°å½•"""
        if not self.result_manager.history:
            messagebox.showwarning("æ— å†å²è®°å½•", "æ²¡æœ‰å¯å¯¼å‡ºçš„å†å²è®°å½•ã€‚")
            return
        
        file_options = [
            ("JSONæ–‡ä»¶", "*.json"),
            ("CSVæ–‡ä»¶", "*.csv"),
            ("æ‰€æœ‰æ–‡ä»¶", "*.*")
        ]
        
        file_path = filedialog.asksaveasfilename(
            defaultextension=".json",
            filetypes=file_options,
            title="å¯¼å‡ºå†å²è®°å½•"
        )
        
        if file_path:
            try:
                extension = os.path.splitext(file_path)[1].lower()
                success, msg = self.result_manager.export_history(file_path, export_format=extension.lstrip('.'))
                if success:
                    self.log_message(f"ğŸ“¤ å†å²è®°å½•å·²å¯¼å‡ºåˆ°: {file_path}", 'SUCCESS')
                    messagebox.showinfo("å¯¼å‡ºæˆåŠŸ", f"å†å²è®°å½•å·²æˆåŠŸå¯¼å‡ºåˆ°:\n{file_path}")
                else:
                    self.log_message(f"âŒ å¯¼å‡ºå†å²è®°å½•å¤±è´¥: {msg}", 'ERROR')
                    messagebox.showerror("å¯¼å‡ºå¤±è´¥", f"å¯¼å‡ºå†å²è®°å½•å¤±è´¥:\n{msg}")
            except Exception as e:
                self.log_message(f"âŒ å¯¼å‡ºå†å²è®°å½•å¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("å¯¼å‡ºå¤±è´¥", f"å¯¼å‡ºå†å²è®°å½•å¤±è´¥:\n{e}")

    def clear_history(self):
        """æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•"""
        if messagebox.askyesno("æ¸…ç©ºå†å²è®°å½•", "æ‚¨ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰å†å²è¯†åˆ«è®°å½•å—ï¼Ÿæ­¤æ“ä½œä¸å¯é€†ï¼"):
            if self.result_manager.clear_history(confirm=False):
                self.refresh_history()
                self.update_enhanced_stats()
                self.log_message("ğŸ§¹ æ‰€æœ‰å†å²è®°å½•å·²æˆåŠŸæ¸…ç©ºã€‚", 'SUCCESS')
            else:
                self.log_message("âŒ æ¸…ç©ºå†å²è®°å½•å¤±è´¥ã€‚", 'ERROR')

    def search_history_dialog(self):
        """æ‰“å¼€æœç´¢å†å²è®°å½•çš„å¯¹è¯æ¡†"""
        search_window = tk.Toplevel(self.root)
        search_window.title("æœç´¢å†å²è®°å½•")
        search_window.geometry("450x200")
        search_window.transient(self.root)
        search_window.grab_set()

        search_frame = ttk.Frame(search_window, padding=design.get_spacing('4'))
        search_frame.pack(fill='both', expand=True)

        tk.Label(search_frame, text="æœç´¢å…³é”®è¯:", bg=design.get_color('neutral', '50')).pack(anchor='w', pady=(0, design.get_spacing('1')))
        search_entry = ttk.Entry(search_frame, width=50)
        search_entry.pack(fill='x', pady=(0, design.get_spacing('2')))
        search_entry.focus_set()

        search_in_text_var = tk.BooleanVar(value=True)
        search_in_filename_var = tk.BooleanVar(value=True)

        ttk.Checkbutton(search_frame, text="åœ¨è¯†åˆ«æ–‡æœ¬ä¸­æœç´¢", variable=search_in_text_var).pack(anchor='w')
        ttk.Checkbutton(search_frame, text="åœ¨å›¾ç‰‡åç§°ä¸­æœç´¢", variable=search_in_filename_var).pack(anchor='w')

        def perform_search():
            query = search_entry.get()
            if not query:
                return

            results = self.result_manager.search_results(
                query,
                search_in_text=search_in_text_var.get(),
                search_in_filename=search_in_filename_var.get()
            )
            
            # æ¸…ç©ºå½“å‰å†å²æ ‘å¹¶æ˜¾ç¤ºæœç´¢ç»“æœ
            self.history_tree.delete(*self.history_tree.get_children())
            if not results:
                self.history_tree.insert('', 'end', values=("", "æ— æœç´¢ç»“æœ", "", "", "", "", "", ""))
            else:
                for i, entry in enumerate(results):
                    components = entry.get('cvocr_components', {})
                    used_components_str = "+".join([k.replace('_used', '') for k, v in components.items() if v]) if components else "Tesseract"
                    status = "æˆåŠŸ" 
                    if 'error' in entry.get('results', {}):
                        status = "é”™è¯¯"
                    elif entry.get('total_blocks', 0) == 0 and entry.get('full_text', '') == '':
                        status = "æ— æ–‡æœ¬"
                    self.history_tree.insert('', 'end', values=(
                        datetime.fromisoformat(entry['timestamp']).strftime('%Y-%m-%d %H:%M:%S'),
                        entry['image_name'],
                        entry.get('total_blocks', 0),
                        entry.get('total_characters', 0),
                        f"{entry.get('avg_confidence', 0):.1f}%",
                        used_components_str,
                        status,
                        f"{entry.get('processing_time', 0):.2f}s"
                    ), iid=entry['id'])
            
            self.log_message(f"ğŸ” å†å²è®°å½•æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results)} æ¡åŒ¹é…é¡¹ã€‚", 'INFO')
            messagebox.showinfo("æœç´¢å®Œæˆ", f"æ‰¾åˆ° {len(results)} æ¡åŒ¹é…é¡¹ã€‚")
            search_window.destroy()
            self.notebook.select(3) # åˆ‡æ¢åˆ°å†å²è®°å½•æ ‡ç­¾é¡µ

        search_button = tk.Button(search_frame, text="æœç´¢", command=perform_search)
        design.apply_button_style(search_button, 'primary')
        search_button.pack(pady=(design.get_spacing('2'), 0))
        search_entry.bind("<Return>", lambda event: perform_search())

    def on_history_double_click(self, event):
        """å¤„ç†å†å²è®°å½•åŒå‡»äº‹ä»¶ï¼Œé‡æ–°åŠ è½½å¹¶æ˜¾ç¤ºç»“æœ"""
        item_id = self.history_tree.focus()
        if not item_id:
            return

        result_id = self.history_tree.item(item_id, 'iid')
        entry = self.result_manager.get_result_by_id(result_id)

        if entry:
            self.log_message(f"ğŸ”„ æ­£åœ¨ä»å†å²è®°å½•åŠ è½½: {entry['image_name']}", 'INFO')
            self.current_image_path = entry['image_path']
            # Pass the entry's 'results' dict directly as if it came from recognition
            self._handle_recognition_result(entry['image_path'], entry['results'], "ä»å†å²è®°å½•åŠ è½½")
            self.notebook.select(0) # åˆ‡æ¢åˆ°å›¾ç‰‡é¢„è§ˆ

    def on_history_right_click(self, event):
        """å¤„ç†å†å²è®°å½•å³é”®ç‚¹å‡»äº‹ä»¶ï¼Œæ˜¾ç¤ºä¸Šä¸‹æ–‡èœå•"""
        item_id = self.history_tree.identify_row(event.y)
        if not item_id:
            return

        self.history_tree.selection_set(item_id) # é€‰ä¸­å³é”®ç‚¹å‡»çš„é¡¹
        result_id = self.history_tree.item(item_id, 'iid')
        entry = self.result_manager.get_result_by_id(result_id)

        if entry:
            menu = tk.Menu(self.root, tearoff=0)
            menu.add_command(label="ğŸ”„ åŠ è½½æ­¤ç»“æœ", command=lambda: self.on_history_double_click(None))
            menu.add_command(label="ğŸ“ åœ¨æ–‡ä»¶æµè§ˆå™¨ä¸­æ‰“å¼€å›¾ç‰‡", command=lambda: self.show_in_explorer_for_history(entry['image_path']))
            menu.add_command(label="ğŸ“‹ å¤åˆ¶çº¯æ–‡æœ¬", command=lambda: self.copy_text_from_history(entry['full_text']))
            menu.add_command(label="ğŸ“¤ å¯¼å‡ºæ­¤ç»“æœ (JSON)", command=lambda: self.export_single_history_result(entry))
            menu.add_command(label="ğŸ—‘ï¸ åˆ é™¤æ­¤å†å²è®°å½•", command=lambda: self.delete_history_item(result_id))
            
            menu.post(event.x_root, event.y_root)

    def show_in_explorer_for_history(self, image_path: str):
        """ä¸ºå†å²è®°å½•ä¸­çš„å›¾ç‰‡åœ¨æ–‡ä»¶æµè§ˆå™¨ä¸­æ‰“å¼€"""
        self.current_image_path = image_path # æš‚æ—¶è®¾ç½®å½“å‰å›¾ç‰‡è·¯å¾„
        self.show_in_explorer()
        
    def copy_text_from_history(self, text: str):
        """å¤åˆ¶å†å²è®°å½•ä¸­çš„æ–‡æœ¬åˆ°å‰ªè´´æ¿"""
        if text:
            try:
                self.root.clipboard_clear()
                self.root.clipboard_append(text)
                self.log_message("ğŸ“‹ å†å²è®°å½•æ–‡æœ¬å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ã€‚", 'SUCCESS')
            except Exception as e:
                self.log_message(f"âŒ å¤åˆ¶å†å²è®°å½•æ–‡æœ¬å¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("å¤åˆ¶å¤±è´¥", f"æ— æ³•å¤åˆ¶æ–‡æœ¬åˆ°å‰ªè´´æ¿:\n{e}")
        else:
            messagebox.showwarning("æ— æ–‡æœ¬", "è¯¥å†å²è®°å½•æ²¡æœ‰æ–‡æœ¬å†…å®¹ã€‚")

    def export_single_history_result(self, entry: Dict):
        """å¯¼å‡ºå•ä¸ªå†å²è®°å½•ç»“æœ"""
        file_path = filedialog.asksaveasfilename(
            defaultextension=".json",
            filetypes=[("JSONæ–‡ä»¶", "*.json"), ("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")],
            title=f"å¯¼å‡º '{entry['image_name']}' çš„ç»“æœ"
        )
        
        if file_path:
            try:
                extension = os.path.splitext(file_path)[1].lower()
                
                if extension == ".json":
                    with open(file_path, 'w', encoding='utf-8') as f:
                        json.dump(entry, f, ensure_ascii=False, indent=2)
                elif extension == ".txt":
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(entry.get('full_text', ''))
                else:
                    messagebox.showwarning("ä¸æ”¯æŒçš„æ ¼å¼", "è¯·é€‰æ‹©JSONæˆ–TXTæ ¼å¼è¿›è¡Œå¯¼å‡ºã€‚")
                    self.log_message(f"âŒ å¯¼å‡ºå†å²ç»“æœå¤±è´¥ï¼šä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ {extension}ã€‚", 'ERROR')
                    return
                
                self.log_message(f"ğŸ“¤ å†å²ç»“æœå·²å¯¼å‡ºåˆ°: {file_path}", 'SUCCESS')
                messagebox.showinfo("å¯¼å‡ºæˆåŠŸ", f"ç»“æœå·²æˆåŠŸå¯¼å‡ºåˆ°:\n{file_path}")
            except Exception as e:
                self.log_message(f"âŒ å¯¼å‡ºå†å²ç»“æœå¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("å¯¼å‡ºå¤±è´¥", f"å¯¼å‡ºç»“æœå¤±è´¥:\n{e}")

    def delete_history_item(self, result_id: str):
        """ä»å†å²è®°å½•ä¸­åˆ é™¤æŒ‡å®šçš„é¡¹"""
        if messagebox.askyesno("åˆ é™¤å†å²è®°å½•", "æ‚¨ç¡®å®šè¦åˆ é™¤æ­¤å†å²è®°å½•å—ï¼Ÿæ­¤æ“ä½œä¸å¯é€†ï¼"):
            # åœ¨ result_manager ä¸­åˆ é™¤
            for i, entry in enumerate(self.result_manager.history):
                if entry['id'] == result_id:
                    del self.result_manager.history[i]
                    self.result_manager._results_cache.pop(result_id, None)
                    break
            self.refresh_history()
            self.update_enhanced_stats()
            self.log_message(f"ğŸ—‘ï¸ å·²åˆ é™¤å†å²è®°å½•é¡¹: {result_id}", 'INFO')

    def update_enhanced_stats(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯æ ‡ç­¾é¡µçš„æ˜¾ç¤ºå†…å®¹"""
        stats = self.result_manager.get_stats()
        cvocr_perf = self.cvocr_manager.get_performance_stats() # Get performance stats from manager itself
        img_proc_perf = self.image_processor.get_processing_stats()

        stats_report = []
        stats_report.append("--- CVOCR ç»¼åˆç»Ÿè®¡æŠ¥å‘Š ---\n")
        stats_report.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        stats_report.append("-" * 40 + "\n")

        stats_report.append("=== è¯†åˆ«æ€»è§ˆ ===\n")
        stats_report.append(f"æ€»è¯†åˆ«ä»»åŠ¡æ•°: {cvocr_perf.get('total_recognitions', 0)}\n") # Use cvocr_perf for consistency
        stats_report.append(f"æˆåŠŸè¯†åˆ«ä»»åŠ¡æ•°: {cvocr_perf.get('successful_recognitions', 0)}\n")
        stats_report.append(f"å¤±è´¥è¯†åˆ«ä»»åŠ¡æ•°: {cvocr_perf.get('failed_recognitions', 0)}\n")
        stats_report.append(f"æˆåŠŸç‡: {stats.get('success_rate', 0):.2f}%\n") # success_rate is calculated by result_manager
        stats_report.append(f"æ€»å­—ç¬¦æ•°: {stats.get('total_characters_recognized', 0)}\n")
        stats_report.append(f"æ€»å¤„ç†æ—¶é—´: {stats.get('total_processing_time', 0):.2f} ç§’\n")
        stats_report.append(f"å¹³å‡å¤„ç†æ—¶é—´/ä»»åŠ¡: {stats.get('average_processing_time', 0):.2f} ç§’\n")
        stats_report.append(f"å¹³å‡ç½®ä¿¡åº¦: {stats.get('average_confidence', 0):.2f}%\n")
        stats_report.append("-" * 40 + "\n")

        stats_report.append("=== è¯­è¨€åˆ†å¸ƒ ===\n")
        if stats.get('language_distribution'):
            for lang, count in stats['language_distribution'].items():
                stats_report.append(f"  {lang}: {count} æ¬¡\n")
            stats_report.append(f"æœ€å¸¸ç”¨è¯­è¨€: {stats.get('most_used_language', 'N/A')}\n")
        else:
            stats_report.append("  æ— è¯­è¨€ç»Ÿè®¡æ•°æ®ã€‚\n")
        stats_report.append("-" * 40 + "\n")

        stats_report.append("=== ç»„ä»¶ä½¿ç”¨æƒ…å†µ ===\n")
        if cvocr_perf.get('component_usage'): # Use cvocr_perf for consistency
            for comp, count in cvocr_perf['component_usage'].items():
                stats_report.append(f"  {comp}: {count} æ¬¡\n")
        else:
            stats_report.append("  æ— ç»„ä»¶ä½¿ç”¨ç»Ÿè®¡æ•°æ®ã€‚\n")
        stats_report.append("-" * 40 + "\n")

        stats_report.append("=== å›¾åƒé¢„å¤„ç†ç»Ÿè®¡ ===\n")
        stats_report.append(f"æ€»é¢„å¤„ç†å›¾åƒæ•°: {img_proc_perf.get('total_processed', 0)}\n")
        stats_report.append(f"ç¼“å­˜å‘½ä¸­æ¬¡æ•°: {img_proc_perf.get('cache_hits', 0)}\n")
        stats_report.append(f"ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°: {img_proc_perf.get('cache_misses', 0)}\n")
        stats_report.append(f"ç¼“å­˜å‘½ä¸­ç‡: {img_proc_perf.get('cache_hit_rate', 0):.2f}%\n")
        stats_report.append(f"å¹³å‡é¢„å¤„ç†æ—¶é—´: {img_proc_perf.get('average_processing_time', 0):.2f} ç§’\n")
        stats_report.append("-" * 40 + "\n")

        self.stats_text.config(state='normal')
        self.stats_text.delete(1.0, tk.END)
        self.stats_text.insert(tk.END, "".join(stats_report))
        self.stats_text.config(state='disabled')
        
        self.log_message(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯å·²æ›´æ–°ã€‚", 'INFO')

    def export_stats(self):
        """å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯åˆ°æ–‡ä»¶"""
        stats = self.result_manager.get_stats()
        processor_stats = self.image_processor.get_processing_stats()
        cvocr_manager_perf_stats = self.cvocr_manager.get_performance_stats() # Get performance stats from manager

        export_data = {
            "timestamp": datetime.now().isoformat(),
            "cvocr_version": CVOCRConstants.VERSION,
            "recognition_overall_stats_from_result_manager": stats, # Renamed for clarity
            "cvocr_manager_performance_stats": cvocr_manager_perf_stats, # Added
            "preprocessing_stats": processor_stats
        }

        file_path = filedialog.asksaveasfilename(
            defaultextension=".json",
            filetypes=[("JSONæ–‡ä»¶", "*.json"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")],
            title="å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯"
        )
        
        if file_path:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
                self.log_message(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²å¯¼å‡ºåˆ°: {file_path}", 'SUCCESS')
                messagebox.showinfo("å¯¼å‡ºæˆåŠŸ", f"ç»Ÿè®¡ä¿¡æ¯å·²æˆåŠŸå¯¼å‡ºåˆ°:\n{file_path}")
            except Exception as e:
                self.log_message(f"âŒ å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("å¯¼å‡ºå¤±è´¥", f"å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯å¤±è´¥:\n{e}")

    def reset_stats(self):
        """é‡ç½®æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯"""
        if messagebox.askyesno("é‡ç½®ç»Ÿè®¡ä¿¡æ¯", "æ‚¨ç¡®å®šè¦é‡ç½®æ‰€æœ‰ç»Ÿè®¡æ•°æ®å—ï¼Ÿæ­¤æ“ä½œä¸å¯é€†ï¼"):
            self.result_manager.clear_history(confirm=False) # æ¸…ç©ºå†å²ä¼šé‡ç½®å…¶ç»Ÿè®¡
            self.cvocr_manager.clear_performance_stats()
            self.image_processor.clear_cache()
            self.update_enhanced_stats()
            self.log_message("ğŸ”„ æ‰€æœ‰ç»Ÿè®¡æ•°æ®å’Œç¼“å­˜å·²é‡ç½®ã€‚", 'SUCCESS')

    def compare_images(self):
        """æ¯”è¾ƒä¸¤å¼ å›¾ç‰‡çš„å¤„ç†æ•ˆæœï¼ˆå¾…å®ç°å¤æ‚UIï¼‰"""
        messagebox.showinfo("åŠŸèƒ½å¾…å®ç°", "å›¾ç‰‡æ¯”è¾ƒåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼")
        self.log_message("â„¹ï¸ å›¾ç‰‡æ¯”è¾ƒåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ã€‚", 'INFO')

    def compare_methods(self):
        """æ¯”è¾ƒä¸åŒOCRæ–¹æ³•æˆ–é…ç½®çš„è¯†åˆ«æ•ˆæœï¼ˆå¾…å®ç°å¤æ‚UIï¼‰"""
        messagebox.showinfo("åŠŸèƒ½å¾…å®ç°", "æ–¹æ³•æ¯”è¾ƒåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼")
        self.log_message("â„¹ï¸ æ–¹æ³•æ¯”è¾ƒåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ã€‚", 'INFO')

    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—æ˜¾ç¤ºåŒº"""
        self.log_text.config(state='normal')
        self.log_text.delete(1.0, tk.END)
        self.log_text.config(state='disabled')
        self.log_message("ğŸ§¹ æ—¥å¿—å·²æ¸…ç©ºã€‚", 'INFO')

    def save_log(self):
        """ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶"""
        log_content = self.log_text.get(1.0, tk.END).strip()
        if not log_content:
            messagebox.showwarning("æ— æ—¥å¿—", "æ²¡æœ‰å¯ä¿å­˜çš„æ—¥å¿—å†…å®¹ã€‚")
            return
        
        file_path = filedialog.asksaveasfilename(
            defaultextension=".log",
            filetypes=[("æ—¥å¿—æ–‡ä»¶", "*.log"), ("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")],
            title="ä¿å­˜æ—¥å¿—"
        )
        
        if file_path:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(log_content)
                self.log_message(f"ğŸ’¾ æ—¥å¿—å·²ä¿å­˜åˆ°: {file_path}", 'SUCCESS')
                messagebox.showinfo("ä¿å­˜æˆåŠŸ", f"æ—¥å¿—å·²æˆåŠŸä¿å­˜åˆ°:\n{file_path}")
            except Exception as e:
                self.log_message(f"âŒ ä¿å­˜æ—¥å¿—å¤±è´¥: {e}", 'ERROR')
                messagebox.showerror("ä¿å­˜å¤±è´¥", f"ä¿å­˜æ—¥å¿—å¤±è´¥:\n{e}")

    def on_closing(self):
        """å¤„ç†çª—å£å…³é—­äº‹ä»¶ï¼Œç¡®ä¿åªæ‰§è¡Œä¸€æ¬¡"""
        # å¦‚æœæ­£åœ¨å…³é—­æˆ–å·²ç»å…³é—­ï¼Œåˆ™ç›´æ¥è¿”å›
        if self._is_closing:
            return

        self._is_closing = True
        
        try:
            # 1. ä¿å­˜è®¾ç½®
            self._save_settings()
            self.log_message("ğŸ‘‹ CVOCRå¢å¼ºç‰ˆæ­£åœ¨é€€å‡º...", 'INFO')
        
            # 2. å¹²å‡€åœ°å…³é—­åå°çº¿ç¨‹å’Œå¾ªç¯
            # å…³é—­ AsyncOCRProcessor çš„çº¿ç¨‹æ± 
            if hasattr(self, 'async_ocr_processor'):
                self.async_ocr_processor.shutdown()

            # åœæ­¢ asyncio äº‹ä»¶å¾ªç¯
            if self.loop and self.loop.is_running():
                # æäº¤ä¸€ä¸ªä»»åŠ¡æ¥åœæ­¢å¾ªç¯
                self.loop.call_soon_threadsafe(self.loop.stop)
                # ç­‰å¾…äº‹ä»¶å¾ªç¯çº¿ç¨‹ç»“æŸï¼Œé¿å…ä¸»è¿›ç¨‹æå‰é€€å‡º
                if hasattr(self, 'async_loop_thread') and self.async_loop_thread.is_alive():
                    self.async_loop_thread.join(timeout=2) # ç­‰å¾…æœ€å¤š2ç§’
                    if self.async_loop_thread.is_alive():
                        logger.warning("Asyncio event loop thread did not terminate gracefully.")
                # åœ¨ä¸»çº¿ç¨‹ä¸­å…³é—­å¾ªç¯
                self.loop.close()
                logger.info("Asyncio event loop closed.")
        except Exception as e:
            logger.error(f"Error during shutdown cleanup: {e}", exc_info=True)
        finally:
            # 3. æœ€åé”€æ¯Tkinterçª—å£
            # ç¡®ä¿å³ä½¿æ¸…ç†å¤±è´¥ï¼Œçª—å£ä¹Ÿèƒ½è¢«é”€æ¯
            if self.root:
                self.root.destroy()

    def add_debug_monitoring(self):
        """æ·»åŠ è°ƒè¯•ç›‘æ§ï¼Œå®šæœŸæ›´æ–°æ€§èƒ½æ˜¾ç¤º"""
        self.root.after(1000, self._update_performance_display) # æ¯ç§’æ›´æ–°ä¸€æ¬¡

    def _update_performance_display(self):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡æ˜¾ç¤º"""
        cvocr_perf = self.cvocr_manager.get_performance_stats()
        img_proc_perf = self.image_processor.get_processing_stats()

        # CVOCRè¯†åˆ«æ€§èƒ½
        avg_rec_time = cvocr_perf.get('average_recognition_time', 0)
        total_recs = cvocr_perf.get('total_recognitions', 0)
        success_recs = cvocr_perf.get('successful_recognitions', 0)
        rec_rate = (success_recs / total_recs * 100) if total_recs > 0 else 0

        # å›¾åƒå¤„ç†ç¼“å­˜æ€§èƒ½
        cache_hit_rate = img_proc_perf.get('cache_hit_rate', 0)
        
        perf_text = (
            f"è¯†åˆ«: {total_recs}æ¬¡ | æˆåŠŸ: {success_recs} ({rec_rate:.1f}%) | "
            f"å¹³å‡è¯†åˆ«: {avg_rec_time:.2f}s | ç¼“å­˜å‘½ä¸­: {cache_hit_rate:.1f}%"
        )
        self.performance_label.config(text=perf_text)
        
        self.root.after(1000, self._update_performance_display) # å†æ¬¡è°ƒåº¦

    def on_text_result_double_click(self, event):
        """å¤„ç†è¯¦ç»†ç»“æœæ ‘çš„åŒå‡»äº‹ä»¶ï¼Œåœ¨å›¾ç‰‡ä¸Šé«˜äº®å¯¹åº”åŒºåŸŸ"""
        item_id = self.results_tree.focus()
        if not item_id or not self.current_image_path:
            return

        idx = int(item_id.split('_')[1]) # ä» item_id (e.g., "block_0") è·å–ç´¢å¼•
        current_results_data = self.result_manager.current_results
        if not current_results_data or idx >= len(current_results_data.get('text_blocks', [])):
            return

        selected_block = current_results_data['text_blocks'][idx]
        bbox = selected_block.get('bbox')
        
        # --- æ ¸å¿ƒä¿®æ­£å¼€å§‹ ---
        # å¢åŠ å¯¹ bbox å’Œå…³é”®å®ä¾‹å˜é‡çš„æ£€æŸ¥
        if not bbox or len(bbox) != 4:
             self.log_message(f"æ— æ³•é«˜äº®ï¼šæ–‡æœ¬å— '{selected_block['text'][:20]}...' ç¼ºå°‘æœ‰æ•ˆçš„è¾¹ç•Œæ¡†ä¿¡æ¯ã€‚", "WARNING")
             return
             
        if not hasattr(self, '_last_display_scale_ratio_x') or \
           not hasattr(self, '_last_display_x_offset'):
            self.log_message("æ— æ³•é«˜äº®ï¼šç¼ºå°‘å›¾åƒæ˜¾ç¤ºå‚æ•°ã€‚è¯·ç¡®ä¿å›¾ç‰‡å·²æ­£ç¡®æ˜¾ç¤ºã€‚", "WARNING")
            return
        
        # æ¸…é™¤æ—§çš„é«˜äº®æ¡†
        self.image_canvas.delete("highlight_bbox")

        # ä»å®ä¾‹å˜é‡è·å–æ˜¾ç¤ºå‚æ•°
        scale_ratio_x = self._last_display_scale_ratio_x
        scale_ratio_y = self._last_display_scale_ratio_y
        x_offset = self._last_display_x_offset
        y_offset = self._last_display_y_offset

        # è½¬æ¢åŸå§‹åæ ‡åˆ°ç”»å¸ƒåæ ‡
        x1_orig, y1_orig, x2_orig, y2_orig = bbox
        x1_canvas = int(x1_orig * scale_ratio_x + x_offset)
        y1_canvas = int(y1_orig * scale_ratio_y + y_offset)
        x2_canvas = int(x2_orig * scale_ratio_x + x_offset)
        y2_canvas = int(y2_orig * scale_ratio_y + y_offset)
        
        # ç»˜åˆ¶é«˜äº®çŸ©å½¢æ¡†
        self.image_canvas.create_rectangle(
            x1_canvas, y1_canvas, x2_canvas, y2_canvas, 
            outline='blue', width=3, tags="highlight_bbox"
        )
        
        # --- æ»šåŠ¨é€»è¾‘ä¿æŒä¸å˜ï¼Œä½†åŸºäºæ­£ç¡®çš„åæ ‡ ---
        canvas_width = self.image_canvas.winfo_width()
        canvas_height = self.image_canvas.winfo_height()
        
        if self._last_original_image_size:
            original_img_width, original_img_height = self._last_original_image_size
            display_width = int(original_img_width * scale_ratio_x)
            display_height = int(original_img_height * scale_ratio_y)
            
            # ç¡®ä¿ display_width å’Œ display_height ä¸ä¸ºé›¶
            if display_width > 0 and display_height > 0:
                scroll_x = (x1_canvas + (x2_canvas - x1_canvas) / 2 - canvas_width / 2) / display_width
                scroll_y = (y1_canvas + (y2_canvas - y1_canvas) / 2 - canvas_height / 2) / display_height
                
                scroll_x = max(0.0, min(1.0, scroll_x))
                scroll_y = max(0.0, min(1.0, scroll_y))

                self.image_canvas.xview_moveto(scroll_x)
                self.image_canvas.yview_moveto(scroll_y)
        # --- æ ¸å¿ƒä¿®æ­£ç»“æŸ ---

        self.log_message(f"é«˜äº®æ˜¾ç¤ºæ–‡æœ¬å—: {selected_block['text'][:20]}...", 'INFO')
        self.notebook.select(0) # åˆ‡æ¢åˆ°å›¾ç‰‡é¢„è§ˆ

    def on_text_result_right_click(self, event):
        """å¤„ç†è¯¦ç»†ç»“æœæ ‘çš„å³é”®ç‚¹å‡»äº‹ä»¶"""
        item_id = self.results_tree.identify_row(event.y)
        if not item_id:
            return
        
        self.results_tree.selection_set(item_id)
        result_idx = int(self.results_tree.item(item_id, 'iid').split('_')[1])
        current_results_data = self.result_manager.current_results
        
        if current_results_data and result_idx < len(current_results_data.get('text_blocks', [])):
            selected_block = current_results_data['text_blocks'][result_idx]
            
            menu = tk.Menu(self.root, tearoff=0)
            menu.add_command(label="ğŸ“‹ å¤åˆ¶æ–‡æœ¬", command=lambda: self.copy_text_from_history(selected_block['text']))
            menu.add_command(label="ğŸ” åœ¨å›¾ç‰‡ä¸Šé«˜äº®æ˜¾ç¤º", command=lambda: self.on_text_result_double_click(None))
            menu.add_command(label="ğŸ—‘ï¸ ä»ç»“æœä¸­åˆ é™¤ (å¾…å®ç°)", state='disabled') # å¤æ‚åŠŸèƒ½ï¼Œæš‚ç¦ç”¨
            menu.post(event.x_root, event.y_root)

    def filter_results_dialog(self):
        """æ‰“å¼€è¿‡æ»¤è¯¦ç»†è¯†åˆ«ç»“æœçš„å¯¹è¯æ¡†"""
        messagebox.showinfo("åŠŸèƒ½å¾…å®ç°", "è¿‡æ»¤ç»“æœåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼")
        self.log_message("â„¹ï¸ è¿‡æ»¤ç»“æœåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ã€‚", 'INFO')

    def sort_results_dialog(self):
        """æ‰“å¼€æ’åºè¯¦ç»†è¯†åˆ«ç»“æœçš„å¯¹è¯æ¡†"""
        messagebox.showinfo("åŠŸèƒ½å¾…å®ç°", "æ’åºç»“æœåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼")
        self.log_message("â„¹ï¸ æ’åºç»“æœåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ã€‚", 'INFO')
    
    def generate_test_images(self):
        """ç”Ÿæˆæµ‹è¯•å›¾ç‰‡ (ç°åœ¨æ˜¯å¼‚æ­¥åç¨‹)"""
        async def generate_worker_async():
            self.log_message("ğŸ¨ æ­£åœ¨ç”Ÿæˆæµ‹è¯•å›¾ç‰‡...", 'INFO')
            try:
                # é˜»å¡æ“ä½œæ”¾å…¥çº¿ç¨‹æ± 
                success, message = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    TextTestImageGenerator.create_text_test_image,
                    "cvocr_test_2025.jpg",
                    True
                )
                self.root.after(0, self._handle_generate_test_image_result, success, message)
            except Exception as e:
                error_msg = f"ç”Ÿæˆæµ‹è¯•å›¾ç‰‡å¤±è´¥: {e}\n{traceback.format_exc()}"
                self.root.after(0, self._handle_generate_test_image_result, False, error_msg)
            finally:
                self.root.after(0, self.set_processing, False)
        
        self.set_processing(True)
        self.loop.call_soon_threadsafe(self.loop.create_task, generate_worker_async())
    def _handle_generate_test_image_result(self, success: bool, message: str):
        """å¤„ç†ç”Ÿæˆæµ‹è¯•å›¾ç‰‡çš„ç»“æœ"""
        if success:
            self.log_message(f"âœ… {message}", 'SUCCESS')
            self.current_image_path = "cvocr_test_2025.jpg"
            self.display_image(self.current_image_path)
            messagebox.showinfo("ç”ŸæˆæˆåŠŸ", message)
        else:
            self.log_message(f"âŒ {message}", 'ERROR')
            messagebox.showerror("ç”Ÿæˆå¤±è´¥", message)
    def preview_region_preprocessing(self):
        """å¯åŠ¨ä¸€ä¸ªå¼‚æ­¥ä»»åŠ¡ï¼Œä»¥é¢„è§ˆå•ä¸ªæ–‡æœ¬åŒºåŸŸçš„ç²¾ç»†åŒ–é¢„å¤„ç†æ•ˆæœã€‚"""
        if self.processing:
            messagebox.showwarning("å¤„ç†ä¸­", "å½“å‰æ­£åœ¨è¿›è¡Œå…¶ä»–æ“ä½œï¼Œè¯·ç¨å€™ã€‚")
            return
        if not self.current_image_path:
            messagebox.showwarning("æœªé€‰æ‹©å›¾ç‰‡", "è¯·å…ˆé€‰æ‹©ä¸€å¼ å›¾ç‰‡ã€‚")
            return
        if not self.cvocr_manager.is_initialized or not self.cvocr_manager.text_detector:
            messagebox.showerror("å¼•æ“æœªå°±ç»ª", "è¯·å…ˆåˆå§‹åŒ–CVOCRå¼•æ“ã€‚")
            return

        self.set_processing(True)
        self.log_message("ğŸ”¬ æ­£åœ¨ç”ŸæˆåŒºåŸŸé¢„å¤„ç†é¢„è§ˆ...", 'INFO')

        async def preview_worker_async():
            try:
                # æ­¥éª¤1: è·å–é¢„å¤„ç†åçš„æ•´å¼ å›¾
                preprocess_options = {key: var.get() for key, var in self.settings.items() if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar))}
                
                task_preprocess = functools.partial(
                    self.image_processor.intelligent_preprocess_image,
                    self.current_image_path,
                    **preprocess_options
                )
                processed_image_np, _, _ = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    task_preprocess
                )

                if processed_image_np is None: 
                    raise Exception("å›¾åƒé¢„å¤„ç†å¤±è´¥ã€‚")

                # æ­¥éª¤2: åœ¨é¢„å¤„ç†å›¾ä¸Šè¿›è¡Œåˆ†å‰²ï¼Œæ‰¾åˆ°åŒºåŸŸ
                enabled_algorithms = self._get_enabled_segmentation_algorithms()
                if not enabled_algorithms: 
                    raise Exception("è¯·è‡³å°‘é€‰æ‹©ä¸€ç§é«˜çº§åˆ†å‰²æŠ€æœ¯ã€‚")
                
                current_config = {key: var.get() for key, var in self.settings.items() if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar))}

                self.cvocr_manager.text_detector.config.update(current_config)
                
                task_detect = functools.partial(
                    self.cvocr_manager.text_detector.detect_text_regions_advanced,
                    processed_image_np, 
                    enabled_algorithms
                )
                regions, _ = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    task_detect
                )
                
                if not regions:
                    self.log_message("âš ï¸ é¢„è§ˆä¸­æ­¢ï¼šä½¿ç”¨å½“å‰åˆ†å‰²æŠ€æœ¯æœªæ£€æµ‹åˆ°ä»»ä½•æ–‡æœ¬åŒºåŸŸã€‚", "WARNING")
                    self.root.after(0, messagebox.showwarning, "é¢„è§ˆä¸­æ­¢", 
                                    "ä½¿ç”¨å½“å‰é€‰æ‹©çš„é«˜çº§åˆ†å‰²æŠ€æœ¯æœªèƒ½åœ¨æ­¤å›¾ç‰‡ä¸Šæ£€æµ‹åˆ°ä»»ä½•æ–‡æœ¬åŒºåŸŸã€‚\n\n"
                                    "è¯·å°è¯•ï¼š\n"
                                    "1. å‹¾é€‰ä¸åŒçš„åˆ†å‰²æŠ€æœ¯ï¼ˆå¦‚â€œæ”¹è¿›MSERâ€ï¼‰ã€‚\n"
                                    "2. è°ƒæ•´â€œé«˜çº§è®¾ç½®â€ä¸­çš„é¢„å¤„ç†é€‰é¡¹ã€‚\n"
                                    "3. ç‚¹å‡»â€œé¢„è§ˆåˆ†å‰²ç»“æœâ€æŸ¥çœ‹æ•´ä½“åˆ†å‰²æ•ˆæœã€‚")
                    return

                # æ­¥éª¤3: é€‰å–ç¬¬ä¸€ä¸ªåŒºåŸŸå¹¶è¿›è¡Œç²¾ç»†åŒ–é¢„å¤„ç†
                region_box = regions[0]
                rect = cv2.minAreaRect(region_box)
                center, (width, height), angle = rect

                # --- æœ€ç»ˆç‰ˆæ™ºèƒ½æ—‹è½¬é€»è¾‘ ---
                # æ­¥éª¤1: ç¡®ä¿ width >= heightï¼Œæ ‡å‡†åŒ–çŸ©å½¢æè¿°
                if width < height:
                    width, height = height, width
                    swapped = True
                else:
                    swapped = False
                
                # æ­¥éª¤2: ä»…å½“çŸ©å½¢åŸæœ¬æ˜¯ç˜¦é•¿çš„å‚ç›´å½¢çŠ¶æ—¶ï¼Œæ‰åº”ç”¨90åº¦æ—‹è½¬æ ¡æ­£
                aspect_ratio = width / height if height > 0 else 0
                if swapped and aspect_ratio > 1.5:
                    angle += 90
                # --- é€»è¾‘ç»“æŸ ---

                width, height = int(width), int(height)
                
                M = cv2.getRotationMatrix2D(center, angle, 1.0)
                warped_bgr = cv2.warpAffine(processed_image_np, M, (processed_image_np.shape[1], processed_image_np.shape[0]))
                cropped_bgr = cv2.getRectSubPix(warped_bgr, (width, height), center)

                if cropped_bgr is None or cropped_bgr.size == 0:
                    raise Exception("æ— æ³•ä»å›¾åƒä¸­åˆ‡å‰²å‡ºæœ‰æ•ˆçš„æ–‡æœ¬åŒºåŸŸã€‚")
                
                # åº”ç”¨ç²¾ç»†åŒ–é¢„å¤„ç†
                gray_cropped = cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2GRAY)
                h, w = gray_cropped.shape
                if h > 0 and (h < 24 or h > 64):
                    scale = 40.0 / h
                    gray_cropped = cv2.resize(gray_cropped, (0,0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
                
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
                enhanced = clahe.apply(gray_cropped)
                _, binarized = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                bordered = cv2.copyMakeBorder(binarized, 8, 8, 8, 8, cv2.BORDER_CONSTANT, value=[255])
                
                original_region_pil = Image.fromarray(cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2RGB))
                processed_region_pil = Image.fromarray(bordered)

                self.root.after(0, self._show_region_preview_window, original_region_pil, processed_region_pil)

            except Exception as e:
                logger.error(f"ç”ŸæˆåŒºåŸŸé¢„å¤„ç†é¢„è§ˆæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
                self.root.after(0, messagebox.showerror, "é¢„è§ˆå¤±è´¥", f"ç”Ÿæˆé¢„è§ˆå¤±è´¥: {e}\n\nè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚")
            finally:
                self.root.after(0, self.set_processing, False)

        self.loop.call_soon_threadsafe(self.loop.create_task, preview_worker_async())
    
    
    def _show_region_preview_window(self, original_region: Image.Image, processed_region: Image.Image):
        """åˆ›å»ºä¸€ä¸ªæ–°çª—å£æ¥å¯¹æ¯”æ˜¾ç¤ºå•ä¸ªæ–‡æœ¬åŒºåŸŸçš„é¢„å¤„ç†å‰åæ•ˆæœã€‚"""
        preview_window = tk.Toplevel(self.root)
        preview_window.title("Tesseractç²¾ç»†åŒ–é¢„å¤„ç†æ•ˆæœé¢„è§ˆ")
        preview_window.geometry("800x400")
        preview_window.transient(self.root)
        preview_window.grab_set()

        main_frame = ttk.Frame(preview_window, padding=design.get_spacing('4'))
        main_frame.pack(fill='both', expand=True)

        image_frame = ttk.Frame(main_frame)
        image_frame.pack(fill='both', expand=True)

        original_frame = ttk.LabelFrame(image_frame, text="å¤„ç†å‰", padding=design.get_spacing('2'))
        original_frame.pack(side='left', fill='both', expand=True, padx=(0, design.get_spacing('2')))
        original_label = tk.Label(original_frame, bg=design.get_color('neutral', '100'))
        original_label.pack(fill='both', expand=True)

        processed_frame = ttk.LabelFrame(image_frame, text="å¤„ç†å (é€å…¥Tesseract)", padding=design.get_spacing('2'))
        processed_frame.pack(side='right', fill='both', expand=True, padx=(design.get_spacing('2'), 0))
        processed_label = tk.Label(processed_frame, bg=design.get_color('neutral', '100'))
        processed_label.pack(fill='both', expand=True)

        def resize_and_display(label: tk.Label, img: Image.Image):
            max_size = 300
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
            photo = ImageTk.PhotoImage(img)
            label.config(image=photo)
            label.image = photo

        resize_and_display(original_label, original_region)
        resize_and_display(processed_label, processed_region)
        
        info_label = tk.Label(main_frame, text="è¿™æ˜¯å¯¹ä¸€ä¸ªæ ·æœ¬åŒºåŸŸåº”ç”¨ç²¾ç»†åŒ–é¢„å¤„ç†ï¼ˆç¼©æ”¾ã€å¢å¼ºã€äºŒå€¼åŒ–ã€åŠ è¾¹æ¡†ï¼‰åçš„æ•ˆæœã€‚\næ‚¨å¯ä»¥åœ¨ä¸»ç•Œé¢å–æ¶ˆå‹¾é€‰â€œå¯ç”¨ç²¾ç»†åŒ–é¢„å¤„ç†â€æ¥è·³è¿‡æ­¤æ­¥éª¤ã€‚",
                              wraplength=750, justify='center', bg=design.get_color('neutral', '50'))
        info_label.pack(pady=(design.get_spacing('2'), 0))
    def preview_merge_effect(self):
        """å¯åŠ¨ä¸€ä¸ªå¼‚æ­¥ä»»åŠ¡ï¼Œä»¥é¢„è§ˆæ™ºèƒ½è¡Œåˆå¹¶çš„æ•ˆæœã€‚"""
        if self.processing:
            messagebox.showwarning("å¤„ç†ä¸­", "å½“å‰æ­£åœ¨è¿›è¡Œå…¶ä»–æ“ä½œï¼Œè¯·ç¨å€™ã€‚")
            return
        if not self.current_image_path:
            messagebox.showwarning("æœªé€‰æ‹©å›¾ç‰‡", "è¯·å…ˆé€‰æ‹©ä¸€å¼ å›¾ç‰‡ã€‚")
            return
        if not self.cvocr_manager.is_initialized or not self.cvocr_manager.text_detector:
            messagebox.showerror("å¼•æ“æœªå°±ç»ª", "è¯·å…ˆåˆå§‹åŒ–CVOCRå¼•æ“ã€‚")
            return

        self.set_processing(True)
        self.log_message("ğŸ”¬ æ­£åœ¨ç”Ÿæˆæ™ºèƒ½è¡Œåˆå¹¶æ•ˆæœé¢„è§ˆ...", 'INFO')

        async def preview_worker_async():
            try:
                # æ­¥éª¤1: é¢„å¤„ç†å›¾åƒ
                self.log_message("  -> [åˆå¹¶é¢„è§ˆ] æ­¥éª¤1: å¼€å§‹é¢„å¤„ç†å›¾åƒ...", "DEBUG")
                preprocess_options = {key: var.get() for key, var in self.settings.items() if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar))}
                
                # ä½¿ç”¨ functools.partial å°†å‡½æ•°å’Œå…¶å‚æ•°æ‰“åŒ…æˆä¸€ä¸ªæ— å‚æ•°çš„å¯è°ƒç”¨å¯¹è±¡
                task_preprocess = functools.partial(
                    self.image_processor.intelligent_preprocess_image,
                    self.current_image_path,
                    **preprocess_options
                )
                
                processed_image_np, _, _ = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    task_preprocess
                )

                if processed_image_np is None: 
                    raise Exception("å›¾åƒé¢„å¤„ç†å¤±è´¥ã€‚")
                self.log_message("  -> [åˆå¹¶é¢„è§ˆ] æ­¥éª¤1: é¢„å¤„ç†å›¾åƒå®Œæˆã€‚", "DEBUG")

                enabled_algorithms = self._get_enabled_segmentation_algorithms()
                if not enabled_algorithms: 
                    raise Exception("è¯·è‡³å°‘é€‰æ‹©ä¸€ç§é«˜çº§åˆ†å‰²æŠ€æœ¯ã€‚")

                # æ­¥éª¤2a: æ‰§è¡Œåˆ†å‰²ï¼Œä½†ä¸è¿›è¡Œåˆå¹¶
                self.log_message("  -> [åˆå¹¶é¢„è§ˆ] æ­¥éª¤2a: æ‰§è¡Œåˆ†å‰² (ä¸åˆå¹¶)...", "DEBUG")
                unmerged_config = {key: var.get() for key, var in self.settings.items() if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar))}
                unmerged_config['enable_smart_line_merge'] = False
                self.cvocr_manager.text_detector.config.update(unmerged_config)
                
                task_unmerged_detect = functools.partial(
                    self.cvocr_manager.text_detector.detect_text_regions_advanced,
                    processed_image_np,
                    enabled_algorithms
                )
                unmerged_regions, _ = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    task_unmerged_detect
                )
                self.log_message(f"  -> [åˆå¹¶é¢„è§ˆ] æ­¥éª¤2a: åˆ†å‰²å®Œæˆï¼Œæ‰¾åˆ° {len(unmerged_regions)} ä¸ªåŒºåŸŸã€‚", "DEBUG")

                # æ­¥éª¤2b: æ‰§è¡Œåˆ†å‰²ï¼Œå¹¶è¿›è¡Œåˆå¹¶
                self.log_message("  -> [åˆå¹¶é¢„è§ˆ] æ­¥éª¤2b: æ‰§è¡Œåˆ†å‰² (åˆå¹¶)...", "DEBUG")
                merged_config = {key: var.get() for key, var in self.settings.items() if isinstance(var, (tk.BooleanVar, tk.StringVar, tk.IntVar, tk.DoubleVar))}
                merged_config['enable_smart_line_merge'] = True
                self.cvocr_manager.text_detector.config.update(merged_config)
                
                task_merged_detect = functools.partial(
                    self.cvocr_manager.text_detector.detect_text_regions_advanced,
                    processed_image_np,
                    enabled_algorithms
                )
                merged_regions, _ = await self.loop.run_in_executor(
                    self.async_ocr_processor.executor,
                    task_merged_detect
                )
                self.log_message(f"  -> [åˆå¹¶é¢„è§ˆ] æ­¥éª¤2b: åˆå¹¶å®Œæˆï¼Œå¾—åˆ° {len(merged_regions)} ä¸ªåŒºåŸŸã€‚", "DEBUG")
                
                self.log_message(f"  -> åˆ†å‰²ç»“æœ: {len(unmerged_regions)} (åˆå¹¶å‰) -> {len(merged_regions)} (åˆå¹¶å)", "INFO")

                # æ­¥éª¤3: ç»˜åˆ¶å¯¹æ¯”å›¾åƒ
                self.log_message("  -> [åˆå¹¶é¢„è§ˆ] æ­¥éª¤3: æ­£åœ¨ç»˜åˆ¶é¢„è§ˆå›¾åƒ...", "DEBUG")
                img_unmerged = processed_image_np.copy()
                img_merged = processed_image_np.copy()
                
                if len(img_unmerged.shape) == 2: img_unmerged = cv2.cvtColor(img_unmerged, cv2.COLOR_GRAY2BGR)
                if len(img_merged.shape) == 2: img_merged = cv2.cvtColor(img_merged, cv2.COLOR_GRAY2BGR)
                
                if unmerged_regions:
                    cv2.polylines(img_unmerged, [np.array(r, np.int32) for r in unmerged_regions], True, (255, 0, 0), 2) # çº¢è‰²ï¼šæœªåˆå¹¶
                if merged_regions:
                    cv2.polylines(img_merged, [np.array(r, np.int32) for r in merged_regions], True, (0, 255, 0), 2) # ç»¿è‰²ï¼šå·²åˆå¹¶

                img_unmerged_pil = Image.fromarray(cv2.cvtColor(img_unmerged, cv2.COLOR_BGR2RGB))
                img_merged_pil = Image.fromarray(cv2.cvtColor(img_merged, cv2.COLOR_BGR2RGB))
                
                metadata = {
                    'unmerged_count': len(unmerged_regions),
                    'merged_count': len(merged_regions)
                }
                
                # æ­¥éª¤4: åœ¨ä¸»çº¿ç¨‹æ˜¾ç¤ºé¢„è§ˆçª—å£
                self.log_message("  -> [åˆå¹¶é¢„è§ˆ] æ­¥éª¤4: å³å°†æ˜¾ç¤ºé¢„è§ˆçª—å£...", "DEBUG")
                self.root.after(0, self._show_merge_preview_window, img_unmerged_pil, img_merged_pil, metadata)

            except Exception as e:
                logger.error(f"ç”Ÿæˆåˆå¹¶é¢„è§ˆæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
                self.root.after(0, messagebox.showerror, "é¢„è§ˆå¤±è´¥", f"ç”Ÿæˆé¢„è§ˆå¤±è´¥: {e}\n\nè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚")
            finally:
                self.root.after(0, self.set_processing, False)

        self.loop.call_soon_threadsafe(self.loop.create_task, preview_worker_async())
    
    
    
    def _show_merge_preview_window(self, img_unmerged: Image.Image, img_merged: Image.Image, metadata: Dict):
        """åˆ›å»ºæ–°çª—å£å¯¹æ¯”æ˜¾ç¤ºè¡Œåˆå¹¶å‰åçš„æ•ˆæœã€‚"""
        preview_window = tk.Toplevel(self.root)
        preview_window.title("æ™ºèƒ½è¡Œåˆå¹¶æ•ˆæœé¢„è§ˆ")
        preview_window.geometry("1600x800")
        preview_window.transient(self.root)
        preview_window.grab_set()

        main_frame = ttk.Frame(preview_window, padding=design.get_spacing('4'))
        main_frame.pack(fill='both', expand=True)

        image_frame = ttk.Frame(main_frame)
        image_frame.pack(fill='both', expand=True)

        unmerged_frame = ttk.LabelFrame(image_frame, text=f"åˆå¹¶å‰ (çº¢è‰²æ¡†) - {metadata['unmerged_count']} ä¸ªåŒºåŸŸ", padding=design.get_spacing('2'))
        unmerged_frame.pack(side='left', fill='both', expand=True, padx=(0, design.get_spacing('2')))
        unmerged_canvas = tk.Canvas(unmerged_frame, bg='black')
        unmerged_canvas.pack(fill='both', expand=True)

        merged_frame = ttk.LabelFrame(image_frame, text=f"åˆå¹¶å (ç»¿è‰²æ¡†) - {metadata['merged_count']} ä¸ªåŒºåŸŸ", padding=design.get_spacing('2'))
        merged_frame.pack(side='right', fill='both', expand=True, padx=(design.get_spacing('2'), 0))
        merged_canvas = tk.Canvas(merged_frame, bg='black')
        merged_canvas.pack(fill='both', expand=True)

        def resize_and_display(canvas: tk.Canvas, img: Image.Image):
            canvas.update_idletasks()
            canvas_w, canvas_h = canvas.winfo_width(), canvas.winfo_height()
            if canvas_w <= 1 or canvas_h <= 1: return
            
            img_w, img_h = img.size
            scale = min(canvas_w / img_w, canvas_h / img_h)
            new_w, new_h = int(img_w * scale), int(img_h * scale)
            
            resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            photo = ImageTk.PhotoImage(resized)
            canvas.image = photo 
            x_offset = (canvas_w - new_w) // 2
            y_offset = (canvas_h - new_h) // 2
            canvas.create_image(x_offset, y_offset, image=photo, anchor='nw')

        preview_window.after(100, lambda: [
            resize_and_display(unmerged_canvas, img_unmerged),
            resize_and_display(merged_canvas, img_merged),
            unmerged_canvas.bind('<Configure>', lambda e: resize_and_display(unmerged_canvas, img_unmerged)),
            merged_canvas.bind('<Configure>', lambda e: resize_and_display(merged_canvas, img_merged))
        ])
if __name__ == "__main__":
    app_instance = None
    try:
        # åˆ›å»ºTkinteræ ¹çª—å£
        root = tk.Tk()
        # å®ä¾‹åŒ–ä¸»GUIåº”ç”¨ç±»
        app_instance = EnhancedCVOCRGUI(root)
        
        # å¯åŠ¨Tkinterçš„ä¸»äº‹ä»¶å¾ªç¯ã€‚
        # æ­¤å¾ªç¯ä¼šä¸€ç›´è¿è¡Œï¼Œç›´åˆ°çª—å£è¢«å…³é—­ã€‚
        # çª—å£å…³é—­äº‹ä»¶ç”± EnhancedCVOCRGUI å†…éƒ¨çš„ protocol("WM_DELETE_WINDOW", ...) æ•è·ï¼Œ
        # å¹¶è°ƒç”¨ on_closing æ–¹æ³•æ¥æ‰§è¡Œæ‰€æœ‰æ¸…ç†å·¥ä½œã€‚
        root.mainloop()
        
    except Exception as e:
        # æ•è·åº”ç”¨å¯åŠ¨æˆ–è¿è¡ŒæœŸé—´å‘ç”Ÿçš„ä»»ä½•æœªå¤„ç†çš„è‡´å‘½é”™è¯¯
        logger.critical(f"åº”ç”¨å¯åŠ¨æˆ–è¿è¡Œæ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}\n{traceback.format_exc()}", exc_info=True)
        
        # å°è¯•å¼¹å‡ºä¸€ä¸ªç®€å•çš„é”™è¯¯çª—å£ï¼Œä»¥ä¾¿ç”¨æˆ·äº†è§£æƒ…å†µ
        try:
            # --- é¢å¤–ä¼˜åŒ–ï¼šç¡®ä¿åœ¨åˆ›å»º messagebox ä¹‹å‰æœ‰ root çª—å£ ---
            # å¦‚æœ root åˆ›å»ºå¤±è´¥ï¼Œä¹‹å‰çš„ messagebox ä¼šæŠ¥é”™
            # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ root æ¥æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            root_exists = 'root' in locals() and isinstance(root, tk.Tk) and root.winfo_exists()
            
            if not root_exists:
                error_root = tk.Tk()
                error_root.withdraw() # éšè—ä¸»çª—å£
                messagebox.showerror("CVOCRåº”ç”¨é”™è¯¯", f"åº”ç”¨å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}\nè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ 'cvocr_gui.log' è·å–æ›´å¤šè¯¦æƒ…ã€‚", parent=error_root)
                error_root.destroy()
            else:
                 messagebox.showerror("CVOCRåº”ç”¨é”™è¯¯", f"åº”ç”¨å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}\nè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ 'cvocr_gui.log' è·å–æ›´å¤šè¯¦æƒ…ã€‚")
        except Exception as tk_e:
            # å¦‚æœè¿messageboxéƒ½æ— æ³•å¼¹å‡ºï¼ˆä¾‹å¦‚åœ¨æ— å¤´ç¯å¢ƒä¸­ï¼‰ï¼Œå°±åœ¨æ§åˆ¶å°æ‰“å°æœ€ç»ˆé”™è¯¯
            print(f"CRITICAL ERROR (cannot show messagebox, check log file): {e}\nTraceback: {traceback.format_exc()}")
            logger.critical(f"æ— æ³•æ˜¾ç¤ºTkinteré”™è¯¯å¯¹è¯æ¡†: {tk_e}", exc_info=True)
    
    # --- ä¿®æ­£: ç§»é™¤äº†æ•´ä¸ª finally å— ---
    # å…³é—­é€»è¾‘å·²å®Œå…¨ç”± on_closing æ–¹æ³•é€šè¿‡çª—å£åè®®è§¦å‘ï¼Œè¿™é‡Œä¸å†éœ€è¦ã€‚
    # è¿™å¯ä»¥é˜²æ­¢åœ¨åº”ç”¨å·²é”€æ¯åå†æ¬¡è°ƒç”¨ on_closing å¯¼è‡´çš„ TclErrorã€‚
    logger.info("Application mainloop has finished. Process is exiting.")